# üèõÔ∏è QORUS-IA v3.0: MASTER BLUEPRINT
# Generic Deep Learning Framework

**Entendido. Voc√™ quer o Blueprint de Execu√ß√£o. Sem teoria desnecess√°ria, apenas a engenharia pura para o Cursor executar.**

Aqui est√° a Arquitetura Definitiva do Qorus-IA v3.0. Copie este contexto para o Cursor e ele saber√° exatamente o que fazer.

## Objetivo
Framework Gen√©rico de Deep Learning em C Puro - Sem Limita√ß√µes Arquiteturais.

**Evolu√ß√£o:**
- **v2.0:** Engine especializado (infer√™ncia otimizada)
- **v3.0:** Framework gen√©rico (qualquer arquitetura) mantendo performance e arquitetura limpa

**Prioridades:** Performance (zero-malloc, AVX2), Flexibilidade (qualquer arquitetura), Arquitetura Limpa (valida√ß√µes robustas).

**Restri√ß√£o:** Zero-Malloc no Hot Path (mantido).

---

## 1. ESTRUTURA DE DIRET√ìRIOS (File System)

Esta organiza√ß√£o separa infraestrutura, matem√°tica e l√≥gica de modelo.

```
qorus-ia/
‚îú‚îÄ‚îÄ include/
‚îÇ   ‚îú‚îÄ‚îÄ qorus.h             # Header √önico P√∫blico (API)
‚îÇ   ‚îî‚îÄ‚îÄ qorus_types.h       # Structs e Enums fundamentais
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ core/               # Infraestrutura de Baixo N√≠vel
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ memory.c        # Arena, Aligned Malloc, Mmap
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tensor.c        # Manipula√ß√£o de Metadados de Tensor
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils.c         # Timing, Logging, SIMD detection
‚îÇ   ‚îú‚îÄ‚îÄ ops/                # Kernels Matem√°ticos (Otimizados)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cpu/            # Fallbacks em C puro (Refer√™ncia)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ avx2/           # Kernels AVX2 (MatMul Q4, MatMul FP32, RoPE, RMSNorm, Add, Mul, Causal Mask, Loss, Clip)
‚îÇ   ‚îú‚îÄ‚îÄ optim/              # Optimizers (Training) - NEW
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ optimizer.c     # Base optimizer interface
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ adam.c          # Adam/AdamW optimizer
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scheduler.c     # Learning rate scheduling
‚îÇ   ‚îú‚îÄ‚îÄ layers/             # Camadas Gen√©ricas (Framework v3.0)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ linear.c        # Linear layer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ activation.c    # Activation layers
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ normalization.c # Normalization layers
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mha.c           # Multi-Head Attention
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ffn.c           # Feed-Forward Network
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ transformer_block.c  # Transformer Block
‚îÇ   ‚îú‚îÄ‚îÄ models/             # Model Builders (Exemplos)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ example_models.c  # Exemplos de modelos usando framework gen√©rico
‚îÇ   ‚îî‚îÄ‚îÄ tokenizer/          # Processamento de Texto
‚îÇ       ‚îî‚îÄ‚îÄ bpe.c           # Tokenizer BPE minimalista
‚îú‚îÄ‚îÄ tools/
‚îÇ   ‚îî‚îÄ‚îÄ convert_model.py    # Script Python: Model Format -> Qorus Binary (Zero-Parse)
‚îú‚îÄ‚îÄ tests/                  # Testes Unit√°rios e de Integra√ß√£o
‚îî‚îÄ‚îÄ Makefile                # Build System (-O3 -mavx2)
```

---

## 2. ARQUITETURA DE DADOS (Memory Layout)

O Cursor deve implementar estas estruturas exatamente como definidas para garantir alinhamento e performance.

### 2.1. Tipos e Tensores (include/qorus_types.h)

**Nota de Seguran√ßa:** Todas as fun√ß√µes matem√°ticas agora retornam `q_error_code` e validam inputs em Release mode usando macros otimizadas (`Q_VALIDATE_OR_RETURN`, `Q_VALIDATE_PTR_OR_RETURN`, etc.).

```c
#include <stdint.h>
#include <stdbool.h>

// Alinhamento obrigat√≥rio para AVX2/AVX-512
#define Q_ALIGN 64

typedef enum {
    Q_F32  = 0,
    Q_Q8_0 = 1, // Pesos (Embeddings/Output)
    Q_Q4_0 = 2  // Pesos (Dense Layers)
} q_dtype;

// Tensor View (N√£o possui a mem√≥ria, apenas aponta)
typedef struct {
    void*     data;         // Ponteiro para dados (Mmap ou Arena)
    float*    scales;       // Ponteiro para escalas (se quantizado)
    uint32_t  ne[4];        // Dimens√µes: [Batch, Head, Seq, Dim]
    size_t    nb[4];        // Strides em bytes
    q_dtype   type;         // Tipo de dado
    char      name[32];     // Debugging
} __attribute__((aligned(Q_ALIGN))) q_tensor;

// Contexto Global de Mem√≥ria
typedef struct {
    void* weights_mmap;     // Ponteiro base do arquivo mapeado
    size_t weights_size;
    
    void* kv_buffer;        // Buffer persistente para KV Cache
    size_t kv_size;
    
    void* scratch_buffer;   // Buffer tempor√°rio (Arena)
    size_t scratch_size;
    size_t scratch_head;    // Posi√ß√£o atual na Arena
} q_context;
```

---

## 3. ESTRAT√âGIA DE MEM√ìRIA (The 3 Arenas)

O Cursor deve seguir estritamente esta l√≥gica de aloca√ß√£o.

### Weights (Read-Only):
- **Origem:** mmap de arquivo bin√°rio pr√©-formatado.
- **Acesso:** Ponteiros `q_tensor.data` apontam diretamente para endere√ßos virtuais do mmap.
- **Custo:** Zero copy.

### KV Cache (Persistent):
- **Aloca√ß√£o:** `aligned_alloc` √∫nico na inicializa√ß√£o.
- **Layout:** Cont√≠guo `[n_layers, n_kv_heads, max_seq, head_dim]`.
- **Acesso:** Aritm√©tica de ponteiros simples. Sem indire√ß√£o.

### Scratchpad (Transient):
- **Aloca√ß√£o:** `aligned_alloc` √∫nico na inicializa√ß√£o (ex: 512MB).
- **Uso:** Ativa√ß√µes intermedi√°rias (sa√≠da de MatMul, Softmax).
- **Ciclo:** `scratch_head` √© resetado para 0 no in√≠cio de cada token gerado.
- **Regra:** NUNCA dar `free()` em tensores individuais aqui.

---

## 4. ROTEIRO DE IMPLEMENTA√á√ÉO (Step-by-Step)

Pe√ßa ao Cursor para executar uma fase por vez. N√£o avance sem validar.

### ‚úÖ FASE 1: Infraestrutura & Conversor (A Base) - **COMPLETA**

**Objetivo:** Conseguir carregar pesos do disco sem parsing.

- ‚úÖ **Passo 1.1 (Python):** `tools/convert_llama.py` criado. Gera arquivo `.qorus` com header fixo e tensores alinhados a 64 bytes.

- ‚úÖ **Passo 1.2 (C):** `src/core/memory.c` implementado (mmap, arena). `src/core/tensor.c` implementado (cria√ß√£o de views).

- ‚úÖ **Valida√ß√£o:** Testes de mem√≥ria validados. Carregamento de modelo dummy funcionando.

### ‚úÖ FASE 2: Kernels Matem√°ticos (O Motor) - **COMPLETA**

**Objetivo:** Opera√ß√µes vetoriais r√°pidas.

- ‚úÖ **Passo 2.1:** `src/ops/avx2/dequantize.c` implementado. Q4_0 ‚Üí 32 floats em YMM, FMA-optimized.

- ‚úÖ **Passo 2.2:** `src/ops/avx2/matmul.c` implementado. GEMV Q4_F32 com dequantiza√ß√£o fundida, 4x unrolling.

- ‚úÖ **Passo 2.3:** `src/ops/avx2/rope.c` e `src/ops/avx2/rmsnorm.c` implementados.

- ‚úÖ **Passo 2.4:** `src/ops/avx2/silu.c` e `src/ops/avx2/softmax.c` implementados. Utilit√°rios matem√°ticos em `avx_math.h`.

- ‚úÖ **Passo 2.5:** **Seguran√ßa Implementada** - Todas as fun√ß√µes matem√°ticas agora retornam `q_error_code` e validam inputs em Release mode:
  - Valida√ß√£o de ponteiros nulos
  - Valida√ß√£o de aliasing (input == output)
  - Valida√ß√£o de overflow
  - Valida√ß√£o de alinhamento
  - Valida√ß√£o de tipo de dados
  - Valida√ß√£o de dimens√µes (m√∫ltiplos de 8/32)
  - Macros de valida√ß√£o otimizadas com `__builtin_expect` para overhead m√≠nimo

- ‚úÖ **Valida√ß√£o:** Todos os kernels testados e validados contra refer√™ncias NumPy. Testes atualizados para verificar retornos de erro.

### ‚úÖ FASE 2.5: Kernels Adicionais (MetaIA Portation) - **COMPLETA**

**Objetivo:** Portar kernels cr√≠ticos do MetaIA v1.4.0 para completar o forward pass.

**Status:** ‚úÖ **COMPLETA** (2025-12-31). Todos os kernels implementados, testados e validados.

**Kernels Implementados:**

- ‚úÖ **MatMul FP32 AVX2** (`q_matmul_f32_avx2`)
  - **Arquivo:** `src/ops/avx2/matmul_fp32.c`
  - **Testes:** `tests/test_matmul_f32.c`
  - **Uso:** Q @ K^T (attention scores), probs @ V (attention output), LM Head projection
  - **Complexidade:** O(M √ó N √ó K)
  - **Status:** Implementado, testado e validado
  - **Caracter√≠sticas:**
    - Cache-blocked matrix multiplication
    - 4x accumulator unrolling
    - Manual prefetching
    - Transpose B for cache efficiency

- ‚úÖ **Causal Masking AVX2** (`q_causal_mask_f32_avx2`)
  - **Arquivo:** `src/ops/avx2/causal_mask_fp32.c`
  - **Testes:** `tests/test_causal_mask_f32.c`
  - **Uso:** Attention triangular mask (prevent future tokens from attending to past)
  - **Complexidade:** O(N¬≤)
  - **Status:** Implementado, testado e validado
  - **Caracter√≠sticas:**
    - Vectorized upper triangular masking
    - AVX2 stores for efficiency
    - In-place operation

- ‚úÖ **Tensor Add AVX2** (`q_add_f32_avx2`)
  - **Arquivo:** `src/ops/avx2/add_fp32.c`
  - **Testes:** `tests/test_add_f32.c`
  - **Uso:** Residual connections (`x = x + attn_out`)
  - **Complexidade:** O(N)
  - **Status:** Implementado, testado, validado e code-reviewed
  - **Caracter√≠sticas:**
    - 4x unrolling (32 elements per iteration)
    - AVX2 vectorized addition
    - In-place operation support (output may alias input)

- ‚úÖ **Element-wise Mul AVX2** (`q_mul_f32_avx2`)
  - **Arquivo:** `src/ops/avx2/mul_fp32.c`
  - **Testes:** `tests/test_mul_f32.c`
  - **Uso:** SwiGLU activation (`gate * up` in MLP)
  - **Complexidade:** O(N)
  - **Status:** Implementado, testado, validado e code-reviewed
  - **Caracter√≠sticas:**
    - 4x unrolling (32 elements per iteration)
    - AVX2 vectorized multiplication
    - In-place operation support

**Valida√ß√£o Completa:**
- ‚úÖ Todos os testes passam (Release + Debug with sanitizers)
- ‚úÖ Code review completado (First Principles Thinking + CoT)
- ‚úÖ Edge cases tratados (NULL inputs, shape mismatches, alignment)
- ‚úÖ Opera√ß√µes in-place suportadas (safe aliasing)
- ‚úÖ Valida√ß√£o de precis√£o (max diff < 1e-5 para FP32)
- ‚úÖ Valida√ß√£o de mem√≥ria (AddressSanitizer clean)

**Adapta√ß√µes Arquiteturais Aplicadas (MetaIA ‚Üí New-QorusIA):**
- ‚úÖ `t_tensor` ‚Üí `q_tensor` (field mapping)
- ‚úÖ `int` return ‚Üí `q_error_code` enum
- ‚úÖ `malloc` ‚Üí `q_arena_alloc` (zero-malloc guarantee)
- ‚úÖ `#ifdef DEBUG` ‚Üí Always-active validation
- ‚úÖ `tensor_*` ‚Üí `q_*` naming

**Documenta√ß√£o:**
- `docs/KERNEL_PORTATION_PLAN.md` - Plano completo seguindo MFR + CoT + Mathematical Proof + TDD (Status: ‚úÖ COMPLETA)
- `docs/KERNEL_IMPLEMENTATION_DETAILS.md` - Guia de implementa√ß√£o com c√≥digo completo
- `docs/PLANNING_SUMMARY.md` - Resumo executivo do planejamento

### ‚úÖ D√≠vida T√©cnica de Baixa Prioridade - **COMPLETA**

**Objetivo:** Estabelecer base s√≥lida de testes, benchmarking e documenta√ß√£o antes de avan√ßar para forward pass.

- ‚úÖ **Testes de Utilit√°rios:**
  - `test_utils.c` - 23 testes para `q_strerror()` (valida√ß√£o O(1), todos os c√≥digos de erro)
  - `test_avx_math.c` - 13 testes para utilit√°rios AVX (`exp_approx_avx`, `horizontal_sum_avx`, `horizontal_max_avx`)
  - Toler√¢ncias ajustadas com justificativa matem√°tica para aproxima√ß√£o polinomial

- ‚úÖ **Ferramenta de Benchmark:**
  - `tools/benchmark.c` - Benchmarks end-to-end para todos os kernels AVX2
  - Mede lat√™ncia (ms), throughput (ops/s), e GFLOPS (para MatMul)
  - Inclui warmup iterations para medi√ß√µes precisas

- ‚úÖ **Documenta√ß√£o T√©cnica:**
  - `docs/ASYMPTOTIC_ANALYSIS.md` - An√°lise assint√≥tica completa de todas as fun√ß√µes cr√≠ticas
  - `docs/ASSEMBLY_ANALYSIS.md` - Guia para an√°lise de c√≥digo assembly gerado
  - `tools/analyze_assembly.sh` - Script automatizado para an√°lise de assembly
  - `docs/PRECISION_STANDARDS.md` - Atualizado com justificativas t√©cnicas das toler√¢ncias

### ‚úÖ FASE 3: Model Graph Building (O Corpo) - **PARCIALMENTE COMPLETA**

**Objetivo:** Conectar os kernels na ordem correta usando framework gen√©rico.

- ‚úÖ **Passo 3.1:** Definir estruturas gen√©ricas em `qorus_types.h`.  
  **Status:** Estruturas definidas e validadas com `_Static_assert`.

- ‚úÖ **Passo 3.2:** Implementar `q_model_build_graph()`. Configurar ponteiros dos tensores baseados no arquivo mmap.
  **Status:** Implementado e testado (31 testes, 100% pass rate).
  - Zero-copy tensor views
  - Valida√ß√£o completa de configura√ß√£o
  - Suporte a Q4_0 e FP32
  - Testes adversarial completos

- ‚è≥ **Passo 3.3:** Implementar `llama_forward()`. Orquestrar passagem dos dados pelos kernels usando framework gen√©rico.
  **Status:** Em progresso (estrutura completa, aten√ß√£o e LM Head precisam de conclus√£o).
  **Depend√™ncias:** ‚úÖ Todas resolvidas (FASE 2.5 completa)
    - ‚úÖ MatMul FP32 AVX2 (Q @ K^T, probs @ V, projection layers)
    - ‚úÖ Causal Masking AVX2 (attention mask)
    - ‚úÖ Tensor Add AVX2 (residual connections)
    - ‚úÖ Element-wise Mul AVX2 (SwiGLU activation)
  **Progresso:**
    - ‚úÖ Estrutura do forward pass completa
    - ‚úÖ KV cache helper implementado
    - ‚úÖ MLP forward pass completo (SwiGLU)
    - ‚úÖ Layer forward pass completo (attention + MLP com residuals)
    - ‚úÖ Final RMSNorm implementado
    - ‚è≥ Attention forward pass (Q/K/V projections feito, RoPE/KV cache/causal mask/softmax TODO)
    - ‚è≥ LM Head projection (precisa transpose ou GEMV)

**Nota:** Framework gen√©rico permite qualquer arquitetura, n√£o apenas Transformers.

### ‚è≥ FASE 2.6: Training Kernels (Planejamento Completo) - **PLANEJAMENTO COMPLETO**

**Objetivo:** Adicionar capacidade de treinamento para future-implementations (Code Agent, Customer Behavior Prediction, SEO AI Specialist).

**Status:** üìã Planejamento completo (2024-12-30). Pronto para implementa√ß√£o.

**Componentes Planejados:**

- ‚è≥ **Optimizers** (`src/optim/`)
  - **Arquivo:** `src/optim/optimizer.c`, `src/optim/adam.c`
  - **Uso:** Atualiza√ß√£o de pesos durante treinamento (Adam, AdamW)
  - **Tempo Estimado:** 8-12 horas
  - **Caracter√≠sticas:**
    - AVX2-optimized weight updates
    - Arena-based state allocation (zero-malloc)
    - Support for SGD, Adam, AdamW

- ‚è≥ **Loss Functions** (`src/ops/avx2/`)
  - **Arquivos:** `src/ops/avx2/loss_mse.c`, `src/ops/avx2/loss_crossentropy.c`
  - **Uso:** C√°lculo de loss e gradientes para backward pass
  - **Tempo Estimado:** 4-6 horas
  - **Caracter√≠sticas:**
    - AVX2-optimized loss computation
    - Gradient computation for backward pass

- ‚è≥ **Gradient Clipping** (`src/ops/avx2/`)
  - **Arquivo:** `src/ops/avx2/clip.c`
  - **Uso:** Estabiliza√ß√£o de gradientes durante treinamento
  - **Tempo Estimado:** 2-3 horas
  - **Caracter√≠sticas:**
    - AVX2-optimized clipping
    - In-place operation

**Total Estimado (FASE 2.6):** 14-21 horas

**Documenta√ß√£o de Planejamento:**
- `docs/TRAINING_CAPABILITY_PLAN.md` - Plano completo de capacidade de treinamento

### ‚è≥ FASE 3.4: Backward Pass (Training) - **PLANEJAMENTO COMPLETO**

**Objetivo:** Implementar backward pass para propaga√ß√£o de gradientes.

**Status:** üìã Planejamento completo (2024-12-30). Bloqueado por FASE 2.6.

**Componentes Planejados:**

- ‚è≥ **Backward Infrastructure** (`src/core/model.c`)
  - **Fun√ß√£o:** `q_model_backward()`
  - **Uso:** Propaga√ß√£o de gradientes atrav√©s das camadas (gen√©rico)
  - **Tempo Estimado:** 6-8 horas
  - **Caracter√≠sticas:**
    - Forward cache management
    - Gradient propagation framework
    - Funciona com qualquer arquitetura

- ‚è≥ **Layer Backward Implementations**
  - **Attention Backward:** Q/K/V gradients, GQA-aware
  - **MLP Backward:** SwiGLU backward, down projection gradient
  - **RMSNorm Backward:** Weight gradient, input gradient
  - **Residual Backward:** Gradient pass-through
  - **Tempo Estimado:** 12-16 horas

**Total Estimado (FASE 3.4):** 18-24 horas

**Depend√™ncias:** FASE 2.6 (Optimizers, Loss Functions, Gradient Clipping)

### ‚è≥ FASE 3.5: Training Loop (Training) - **PLANEJAMENTO COMPLETO**

**Objetivo:** Implementar loop de treinamento completo.

**Status:** üìã Planejamento completo (2024-12-30). Bloqueado por FASE 3.4.

**Componentes Planejados:**

- ‚è≥ **Training Loop** (`src/core/model.c`)
  - **Fun√ß√£o:** `q_model_train()`
  - **Uso:** Loop completo de treinamento (epochs, mini-batches) - gen√©rico
  - **Tempo Estimado:** 6-8 horas
  - **Caracter√≠sticas:**
    - Mini-batch shuffling (Fisher-Yates)
    - Forward ‚Üí Loss ‚Üí Backward ‚Üí Optimizer Step ‚Üí Zero Grad
    - Gradient clipping integration
    - Early stopping support
    - Funciona com qualquer arquitetura

- ‚è≥ **Training Utilities**
  - Learning rate scheduling
  - Training metrics tracking
  - Checkpoint saving
  - **Tempo Estimado:** 4-6 horas

**Total Estimado (FASE 3.5):** 10-14 horas

**Depend√™ncias:** FASE 3.4 (Backward Pass)

### ‚è≥ FASE 4: Tokenizer & Loop (A Vida) - **N√ÉO INICIADA**

**Objetivo:** Texto entra, texto sai.

- ‚è≥ **Passo 4.1:** Implementar `src/tokenizer/bpe.c`. Carregar `tokenizer.bin` (extra√≠do do modelo original).

- ‚è≥ **Passo 4.2:** Criar `main.c`. Loop: Tokenize -> Forward -> Sample -> Print -> Update Cache.
  **Nota:** Todas as chamadas de fun√ß√µes matem√°ticas devem verificar retorno `q_error_code`.

---

## üöÄ EVOLU√á√ÉO PARA v3.0: FRAMEWORK GEN√âRICO

### Objetivo v3.0

Transformar QorusIA de engine especializado em **framework gen√©rico** sem limita√ß√µes arquiteturais, mantendo:
- ‚úÖ Performance m√°xima (zero-malloc, AVX2)
- ‚úÖ Arquitetura limpa (valida√ß√µes robustas)
- ‚úÖ Flexibilidade total (qualquer arquitetura)

### ‚è≥ FASE 5.0: Core Abstraction (Framework Gen√©rico) - **PLANEJAMENTO COMPLETO**

**Objetivo:** Implementar abstra√ß√£o gen√©rica de camadas e modelos.

**Status:** üìã Planejamento completo (2024-12-30). Pronto para implementa√ß√£o.

**Componentes Planejados:**

- ‚è≥ **Generic Layer Interface** (`include/qorus_types.h`)
  - **Estrutura:** `q_layer` com function pointers (polimorfismo)
  - **Tempo Estimado:** 4-6 horas
  - **Caracter√≠sticas:**
    - 64-byte aligned
    - Function pointers para forward/backward/free
    - Type enum para runtime checking

- ‚è≥ **Generic Model Container** (`src/core/model.c`)
  - **Estrutura:** `q_model` com array de camadas gen√©ricas
  - **Tempo Estimado:** 6-8 horas
  - **Caracter√≠sticas:**
    - 128-byte aligned
    - Forward cache para treinamento
    - Suporte a mmap (zero-copy)

- ‚è≥ **Generic Forward Pass** (`src/core/model.c`)
  - **Fun√ß√£o:** `q_model_forward()` gen√©rica
  - **Tempo Estimado:** 4-6 horas
  - **Caracter√≠sticas:**
    - Polimorfismo via function pointers
    - Forward cache management
    - Valida√ß√µes robustas

- ‚è≥ **Generic Backward Pass** (`src/core/model.c`)
  - **Fun√ß√£o:** `q_model_backward()` gen√©rica
  - **Tempo Estimado:** 6-8 horas
  - **Caracter√≠sticas:**
    - Propaga√ß√£o de gradientes gen√©rica
    - Uso de forward cache
    - Suporte a camadas n√£o-trein√°veis

**Total Estimado (FASE 5.0):** 20-28 horas

**Documenta√ß√£o de Planejamento:**
- `docs/GENERIC_FRAMEWORK_PLAN.md` - Plano completo de framework gen√©rico

### ‚è≥ FASE 5.1: Basic Layers (Framework Gen√©rico) - **PLANEJAMENTO COMPLETO**

**Objetivo:** Implementar camadas b√°sicas com interface gen√©rica.

**Status:** üìã Planejamento completo (2024-12-30).

**Camadas Planejadas:**

- ‚è≥ **Linear Layer** (`src/layers/linear.c`)
  - **Interface:** Gen√©rica (`q_layer`)
  - **Tempo Estimado:** 6-8 horas
  - **Caracter√≠sticas:**
    - Forward/backward gen√©ricos
    - Suporte Q4_0 e FP32
    - Gradientes para treinamento

- ‚è≥ **Activation Layers** (`src/layers/activation.c`)
  - **Tipos:** ReLU, GeLU, SiLU, Sigmoid
  - **Tempo Estimado:** 4-6 horas
  - **Caracter√≠sticas:**
    - Forward/backward gen√©ricos
    - AVX2 optimized

- ‚è≥ **Normalization Layers** (`src/layers/normalization.c`)
  - **Tipos:** RMSNorm, LayerNorm, BatchNorm
  - **Tempo Estimado:** 6-8 horas
  - **Caracter√≠sticas:**
    - Forward/backward gen√©ricos
    - AVX2 optimized

- ‚è≥ **Softmax Layer** (`src/layers/softmax.c`)
  - **Interface:** Gen√©rica
  - **Tempo Estimado:** 2-3 horas
  - **Caracter√≠sticas:**
    - Forward/backward gen√©ricos
    - AVX2 optimized

**Total Estimado (FASE 5.1):** 18-25 horas

### ‚è≥ FASE 5.2: Advanced Layers (Framework Gen√©rico) - **PLANEJAMENTO COMPLETO**

**Objetivo:** Implementar camadas avan√ßadas com interface gen√©rica.

**Status:** üìã Planejamento completo (2024-12-30).

**Camadas Planejadas:**

- ‚è≥ **Multi-Head Attention** (`src/layers/mha.c`)
  - **Interface:** Gen√©rica
  - **Tempo Estimado:** 8-10 horas
  - **Caracter√≠sticas:**
    - Suporte GQA
    - Forward/backward gen√©ricos
    - AVX2 optimized

- ‚è≥ **Feed-Forward Network** (`src/layers/ffn.c`)
  - **Interface:** Gen√©rica
  - **Tempo Estimado:** 6-8 horas
  - **Caracter√≠sticas:**
    - Suporte SwiGLU
    - Forward/backward gen√©ricos
    - AVX2 optimized

- ‚è≥ **Transformer Block** (`src/layers/transformer_block.c`)
  - **Interface:** Gen√©rica
  - **Tempo Estimado:** 4-6 horas
  - **Caracter√≠sticas:**
    - Composi√ß√£o de MHA + FFN + RMSNorm
    - Forward/backward gen√©ricos

- ‚è≥ **Embedding Layer** (`src/layers/embedding.c`)
  - **Interface:** Gen√©rica
  - **Tempo Estimado:** 4-6 horas
  - **Caracter√≠sticas:**
    - Token embedding
    - Positional embedding (RoPE)
    - Forward/backward gen√©ricos

**Total Estimado (FASE 5.2):** 22-30 horas

### ‚è≥ FASE 5.3: Example Model Builders (Framework Gen√©rico) - **PLANEJAMENTO COMPLETO**

**Objetivo:** Criar exemplos de modelos usando framework gen√©rico.

**Status:** üìã Planejamento completo (2024-12-30). Bloqueado por FASE 5.0-5.2.

**Componentes Planejados:**

- ‚è≥ **Transformer Model Builder** (`src/models/transformer_builder.c`)
  - **Fun√ß√£o:** `transformer_build_model()` usando API gen√©rica
  - **Tempo Estimado:** 6-8 horas
  - **Caracter√≠sticas:**
    - Exemplo de modelo Transformer usando framework gen√©rico
    - Zero-copy weight loading
    - Demonstra flexibilidade do framework

- ‚è≥ **Example Testing**
  - **Tempo Estimado:** 4-6 horas
  - **Caracter√≠sticas:**
    - Testes de performance
    - Valida√ß√£o de corre√ß√£o
    - Demonstra uso do framework gen√©rico

- ‚è≥ **Documentation**
  - **Tempo Estimado:** 2-3 horas
  - **Caracter√≠sticas:**
    - Exemplos de uso
    - Guias de migra√ß√£o
    - Documenta√ß√£o de API

**Total Estimado (FASE 5.3):** 12-17 horas

**Depend√™ncias:** FASE 5.0 (Core Abstraction), FASE 5.1 (Basic Layers), FASE 5.2 (Advanced Layers)

### ‚è≥ FASE 5.4: Additional Architectures (Framework Gen√©rico) - **FUTURO**

**Objetivo:** Suportar arquiteturas adicionais usando framework gen√©rico.

**Arquiteturas Planejadas:**

- ‚è≥ **Simple MLP** (Exemplo: MNIST classifier)
  - **Tempo Estimado:** 4-6 horas
  - **Demonstra:** Flexibilidade do framework gen√©rico

- ‚è≥ **CNN Support** (Futuro)
  - Conv2D layer
  - Pool2D layer
  - Arquiteturas CNN

- ‚è≥ **RNN/LSTM Support** (Futuro)
  - RNN layer
  - LSTM layer
  - Modelos de sequ√™ncia

---

## COMPARA√á√ÉO: v2.0 vs v3.0

### QorusIA v2.0 (Atual)
- ‚úÖ Performance m√°xima (zero-malloc, AVX2)
- ‚úÖ Arquitetura limpa
- ‚ùå Limitado a arquitetura espec√≠fica
- ‚ùå Estrutura hardcoded

### QorusIA v3.0 (Proposto)
- ‚úÖ Performance m√°xima (zero-malloc, AVX2)
- ‚úÖ Arquitetura limpa
- ‚úÖ Gen√©rico (qualquer arquitetura)
- ‚úÖ Composi√ß√£o flex√≠vel
- ‚úÖ F√°cil de estender

**Resultado:** MetaIA's flexibilidade + QorusIA's performance = Framework gen√©rico sem limita√ß√µes.

---

## 5. REGRAS DE CODIFICA√á√ÉO (Para o Cursor)

Cole isso no prompt do Cursor para garantir qualidade:

- **Strict C11:** Use C11 padr√£o. Sem extens√µes GNU a menos que estritamente necess√°rio para AVX.

- **No Mallocs:** Proibido usar `malloc` ou `free` dentro de `src/ops` ou `src/models`. Use a API da Arena.

- **Restrict Pointers:** Use `float *restrict a` em kernels matem√°ticos para permitir otimiza√ß√µes agressivas do compilador.

- **Error Handling:** 
  - Fun√ß√µes matem√°ticas retornam `q_error_code` (enum padronizado).
  - Use macros `Q_VALIDATE_OR_RETURN` para valida√ß√µes cr√≠ticas (sempre ativas em Release).
  - Em DEBUG mode: valida√ß√µes abortam com mensagem detalhada.
  - Em Release mode: valida√ß√µes retornam c√≥digo de erro apropriado.
  - Crash (`abort`) apenas em DEBUG mode para facilitar debugging.

- **Comments:** Documente o layout de mem√≥ria esperado em cima de cada kernel (ex: "Espera que A seja [K, N] transposto").

---

## 6. SEGURAN√áA E VALIDA√á√ÉO

### Valida√ß√µes Cr√≠ticas (Sempre Ativas)

Todas as fun√ß√µes matem√°ticas implementam valida√ß√µes cr√≠ticas que est√£o **sempre ativas**, mesmo em Release mode:

- ‚úÖ **Valida√ß√£o de Ponteiros Nulos:** Previne segfaults
- ‚úÖ **Valida√ß√£o de Aliasing:** Previne corrup√ß√£o de dados (input == output)
- ‚úÖ **Valida√ß√£o de Overflow:** Previne wraparound em c√°lculos de √≠ndices
- ‚úÖ **Valida√ß√£o de Alinhamento:** Previne crashes em instru√ß√µes AVX2
- ‚úÖ **Valida√ß√£o de Tipo:** Previne uso incorreto de dados quantizados
- ‚úÖ **Valida√ß√£o de Dimens√µes:** Previne acesso fora dos limites

### Macros de Valida√ß√£o

```c
// Exemplo de uso em fun√ß√µes matem√°ticas
q_error_code q_gemv_q4_f32_avx2(...) {
    Q_VALIDATE_PTR_OR_RETURN(weights, Q_ERR_INVALID_ARG);
    Q_VALIDATE_OR_RETURN(input != output, Q_ERR_ALIASING);
    Q_VALIDATE_MULTIPLE_OR_RETURN(N, 32, Q_ERR_INVALID_SIZE);
    // ... implementa√ß√£o ...
    return Q_OK;
}
```

### C√≥digos de Erro Padronizados

```c
typedef enum {
    Q_OK = 0,
    Q_ERR_INVALID_ARG = -10,      // Argumento inv√°lido
    Q_ERR_ALIASING = -11,         // Aliasing detectado
    Q_ERR_OVERFLOW = -12,         // Overflow detectado
    Q_ERR_MISALIGNED = -13,       // Ponteiro desalinhado
    Q_ERR_INVALID_DTYPE = -14,    // Tipo de dado inv√°lido
    Q_ERR_INVALID_SIZE = -15      // Tamanho inv√°lido
    // ... outros c√≥digos ...
} q_error_code;
```

### Performance

- **Overhead M√≠nimo:** Valida√ß√µes usam `__builtin_expect` para otimizar branch prediction
- **Custo Estimado:** < 1 ciclo por valida√ß√£o quando passa (caso comum)
- **Custo Quando Falha:** Retorno imediato de erro (sem processamento desnecess√°rio)

---

## 7. MELHORIAS DE ROBUSTEZ

### Aritm√©tica de Ponteiros Robusta

**Implementa√ß√£o:** Todas as opera√ß√µes de aritm√©tica de ponteiros usam `size_t` para c√°lculos de offset, garantindo m√°xima robustez mesmo em casos extremos.

**Exemplo em `q_gemv_q4_f32_avx2`:**
```c
// ROBUSTNESS: Use size_t for offset calculations to prevent uint32_t wraparound
const size_t block_base = (size_t)(bg * 4);
const size_t tail_start = (size_t)(num_block_groups * 4);
const size_t row_offset = (size_t)i * (size_t)blocks_per_row;
```

**Benef√≠cios:**
- ‚úÖ Elimina qualquer possibilidade de wraparound em `uint32_t` antes da convers√£o para aritm√©tica de ponteiros
- ‚úÖ Consist√™ncia de tipos em todo o c√≥digo
- ‚úÖ Zero overhead: compilador otimiza igualmente
- ‚úÖ Dupla camada de prote√ß√£o (valida√ß√£o + tipo mais seguro)

### Documenta√ß√£o de Comportamento

**Wrapper P√∫blico para Testes:** Fun√ß√µes p√∫blicas de teste incluem valida√ß√£o NULL e documenta√ß√£o clara do comportamento esperado.

**Exemplo em `q_dequantize_q4_0_block_avx2_public`:**
```c
// ROBUSTNESS: Validate inputs (only in public wrapper, not in hot path)
// This prevents crashes in test scenarios while maintaining zero overhead
// in production code paths that use the inline version directly
if (__builtin_expect(block == NULL || output == NULL, 0)) {
    return; // Silently return - acceptable for test code defensive programming
}
```

**Filosofia:**
- Hot path usa vers√µes inline sem overhead de valida√ß√£o
- Wrappers p√∫blicos para testes incluem valida√ß√£o defensiva
- Comportamento claramente documentado

### Valida√ß√£o de Overflow em M√∫ltiplas Camadas

**Estrat√©gia:** Valida√ß√µes de overflow em m√∫ltiplos pontos cr√≠ticos:

1. **Valida√ß√£o de Dimens√µes:** `Q_VALIDATE_NO_OVERFLOW_OR_RETURN(M, blocks_per_row)`
2. **C√°lculo Seguro de Offset:** Uso de `size_t` para aritm√©tica de ponteiros
3. **Valida√ß√£o de Alinhamento:** `safe_align_size()` previne overflow no alinhamento
4. **Valida√ß√£o de Adi√ß√£o:** `ctx->scratch_head > SIZE_MAX - aligned_size` previne overflow na adi√ß√£o

**Resultado:** M√∫ltiplas camadas de prote√ß√£o garantem robustez m√°xima sem impacto na performance.

---

## 7.5. CHECKPOINTS DE REFATORA√á√ÉO

### Objetivo

**Prevenir ac√∫mulo de d√≠vida t√©cnica** atrav√©s de refatora√ß√£o sistem√°tica em checkpoints estrat√©gicos entre fases, garantindo:
- Qualidade de c√≥digo mantida
- Arquitetura limpa preservada
- Performance mantida
- D√≠vida t√©cnica minimizada
- Retrabalho reduzido

**Princ√≠pio Chave:** Refatorar incrementalmente, n√£o reativamente.

### Quando Refatorar

#### Checkpoints Obrigat√≥rios (Ap√≥s Cada Fase)
- **Ap√≥s FASE 2.5:** Refatorar consist√™ncia de interface de kernels
- **Ap√≥s FASE 3.3:** Refatorar arquitetura do forward pass
- **Ap√≥s FASE 3.5:** Refatorar arquitetura do training loop
- **Ap√≥s FASE 5.0:** Refatorar design da abstra√ß√£o core
- **Ap√≥s FASE 5.1:** Refatorar consist√™ncia de interface de layers
- **Ap√≥s FASE 5.2:** Refatorar arquitetura de layers avan√ßadas
- **Ap√≥s FASE 5.3:** Refatorar estrat√©gia de migra√ß√£o de arquitetura
- **Ap√≥s FASE 5.4:** Refatora√ß√£o final antes de produ√ß√£o

#### Checkpoints Opcionais (Durante Desenvolvimento)
- Quando duplica√ß√£o de c√≥digo √© detectada
- Quando performance degrada inesperadamente
- Quando arquitetura fica confusa
- Quando testes ficam dif√≠ceis de manter

### Procedimento de Checkpoint

#### Fase 1: Avalia√ß√£o (30 minutos)
1. **Revis√£o de C√≥digo:**
   - Revisar todo c√≥digo adicionado na fase
   - Identificar code smells (duplica√ß√£o, complexidade, inconsist√™ncia)
   - Verificar ader√™ncia a padr√µes de codifica√ß√£o
   - Verificar consist√™ncia de tratamento de erros
   - Verificar padr√µes de gerenciamento de mem√≥ria

2. **Revis√£o de Arquitetura:**
   - Verificar separa√ß√£o de responsabilidades
   - Verificar consist√™ncia de interfaces
   - Revisar alinhamento de estruturas de dados
   - Verificar conven√ß√µes de nomenclatura
   - Verificar completude de documenta√ß√£o

3. **Revis√£o de Performance:**
   - Executar benchmarks de performance
   - Comparar com fase anterior
   - Identificar regress√µes de performance
   - Verificar padr√µes de uso de mem√≥ria
   - Verificar conformidade zero-malloc

4. **Revis√£o de Testes:**
   - Verificar cobertura de testes
   - Verificar qualidade de testes
   - Revisar organiza√ß√£o de testes
   - Verificar manutenibilidade de testes
   - Verificar cobertura de testes adversariais

#### Fase 2: Planejamento de Refatora√ß√£o (30 minutos)
1. **Identificar Alvos de Refatora√ß√£o:**
   - Listar code smells a corrigir
   - Identificar melhorias arquiteturais
   - Planejar padroniza√ß√£o de interfaces
   - Identificar otimiza√ß√µes de performance
   - Planejar atualiza√ß√µes de documenta√ß√£o

2. **Priorizar Tarefas de Refatora√ß√£o:**
   - Alta prioridade: Problemas cr√≠ticos
   - M√©dia prioridade: Melhorias importantes
   - Baixa prioridade: Melhorias desej√°veis

3. **Estimar Esfor√ßo de Refatora√ß√£o:**
   - Estimar tempo para cada tarefa
   - Identificar depend√™ncias
   - Planejar sequ√™ncia de refatora√ß√£o
   - Definir limites de tempo (m√°x 1-2 dias por checkpoint)

#### Fase 3: Execu√ß√£o de Refatora√ß√£o (1-2 dias)
1. **Refatora√ß√£o de C√≥digo:**
   - Remover duplica√ß√£o de c√≥digo
   - Simplificar fun√ß√µes complexas
   - Padronizar interfaces
   - Melhorar tratamento de erros
   - Otimizar uso de mem√≥ria

2. **Refatora√ß√£o de Arquitetura:**
   - Melhorar separa√ß√£o de responsabilidades
   - Padronizar estruturas de dados
   - Melhorar conven√ß√µes de nomenclatura
   - Melhorar modularidade
   - Melhorar extensibilidade

3. **Refatora√ß√£o de Performance:**
   - Otimizar hot paths
   - Reduzir aloca√ß√µes de mem√≥ria
   - Melhorar localidade de cache
   - Otimizar uso de SIMD
   - Reduzir overhead de chamadas de fun√ß√£o

4. **Refatora√ß√£o de Testes:**
   - Melhorar organiza√ß√£o de testes
   - Adicionar casos de teste faltantes
   - Melhorar legibilidade de testes
   - Reduzir duplica√ß√£o de testes
   - Melhorar manutenibilidade de testes

#### Fase 4: Valida√ß√£o (1-2 horas)
1. **Valida√ß√£o de C√≥digo:**
   - Executar todos os testes (devem passar)
   - Executar benchmarks de performance (devem manter ou melhorar)
   - Executar sanitizadores de mem√≥ria (devem passar)
   - Executar ferramentas de an√°lise est√°tica
   - Verificar conformidade zero-malloc

2. **Valida√ß√£o de Documenta√ß√£o:**
   - Atualizar coment√°rios de c√≥digo
   - Atualizar documenta√ß√£o de arquitetura
   - Atualizar documenta√ß√£o de API
   - Atualizar documentos de status
   - Atualizar timeline se necess√°rio

3. **Valida√ß√£o de Qualidade:**
   - Verificar m√©tricas de qualidade de c√≥digo
   - Verificar cobertura de testes (deve manter ou melhorar)
   - Verificar m√©tricas de performance
   - Verificar completude de documenta√ß√£o
   - Verificar conclus√£o do checkpoint

### Checklist de Checkpoint

#### Ap√≥s Conclus√£o de Cada Fase

**Qualidade de C√≥digo:**
- [ ] Sem duplica√ß√£o de c√≥digo
- [ ] Fun√ß√µes s√£o focadas e simples
- [ ] Interfaces s√£o consistentes
- [ ] Tratamento de erros √© padronizado
- [ ] Gerenciamento de mem√≥ria est√° correto

**Qualidade de Arquitetura:**
- [ ] Separa√ß√£o de responsabilidades est√° clara
- [ ] Estruturas de dados est√£o bem projetadas
- [ ] Conven√ß√µes de nomenclatura s√£o consistentes
- [ ] Modularidade est√° mantida
- [ ] Extensibilidade est√° preservada

**Qualidade de Performance:**
- [ ] Performance est√° mantida ou melhorada
- [ ] Conformidade zero-malloc verificada
- [ ] Localidade de cache otimizada
- [ ] Uso de SIMD est√° otimizado
- [ ] Sem regress√µes de performance

**Qualidade de Testes:**
- [ ] Cobertura de testes mantida ou melhorada
- [ ] Testes est√£o bem organizados
- [ ] Testes s√£o manuten√≠veis
- [ ] Testes adversariais s√£o abrangentes
- [ ] Todos os testes passam

**Qualidade de Documenta√ß√£o:**
- [ ] Coment√°rios de c√≥digo atualizados
- [ ] Documentos de arquitetura atualizados
- [ ] Documentos de API atualizados
- [ ] Documentos de status atualizados
- [ ] Timeline atualizada se necess√°rio

### Requisitos Espec√≠ficos por Checkpoint

#### Checkpoint: Ap√≥s FASE 2.5 (Kernels de Infer√™ncia Adicionais)
**√Åreas de Foco:**
- Consist√™ncia de interface de kernels
- Padroniza√ß√£o de tratamento de erros
- Otimiza√ß√£o de performance
- Cobertura de testes

**Tarefas Espec√≠ficas:**
- [ ] Padronizar assinaturas de fun√ß√µes de kernel
- [ ] Garantir tratamento de erros consistente
- [ ] Verificar padr√µes de otimiza√ß√£o AVX2
- [ ] Adicionar casos de teste faltantes
- [ ] Atualizar documenta√ß√£o de kernels

**Limite de Tempo:** 1 dia

#### Checkpoint: Ap√≥s FASE 3.3 (Forward Pass)
**√Åreas de Foco:**
- Arquitetura do forward pass
- Integra√ß√£o de layers
- Otimiza√ß√£o de performance
- Propaga√ß√£o de erros

**Tarefas Espec√≠ficas:**
- [ ] Revisar estrutura do forward pass
- [ ] Padronizar integra√ß√£o de layers
- [ ] Otimizar performance do forward pass
- [ ] Melhorar tratamento de erros
- [ ] Adicionar testes de forward pass

**Limite de Tempo:** 1-2 dias

#### Checkpoint: Ap√≥s FASE 3.5 (Training Loop)
**√Åreas de Foco:**
- Arquitetura do training loop
- Integra√ß√£o de optimizer
- Integra√ß√£o de loss function
- Fluxo de gradientes

**Tarefas Espec√≠ficas:**
- [ ] Revisar estrutura do training loop
- [ ] Padronizar interface de optimizer
- [ ] Otimizar performance de treinamento
- [ ] Melhorar fluxo de gradientes
- [ ] Adicionar testes de treinamento

**Limite de Tempo:** 1-2 dias

#### Checkpoint: Ap√≥s FASE 5.0 (Core Abstraction)
**√Åreas de Foco:**
- Interface gen√©rica de layer
- Design de container de modelo
- Implementa√ß√£o de polimorfismo
- Overhead de performance

**Tarefas Espec√≠ficas:**
- [ ] Revisar design de interface gen√©rica
- [ ] Otimizar overhead de function pointers
- [ ] Padronizar interface de layer
- [ ] Verificar zero overhead de performance
- [ ] Adicionar testes de framework

**Limite de Tempo:** 1-2 dias

#### Checkpoint: Ap√≥s FASE 5.1 (Basic Layers)
**√Åreas de Foco:**
- Consist√™ncia de interface de layers
- Qualidade de implementa√ß√£o de layers
- Otimiza√ß√£o de performance
- Cobertura de testes

**Tarefas Espec√≠ficas:**
- [ ] Padronizar implementa√ß√µes de layers
- [ ] Otimizar performance de layers
- [ ] Melhorar tratamento de erros de layers
- [ ] Adicionar testes de layers
- [ ] Atualizar documenta√ß√£o de layers

**Limite de Tempo:** 1 dia

#### Checkpoint: Ap√≥s FASE 5.2 (Advanced Layers)
**√Åreas de Foco:**
- Arquitetura de layers avan√ßadas
- Composi√ß√£o de layers
- Otimiza√ß√£o de performance
- Testes de layers complexas

**Tarefas Espec√≠ficas:**
- [ ] Revisar design de layers avan√ßadas
- [ ] Otimizar composi√ß√£o de layers
- [ ] Melhorar performance de layers complexas
- [ ] Adicionar testes de layers avan√ßadas
- [ ] Atualizar documenta√ß√£o de layers avan√ßadas

**Limite de Tempo:** 1-2 dias

#### Checkpoint: Ap√≥s FASE 5.3 (Architecture Migration)
**√Åreas de Foco:**
- Completude de migra√ß√£o
- Compatibilidade reversa
- Valida√ß√£o de performance
- Limpeza de c√≥digo

**Tarefas Espec√≠ficas:**
- [ ] Verificar completude de migra√ß√£o
- [ ] Remover c√≥digo de arquitetura antiga
- [ ] Validar compatibilidade reversa
- [ ] Verificar performance mantida
- [ ] Limpar c√≥digo n√£o utilizado

**Limite de Tempo:** 1 dia

#### Checkpoint: Ap√≥s FASE 5.4 (Produ√ß√£o Final)
**√Åreas de Foco:**
- Prontid√£o para produ√ß√£o
- Revis√£o final de qualidade de c√≥digo
- Valida√ß√£o final de performance
- Completude de documenta√ß√£o

**Tarefas Espec√≠ficas:**
- [ ] Revis√£o final de c√≥digo
- [ ] Valida√ß√£o final de performance
- [ ] Revis√£o final de cobertura de testes
- [ ] Completar documenta√ß√£o
- [ ] Checklist de prontid√£o para produ√ß√£o

**Limite de Tempo:** 2 dias

### M√©tricas para Acompanhar

#### M√©tricas de Qualidade de C√≥digo
- **Complexidade Ciclom√°tica:** Deve diminuir ou permanecer est√°vel
- **Duplica√ß√£o de C√≥digo:** Deve diminuir
- **Comprimento de Fun√ß√£o:** Deve permanecer razo√°vel (< 100 linhas)
- **Cobertura de Coment√°rios:** Deve manter ou melhorar

#### M√©tricas de Performance
- **Lat√™ncia de Infer√™ncia:** Deve manter ou melhorar
- **Throughput de Treinamento:** Deve manter ou melhorar
- **Uso de Mem√≥ria:** Deve manter ou diminuir
- **Conformidade Zero-Malloc:** Deve ser 100%

#### M√©tricas de Qualidade de Testes
- **Cobertura de Testes:** Deve manter ou melhorar
- **Taxa de Passagem de Testes:** Deve ser 100%
- **Tempo de Execu√ß√£o de Testes:** Deve permanecer razo√°vel
- **Cobertura de Testes Adversariais:** Deve manter ou melhorar

### Crit√©rios de Sucesso

**Checkpoint √© Bem-Sucedido Quando:**
- [ ] Todos os testes passam
- [ ] Performance est√° mantida ou melhorada
- [ ] M√©tricas de qualidade de c√≥digo melhoram ou permanecem est√°veis
- [ ] Documenta√ß√£o est√° atualizada
- [ ] D√≠vida t√©cnica est√° reduzida
- [ ] Arquitetura est√° mais limpa
- [ ] C√≥digo est√° mais manuten√≠vel

**Documenta√ß√£o Detalhada:** Ver `docs/REFACTORING_CHECKPOINTS.md` para procedimentos completos de checkpoint.

---

## 8. PR√ìXIMOS PASSOS

### ‚úÖ Implementa√ß√£o Completa: FASE 2.5 (Inference Kernels)

**Status:** ‚úÖ **COMPLETA** (2025-12-31)

Todos os kernels cr√≠ticos foram implementados, testados e validados:
1. ‚úÖ MatMul FP32 AVX2
2. ‚úÖ Causal Masking AVX2
3. ‚úÖ Tensor Add AVX2
4. ‚úÖ Element-wise Mul AVX2

**Pr√≥ximo Passo:** Completar integra√ß√£o no forward pass (FASE 3.3)

### Implementa√ß√£o Futura: FASE 2.6 (Training Kernels)

Para implementar capacidade de treinamento:

> **"Atue como Qorus-Architect. Vamos implementar a FASE 2.6. Comece com os Optimizers seguindo o planejamento completo em `docs/TRAINING_CAPABILITY_PLAN.md`. Use o framework MFR + CoT + Mathematical Proof + TDD conforme `docs/.cursorrules`."**

**Ordem de Implementa√ß√£o Recomendada:**
1. Optimizers (Adam, AdamW) - Base para treinamento
2. Loss Functions (MSE, CrossEntropy) - Necess√°rio para backward
3. Gradient Clipping - Estabiliza√ß√£o de treinamento
4. Backward Pass (FASE 3.4) - Propaga√ß√£o de gradientes
5. Training Loop (FASE 3.5) - Loop completo de treinamento

### Implementa√ß√£o Futura: FASE 5.0+ (Generic Framework v3.0)

Para transformar QorusIA em framework gen√©rico sem limita√ß√µes:

> **"Atue como Qorus-Architect. Vamos implementar a FASE 5.0. Comece com a Generic Layer Interface seguindo o planejamento completo em `docs/GENERIC_FRAMEWORK_PLAN.md`. Use o framework MFR + CoT + Mathematical Proof + TDD conforme `docs/.cursorrules`."**

**Ordem de Implementa√ß√£o Recomendada:**
1. FASE 5.0: Core Abstraction (Generic Layer Interface, Model Container)
2. FASE 5.1: Basic Layers (Linear, Activation, Normalization, Softmax)
3. FASE 5.2: Advanced Layers (MHA, FFN, Transformer Block, Embedding)
4. FASE 5.3: Example Model Builders (demonstrar uso do framework gen√©rico)
5. FASE 5.4: Additional Architectures (MLP, CNN, RNN - futuro)

### Comando Inicial (Para Novos Desenvolvedores)

Para come√ßar do zero, pe√ßa ao Cursor:

> **"Atue como Qorus-Architect. Vamos iniciar a Fase 1. Primeiro, crie a estrutura de diret√≥rios e os arquivos de cabe√ßalho `include/qorus_types.h` e `include/qorus.h` com as defini√ß√µes de Tensor e Contexto conforme o Blueprint v2.0."**

Isso garante que o projeto comece com a estrutura correta.

---

## 9. REFER√äNCIAS DE PLANEJAMENTO

**Documentos Executivos:**
- `docs/PROJECT_VISION.md` - **Vis√£o completa do projeto (in√≠cio ‚Üí atual ‚Üí fim)**
- `docs/TIMELINE.md` - **Timeline de desenvolvimento com estimativas e depend√™ncias**
- `docs/INDEX.md` - **√çndice mestre da documenta√ß√£o - guia de navega√ß√£o**

**Documentos de Planejamento (FASE 2.5 - Inference Kernels):**
- `docs/KERNEL_PORTATION_PLAN.md` - Plano completo de porta√ß√£o seguindo MFR + CoT + Mathematical Proof + TDD
- `docs/KERNEL_IMPLEMENTATION_DETAILS.md` - Guia de implementa√ß√£o com c√≥digo completo e exemplos
- `docs/PLANNING_SUMMARY.md` - Resumo executivo do planejamento

**Documentos de Planejamento (FASE 2.6 - Training Capability):**
- `docs/TRAINING_CAPABILITY_PLAN.md` - Plano completo de capacidade de treinamento (MFR + CoT + Proof + TDD)

**Documentos de Planejamento (FASE 5.0+ - Generic Framework v3.0):**
- `docs/GENERIC_FRAMEWORK_PLAN.md` - **Plano completo de framework gen√©rico (MFR + CoT + Proof + TDD)**

**Documenta√ß√£o de Qualidade:**
- `docs/REFACTORING_CHECKPOINTS.md` - **Procedimentos de checkpoint de refatora√ß√£o e garantia de qualidade**

**Documenta√ß√£o T√©cnica:**
- `docs/STATUS.md` - Status detalhado do projeto
- `docs/QUICK_REFERENCE.md` - Refer√™ncia r√°pida
- `docs/FASE_3.3_ANALYSIS.md` - An√°lise do forward pass
- `docs/PRECISION_STANDARDS.md` - Padr√µes de precis√£o num√©rica
- `docs/ASYMPTOTIC_ANALYSIS.md` - An√°lise assint√≥tica
- `docs/.cursorrules` - Metodologia de desenvolvimento (MFR + CoT + Proof + TDD)

