# üèõÔ∏è QORUS-IA v3.0: MASTER BLUEPRINT
# Generic Deep Learning Framework

**Entendido. Voc√™ quer o Blueprint de Execu√ß√£o. Sem teoria desnecess√°ria, apenas a engenharia pura para o Cursor executar.**

Aqui est√° a Arquitetura Definitiva do Qorus-IA v3.0. Copie este contexto para o Cursor e ele saber√° exatamente o que fazer.

## Objetivo
Framework Gen√©rico de Deep Learning em C Puro - Sem Limita√ß√µes Arquiteturais.

**Evolu√ß√£o:**
- **v2.0:** Engine especializado (infer√™ncia otimizada)
- **v3.0:** Framework gen√©rico (qualquer arquitetura) mantendo performance e arquitetura limpa

**Prioridades:** Performance (zero-malloc, AVX2), Flexibilidade (qualquer arquitetura), Arquitetura Limpa (valida√ß√µes robustas).

**Restri√ß√£o:** Zero-Malloc no Hot Path (mantido).

---

## 1. ESTRUTURA DE DIRET√ìRIOS (File System)

Esta organiza√ß√£o separa infraestrutura, matem√°tica e l√≥gica de modelo.

```
qorus-ia/
‚îú‚îÄ‚îÄ include/
‚îÇ   ‚îú‚îÄ‚îÄ qorus.h             # Header √önico P√∫blico (API)
‚îÇ   ‚îî‚îÄ‚îÄ qorus_types.h       # Structs e Enums fundamentais
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ core/               # Infraestrutura de Baixo N√≠vel
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ memory.c        # Arena, Aligned Malloc, Mmap
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tensor.c        # Manipula√ß√£o de Metadados de Tensor
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils.c         # Timing, Logging, SIMD detection
‚îÇ   ‚îú‚îÄ‚îÄ ops/                # Kernels Matem√°ticos (Otimizados)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cpu/            # Fallbacks em C puro (Refer√™ncia)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ avx2/           # Kernels AVX2 (MatMul Q4, MatMul FP32, RoPE, RMSNorm, Add, Mul, Causal Mask, Loss, Clip)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ cuda/           # Kernels CUDA (Para Google Colab / GPU) - FUTURO
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ q_cuda_utils.cu  # Gerenciamento de mem√≥ria GPU
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ matmul.cu        # Calls to cuBLAS
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ rope.cu          # Custom Kernel
‚îÇ   ‚îú‚îÄ‚îÄ optim/              # Optimizers (Training) - NEW
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ optimizer.c     # Base optimizer interface
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ adam.c          # Adam/AdamW optimizer
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scheduler.c     # Learning rate scheduling
‚îÇ   ‚îú‚îÄ‚îÄ layers/             # Camadas Gen√©ricas (Framework v3.0)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ linear.c        # Linear layer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ activation.c    # Activation layers
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ normalization.c # Normalization layers
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mha.c           # Multi-Head Attention
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ffn.c           # Feed-Forward Network
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ transformer_block.c  # Transformer Block
‚îÇ   ‚îú‚îÄ‚îÄ models/             # Model Builders (Exemplos)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ example_models.c  # Exemplos de modelos usando framework gen√©rico
‚îÇ   ‚îî‚îÄ‚îÄ tokenizer/          # Processamento de Texto
‚îÇ       ‚îî‚îÄ‚îÄ dummy_tokenizer.c  # Dummy Tokenizer (Testing Only - NOT real BPE)
‚îú‚îÄ‚îÄ tools/
‚îÇ   ‚îî‚îÄ‚îÄ convert_model.py    # Script Python: Model Format -> Qorus Binary (Zero-Parse)
‚îú‚îÄ‚îÄ tests/                  # Testes Unit√°rios e de Integra√ß√£o
‚îî‚îÄ‚îÄ Makefile                # Build System (-O3 -mavx2)
```

---

## 2. ARQUITETURA DE DADOS (Memory Layout)

O Cursor deve implementar estas estruturas exatamente como definidas para garantir alinhamento e performance.

### 2.1. Tipos e Tensores (include/qorus_types.h)

**Nota de Seguran√ßa:** Todas as fun√ß√µes matem√°ticas agora retornam `q_error_code` e validam inputs em Release mode usando macros otimizadas (`Q_VALIDATE_OR_RETURN`, `Q_VALIDATE_PTR_OR_RETURN`, etc.).

```c
#include <stdint.h>
#include <stdbool.h>

// Alinhamento obrigat√≥rio para AVX2/AVX-512
#define Q_ALIGN 64

typedef enum {
    Q_F32  = 0,
    Q_Q8_0 = 1, // Pesos (Embeddings/Output)
    Q_Q4_0 = 2  // Pesos (Dense Layers)
} q_dtype;

// Device type (CPU or GPU) - NEW for CUDA support
typedef enum {
    Q_DEVICE_CPU = 0,
    Q_DEVICE_CUDA = 1
} q_device_type;

// Tensor View (N√£o possui a mem√≥ria, apenas aponta)
typedef struct {
    void*     data;         // Ponteiro para dados (Mmap, Arena, ou GPU)
    float*    scales;       // Ponteiro para escalas (se quantizado)
    uint32_t  ne[4];        // Dimens√µes: [Batch, Head, Seq, Dim]
    size_t    nb[4];        // Strides em bytes
    q_dtype   type;         // Tipo de dado
    q_device_type device;  // NEW: CPU ou CUDA (para sele√ß√£o autom√°tica de kernel)
    char      name[32];     // Debugging
} __attribute__((aligned(Q_ALIGN))) q_tensor;

// Contexto Global de Mem√≥ria
typedef struct {
    // Tier 1: Weights (Read-Only)
    void* weights_mmap;     // CPU: mmap, GPU: NULL (pesos ficam em GPU)
    size_t weights_size;
    
    // Tier 2: KV Cache (Persistent)
    void* kv_buffer;        // CPU: aligned_alloc, GPU: cudaMalloc
    size_t kv_size;
    q_device_type kv_device;  // NEW: Onde est√° o KV cache
    
    // Tier 3: Scratchpad (Transient)
    void* scratch_buffer;   // CPU: aligned_alloc, GPU: cudaMalloc
    size_t scratch_size;
    size_t scratch_head;    // Posi√ß√£o atual na Arena
    q_device_type scratch_device;  // NEW: Onde est√° o scratchpad
    
    // NEW: CUDA context (se dispon√≠vel)
    void* cuda_context;     // NULL se n√£o usar CUDA
} q_context;
```

---

## 3. ESTRAT√âGIA DE MEM√ìRIA (The 3 Arenas)

O Cursor deve seguir estritamente esta l√≥gica de aloca√ß√£o.

### Weights (Read-Only):
- **Origem:** mmap de arquivo bin√°rio pr√©-formatado.
- **Acesso:** Ponteiros `q_tensor.data` apontam diretamente para endere√ßos virtuais do mmap.
- **Custo:** Zero copy.

### KV Cache (Persistent):
- **Aloca√ß√£o:** `aligned_alloc` √∫nico na inicializa√ß√£o.
- **Layout:** Cont√≠guo `[n_layers, n_kv_heads, max_seq, head_dim]`.
- **Acesso:** Aritm√©tica de ponteiros simples. Sem indire√ß√£o.

### Scratchpad (Transient):
- **Aloca√ß√£o:** `aligned_alloc` √∫nico na inicializa√ß√£o (ex: 512MB).
  - **CPU:** `aligned_alloc` (como antes)
  - **CUDA:** `cudaMalloc` (zero-malloc mantido no hot path)
- **Uso:** Ativa√ß√µes intermedi√°rias (sa√≠da de MatMul, Softmax).
- **Ciclo:** `scratch_head` √© resetado para 0 no in√≠cio de cada token gerado.
- **Regra:** NUNCA dar `free()` em tensores individuais aqui.

### Adapta√ß√£o para CUDA (FASE 2.7 - Planejamento):

**Estrat√©gia de Mem√≥ria GPU:**
- **Weights:** Transferir do mmap para GPU na inicializa√ß√£o (uma vez)
- **KV Cache:** Pode ficar em GPU ou CPU (configur√°vel)
- **Scratchpad:** Usar `cudaMalloc` normal (zero-malloc mantido)
- **Pinned Memory:** Apenas para buffers persistentes (Tier 2), n√£o no hot path

**Problema do mmap no Google Drive:**
- Google Drive usa fuse filesystem (muito lento para mmap)
- **Solu√ß√£o:** Detectar fuse e copiar modelo para `/tmp` antes de mmap
- Implementado em `q_init_memory_smart()` (FASE 2.7)

---

## 4. ROTEIRO DE IMPLEMENTA√á√ÉO (Step-by-Step)

**ORDEM CORRETA DE IMPLEMENTA√á√ÉO:** Execute as fases nesta ordem exata. N√£o avance sem validar crit√©rios objetivos.

**Estrutura do Roteiro:**
- **PARTE 1:** Infer√™ncia (FASE 1-4) - Sistema completo de infer√™ncia
- **PARTE 2:** Treinamento (FASE 2.6-3.5) - Capacidade de treinamento
- **PARTE 3:** Framework Gen√©rico (FASE 5.0+) - Evolu√ß√£o para v3.0

---

## PARTE 1: INFER√äNCIA (v2.0) - Sistema Completo de Infer√™ncia

**Objetivo:** Sistema completo de infer√™ncia funcional, do carregamento de modelo at√© gera√ß√£o de texto.

---

### ‚úÖ FASE 1: Infraestrutura & Conversor (A Base) - **COMPLETA**

**Objetivo:** Conseguir carregar pesos do disco sem parsing.

**Implementa√ß√£o:**
- ‚úÖ **Passo 1.1 (Python):** `tools/convert_llama.py` criado. Gera arquivo `.qorus` com header fixo e tensores alinhados a 64 bytes.
- ‚úÖ **Passo 1.2 (C):** `src/core/memory.c` implementado (mmap, arena). `src/core/tensor.c` implementado (cria√ß√£o de views).
- ‚úÖ **Valida√ß√£o:** Testes de mem√≥ria validados. Carregamento de modelo dummy funcionando.

**Crit√©rios Objetivos de Qualidade (FASE 1):**
- ‚úÖ **Testes:** 100% pass rate em todos os testes de mem√≥ria e tensor
- ‚úÖ **Zero-Malloc:** Nenhuma aloca√ß√£o din√¢mica no hot path (apenas inicializa√ß√£o)
- ‚úÖ **Alinhamento:** Todos os buffers alinhados a 64 bytes (verificado com `_Static_assert`)
- ‚úÖ **Valida√ß√£o:** Modelo dummy carregado e validado com sucesso
- ‚úÖ **Sanitizers:** AddressSanitizer e MemorySanitizer passam sem erros

**Checkpoint de Refatora√ß√£o (Ap√≥s FASE 1):**
- ‚úÖ **Status:** Conclu√≠do
- ‚úÖ **√Åreas Verificadas:**
  - Consist√™ncia de alinhamento de mem√≥ria
  - Padroniza√ß√£o de tratamento de erros em `memory.c`
  - Valida√ß√£o de mmap e arena allocation
- ‚úÖ **M√©tricas:** Zero regress√µes de performance, todos os testes passando

---

### ‚úÖ FASE 2: Kernels Matem√°ticos B√°sicos (O Motor) - **COMPLETA**

**Objetivo:** Opera√ß√µes vetoriais r√°pidas com valida√ß√£o robusta.

**Implementa√ß√£o:**
- ‚úÖ **Passo 2.1:** `src/ops/avx2/dequantize.c` implementado. Q4_0 ‚Üí 32 floats em YMM, FMA-optimized.
- ‚úÖ **Passo 2.2:** `src/ops/avx2/matmul.c` implementado. GEMV Q4_F32 com dequantiza√ß√£o fundida, 4x unrolling.
  - ‚úÖ **Valida√ß√£o de Contiguidade (2025-01-02):** Valida√ß√£o cr√≠tica de que tensor √© cont√≠guo em mem√≥ria antes de execu√ß√£o
    - Valida `nb[0] == expected_stride` para prevenir leitura de mem√≥ria inv√°lida
    - Falha com erro claro se tensor n√£o for cont√≠guo (v1.0 limitation)
    - Documenta√ß√£o clara de limita√ß√£o arquitetural
- ‚úÖ **Passo 2.3:** `src/ops/avx2/rope.c` e `src/ops/avx2/rmsnorm.c` implementados.
- ‚úÖ **Passo 2.4:** `src/ops/avx2/silu.c` e `src/ops/avx2/softmax.c` implementados. Utilit√°rios matem√°ticos em `avx_math.h`.
- ‚úÖ **Passo 2.5:** **Seguran√ßa Implementada** - Todas as fun√ß√µes matem√°ticas agora retornam `q_error_code` e validam inputs em Release mode:
  - Valida√ß√£o de ponteiros nulos
  - Valida√ß√£o de aliasing (input == output)
  - Valida√ß√£o de overflow
  - Valida√ß√£o de alinhamento
  - Valida√ß√£o de tipo de dados
  - Valida√ß√£o de dimens√µes (m√∫ltiplos de 8/32)
  - Macros de valida√ß√£o otimizadas com `__builtin_expect` para overhead m√≠nimo

**Crit√©rios Objetivos de Qualidade (FASE 2):**
- ‚úÖ **Testes:** 100% pass rate em todos os testes de kernel
- ‚úÖ **Precis√£o Num√©rica:** Max absolute difference < 1e-5, Max relative difference < 1e-4 (FP32)
- ‚úÖ **Valida√ß√£o:** Todos os kernels validados contra refer√™ncias NumPy/PyTorch
- ‚úÖ **Zero-Malloc:** Nenhuma aloca√ß√£o din√¢mica no hot path
- ‚úÖ **Performance:** Benchmarks mantidos ou melhorados vs refer√™ncia
- ‚úÖ **Sanitizers:** AddressSanitizer, MemorySanitizer, UndefinedBehaviorSanitizer passam
- ‚úÖ **Valida√ß√£o de Erros:** Todos os c√≥digos de erro testados e documentados

**Checkpoint de Refatora√ß√£o (Ap√≥s FASE 2):**
- ‚úÖ **Status:** Conclu√≠do
- ‚úÖ **√Åreas Verificadas:**
  - Consist√™ncia de interface de kernels (assinaturas padronizadas)
  - Tratamento de erros consistente (`q_error_code` em todas as fun√ß√µes)
  - Padr√µes de otimiza√ß√£o AVX2 verificados
- ‚úÖ **M√©tricas:** Zero regress√µes, performance mantida, todos os testes passando

---

### ‚úÖ FASE 2.5: Kernels Adicionais (MetaIA Portation) - **COMPLETA**

**Objetivo:** Portar kernels cr√≠ticos do MetaIA v1.4.0 para completar o forward pass.

**Status:** ‚úÖ **COMPLETA** (2025-12-31). Todos os kernels implementados, testados e validados.

**Kernels Implementados:**
- ‚úÖ **MatMul FP32 AVX2** (`q_matmul_f32_avx2`)
  - **Arquivo:** `src/ops/avx2/matmul_fp32.c`
  - **Testes:** `tests/test_matmul_f32.c`
  - **Uso:** Q @ K^T (attention scores), probs @ V (attention output), LM Head projection
  - **Complexidade:** O(M √ó N √ó K)
  - **Status:** Implementado, testado e validado
  - **Caracter√≠sticas:**
    - Cache-blocked matrix multiplication
    - 4x accumulator unrolling
    - Manual prefetching
    - Transpose B for cache efficiency

- ‚úÖ **Causal Masking AVX2** (`q_causal_mask_f32_avx2`)
  - **Arquivo:** `src/ops/avx2/causal_mask_fp32.c`
  - **Testes:** `tests/test_causal_mask_f32.c`
  - **Uso:** Attention triangular mask (prevent future tokens from attending to past)
  - **Complexidade:** O(N¬≤)
  - **Status:** Implementado, testado e validado
  - **Caracter√≠sticas:**
    - Vectorized upper triangular masking
    - AVX2 stores for efficiency
    - In-place operation

- ‚úÖ **Tensor Add AVX2** (`q_add_f32_avx2`)
  - **Arquivo:** `src/ops/avx2/add_fp32.c`
  - **Testes:** `tests/test_add_f32.c`
  - **Uso:** Residual connections (`x = x + attn_out`)
  - **Complexidade:** O(N)
  - **Status:** Implementado, testado, validado e code-reviewed
  - **Caracter√≠sticas:**
    - 4x unrolling (32 elements per iteration)
    - AVX2 vectorized addition
    - In-place operation support (output may alias input)

- ‚úÖ **Element-wise Mul AVX2** (`q_mul_f32_avx2`)
  - **Arquivo:** `src/ops/avx2/mul_fp32.c`
  - **Testes:** `tests/test_mul_f32.c`
  - **Uso:** SwiGLU activation (`gate * up` in MLP)
  - **Complexidade:** O(N)
  - **Status:** Implementado, testado, validado e code-reviewed
  - **Caracter√≠sticas:**
    - 4x unrolling (32 elements per iteration)
    - AVX2 vectorized multiplication
    - In-place operation support

**Crit√©rios Objetivos de Qualidade (FASE 2.5):**
- ‚úÖ **Testes:** 100% pass rate (Release + Debug with sanitizers)
- ‚úÖ **Precis√£o Num√©rica:** Max absolute difference < 1e-5, Max relative difference < 1e-4 (FP32)
- ‚úÖ **Code Review:** Completado (First Principles Thinking + CoT)
- ‚úÖ **Edge Cases:** Tratados (NULL inputs, shape mismatches, alignment)
- ‚úÖ **Opera√ß√µes In-Place:** Suportadas (safe aliasing)
- ‚úÖ **Valida√ß√£o de Precis√£o:** Max diff < 1e-5 para FP32
- ‚úÖ **Valida√ß√£o de Mem√≥ria:** AddressSanitizer clean
- ‚úÖ **Valida√ß√£o:** Todos os kernels validados contra refer√™ncias NumPy

**Checkpoint de Refatora√ß√£o (Ap√≥s FASE 2.5):**
- ‚úÖ **Status:** Conclu√≠do
- ‚úÖ **√Åreas Verificadas:**
  - Consist√™ncia de interface de kernels (assinaturas padronizadas)
  - Padroniza√ß√£o de tratamento de erros
  - Otimiza√ß√£o de performance AVX2 verificada
  - Cobertura de testes completa
- ‚úÖ **M√©tricas:** Zero regress√µes, performance mantida ou melhorada, todos os testes passando

**Documenta√ß√£o:**
- `docs/KERNEL_PORTATION_PLAN.md` - Plano completo seguindo MFR + CoT + Mathematical Proof + TDD (Status: ‚úÖ COMPLETA)
- `docs/KERNEL_IMPLEMENTATION_DETAILS.md` - Guia de implementa√ß√£o com c√≥digo completo
- `docs/PLANNING_SUMMARY.md` - Resumo executivo do planejamento

---

### ‚úÖ D√≠vida T√©cnica de Baixa Prioridade - **COMPLETA**

**Objetivo:** Estabelecer base s√≥lida de testes, benchmarking e documenta√ß√£o antes de avan√ßar para forward pass.

**Implementa√ß√£o:**
- ‚úÖ **Testes de Utilit√°rios:**
  - `test_utils.c` - 23 testes para `q_strerror()` (valida√ß√£o O(1), todos os c√≥digos de erro)
  - `test_avx_math.c` - 13 testes para utilit√°rios AVX (`exp_approx_avx`, `horizontal_sum_avx`, `horizontal_max_avx`)
  - Toler√¢ncias ajustadas com justificativa matem√°tica para aproxima√ß√£o polinomial

- ‚úÖ **Ferramenta de Benchmark:**
  - `tools/benchmark.c` - Benchmarks end-to-end para todos os kernels AVX2
  - Mede lat√™ncia (ms), throughput (ops/s), e GFLOPS (para MatMul)
  - Inclui warmup iterations para medi√ß√µes precisas

- ‚úÖ **Documenta√ß√£o T√©cnica:**
  - `docs/ASYMPTOTIC_ANALYSIS.md` - An√°lise assint√≥tica completa de todas as fun√ß√µes cr√≠ticas
  - `docs/ASSEMBLY_ANALYSIS.md` - Guia para an√°lise de c√≥digo assembly gerado
  - `tools/analyze_assembly.sh` - Script automatizado para an√°lise de assembly
  - `docs/PRECISION_STANDARDS.md` - Atualizado com justificativas t√©cnicas das toler√¢ncias

**Crit√©rios Objetivos de Qualidade:**
- ‚úÖ **Cobertura de Testes:** Todos os utilit√°rios testados (100% pass rate)
- ‚úÖ **Benchmarks:** Ferramenta funcional e validada
- ‚úÖ **Documenta√ß√£o:** An√°lise assint√≥tica completa para todas as fun√ß√µes cr√≠ticas

---

### ‚úÖ FASE 3: Model Graph Building (O Corpo) - **PARCIALMENTE COMPLETA**

**Objetivo:** Conectar os kernels na ordem correta usando framework gen√©rico.

**Implementa√ß√£o:**
- ‚úÖ **Passo 3.1:** Definir estruturas gen√©ricas em `qorus_types.h`.  
  **Status:** Estruturas definidas e validadas com `_Static_assert`.

- ‚úÖ **Passo 3.2:** Implementar `q_model_build_graph()`. Configurar ponteiros dos tensores baseados no arquivo mmap.
  **Status:** Implementado e testado (31 testes, 100% pass rate).
  - Zero-copy tensor views
  - Valida√ß√£o completa de configura√ß√£o
  - Suporte a Q4_0 e FP32
  - Testes adversarial completos

- ‚úÖ **Passo 3.3:** Implementar `llama_forward()`. Orquestrar passagem dos dados pelos kernels usando framework gen√©rico.
  **Status:** ‚úÖ **COMPLETA** (2025-01-02)
  **Depend√™ncias:** ‚úÖ Todas resolvidas (FASE 2.5 completa)
    - ‚úÖ MatMul FP32 AVX2 (Q @ K^T, probs @ V, projection layers)
    - ‚úÖ Causal Masking AVX2 (attention mask)
    - ‚úÖ Tensor Add AVX2 (residual connections)
    - ‚úÖ Element-wise Mul AVX2 (SwiGLU activation)
  **Implementa√ß√£o Completa:**
    - ‚úÖ Estrutura do forward pass completa
    - ‚úÖ KV cache helper implementado (`get_kv_cache_ptr`)
    - ‚úÖ MLP forward pass completo (SwiGLU)
    - ‚úÖ Layer forward pass completo (attention + MLP com residuals)
    - ‚úÖ Attention forward pass completo (Q/K/V projections, RoPE, KV cache, causal mask, softmax)
    - ‚úÖ Final RMSNorm implementado
    - ‚úÖ LM Head projection implementado (transposed view)
    - ‚úÖ Token embedding lookup implementado
    - ‚úÖ Valida√ß√µes de seguran√ßa implementadas
    - ‚úÖ Estrutura `q_llama_layer` definida e integrada
    - ‚úÖ Corre√ß√£o de alinhamento em softmax (buffers alinhados para cada linha)
    - ‚úÖ Debug aprimorado em valida√ß√µes de alinhamento (`Q_VALIDATE_ALIGNED_OR_RETURN`)
  **Testes:** ‚úÖ Todos passando (14 testes unit√°rios + 19 testes adversariais, 100% pass rate)
    - ‚úÖ Forward pass b√°sico (single token, multiple tokens)
    - ‚úÖ Gera√ß√£o incremental (pos > 0)
    - ‚úÖ Valida√ß√£o de logits (finite, shape correto)
    - ‚úÖ Tratamento de erros (NULL pointers, invalid sizes, invalid positions)
    - ‚úÖ Testes adversariais completos (19 testes, 100% pass rate):
      - ‚úÖ NULL pointer attacks
      - ‚úÖ Edge cases (empty sequences, invalid token IDs)
      - ‚úÖ Memory safety (buffer overflows, double-free)
      - ‚úÖ Large sequences (seq_len = 100)
      - ‚úÖ Misaligned memory attacks
      - ‚úÖ Corrupted model data
      - ‚úÖ Numerical stability attacks

**Crit√©rios Objetivos de Qualidade (FASE 3.3):**
- ‚úÖ **Testes:** 100% pass rate (14 testes unit√°rios + 19 testes adversariais)
- ‚úÖ **Valida√ß√£o:** Forward pass completo validado end-to-end
- ‚úÖ **Zero-Malloc:** Nenhuma aloca√ß√£o din√¢mica no hot path (apenas arena)
- ‚úÖ **Valida√ß√£o de Erros:** Todos os c√≥digos de erro testados e documentados
- ‚úÖ **Sanitizers:** AddressSanitizer, MemorySanitizer passam sem erros
- ‚úÖ **Alinhamento:** Todos os buffers alinhados a 32 bytes (verificado)
- ‚úÖ **Performance:** Benchmarks mantidos ou melhorados

**Checkpoint de Refatora√ß√£o (Ap√≥s FASE 3.3):**
- ‚úÖ **Status:** Conclu√≠do
- ‚úÖ **√Åreas Verificadas:**
  - Arquitetura do forward pass revisada
  - Integra√ß√£o de layers padronizada
  - Performance do forward pass otimizada
  - Tratamento de erros melhorado
  - Testes de forward pass completos
- ‚úÖ **M√©tricas:** Zero regress√µes, performance mantida, todos os testes passando
- ‚úÖ **Limite de Tempo:** 1-2 dias (conclu√≠do)

**Nota:** Framework gen√©rico permite qualquer arquitetura, n√£o apenas Transformers.

---

### ‚úÖ FASE 4: Tokenizer & Loop (A Vida) - **COMPLETA**

**Objetivo:** Texto entra, texto sai.

**Implementa√ß√£o:**
- ‚úÖ **Passo 4.1:** Implementar `src/tokenizer/dummy_tokenizer.c`. Carregar `tokenizer.bin` (extra√≠do do modelo original).
  - **Status:** ‚úÖ **COMPLETA** (2025-01-02) - **ATUALIZADO** (2025-01-02)
  - **Arquivos Implementados:**
    - `src/tokenizer/dummy_tokenizer.c` - Dummy Tokenizer para testes (350+ linhas)
    - **‚ö†Ô∏è IMPORTANTE:** Este √© um **Dummy Tokenizer** (N√ÉO implementa BPE real)
    - **Limita√ß√µes:**
      - N√£o implementa algoritmo BPE (Byte Pair Encoding)
      - Mapeia bytes diretamente para token IDs (byte value = token ID se < vocab_size)
      - N√£o usa regras de merge carregadas do arquivo tokenizer
    - **Casos de Uso:**
      - Testes de infraestrutura com inputs pr√©-tokenizados
      - Desenvolvimento/debugging com tokens byte-level
      - **N√ÉO adequado para infer√™ncia em produ√ß√£o com modelos Transformer reais**
    - **Para Produ√ß√£o:**
      - Implementar algoritmo BPE completo (aplica√ß√£o greedy de merges)
      - Ou usar inputs pr√©-tokenizados de tokenizer externo
    - `include/qorus_types.h` - Estruturas `q_tokenizer` e `q_bpe_merge`
    - `include/qorus.h` - API p√∫blica completa
    - `tools/convert_llama.py` - Fun√ß√£o `write_tokenizer()` para exporta√ß√£o
    - `tests/test_tokenizer.c` - Testes completos (Release + Debug)
    - `examples/hello_world.c` - Exemplo funcional "Hello World"
  - **Estruturas de Dados:**
    ```c
    typedef struct {
        char** vocab;              // Array de token strings [vocab_size]
        uint32_t vocab_size;       // Tamanho do vocabul√°rio
        q_bpe_merge* merges;       // Array de regras BPE [num_merges]
        uint32_t num_merges;       // N√∫mero de merges BPE
        uint32_t bos_token_id;     // Beginning of sequence token ID
        uint32_t eos_token_id;     // End of sequence token ID
        uint32_t pad_token_id;     // Padding token ID
        bool initialized;          // Flag de inicializa√ß√£o
    } q_tokenizer;
    ```
  - **Formato Bin√°rio:**
    - **Header (32 bytes):** Magic (4B), Version (4B), vocab_size (4B), num_merges (4B), bos_id (4B), eos_id (4B), pad_id (4B), reserved (4B)
    - **Vocab Section:** Para cada token: length (1B) + token_bytes (N bytes)
    - **Merges Section:** Para cada merge: token_id1 (4B) + token_id2 (4B) + merged_id (4B)
  - **API P√∫blica:**
    - `q_tokenizer_load()` - Carrega tokenizer de arquivo bin√°rio
    - `q_tokenizer_encode()` - Converte texto ‚Üí tokens (com suporte a BOS/EOS)
    - `q_tokenizer_decode()` - Converte tokens ‚Üí texto
    - `q_tokenizer_free()` - Libera recursos do tokenizer
  - **Funcionalidades:**
    - ‚úÖ Carregamento de tokenizer bin√°rio (formato customizado)
    - ‚úÖ Encode: texto ‚Üí tokens (com suporte a BOS/EOS)
    - ‚úÖ Decode: tokens ‚Üí texto
    - ‚úÖ Vocabul√°rio base: 256 tokens (bytes 0-255) + 3 tokens especiais (BOS=256, EOS=257, PAD=258)
    - ‚úÖ Valida√ß√µes de seguran√ßa implementadas (Q_VALIDATE_PTR_OR_RETURN, etc.)
    - ‚úÖ Gerenciamento de mem√≥ria seguro (cleanup em caso de erro)
  - **Complexidade:**
    - Load: O(V + M) onde V=vocab_size, M=num_merges
    - Encode: O(T) onde T=text_length (mapeamento direto byte‚Üítoken, sem BPE merges)
    - Decode: O(N) onde N=num_tokens
  - **‚ö†Ô∏è Limita√ß√£o Cr√≠tica:**
    - O tokenizer atual √© um **placeholder** que n√£o implementa BPE real
    - Para produ√ß√£o com modelos Transformer reais, √© necess√°rio implementar algoritmo BPE completo
    - Ou usar inputs pr√©-tokenizados de tokenizer externo (ex: HuggingFace tokenizers)
  - **Testes:** ‚úÖ Todos passando (Release + Debug com sanitizers)
    - Teste de carregamento
    - Teste de encode/decode
    - Teste de BOS/EOS tokens
    - Hello World funcionando: "Hello World" ‚Üí tokens ‚Üí "Hello World"
  - **Ferramenta de Exporta√ß√£o:**
    ```bash
    python3 tools/convert_llama.py --tokenizer tokenizer.bin [vocab_size]
    ```
  - **Documenta√ß√£o:** `docs/TOKENIZER_IMPLEMENTATION.md` - Documenta√ß√£o completa

- ‚úÖ **Passo 4.2:** Criar `main.c`. Loop: Tokenize -> Forward -> Sample -> Print -> Update Cache.
  - **Status:** ‚úÖ **COMPLETA** (2025-01-02)
  - **Implementa√ß√£o:**
    - ‚úÖ Interface de linha de comando (CLI)
    - ‚úÖ Loop de gera√ß√£o: Tokenize input ‚Üí Forward pass ‚Üí Sample ‚Üí Print ‚Üí Update KV Cache
    - ‚úÖ Suporte a prompts interativos
    - ‚úÖ Tratamento de erros robusto (verificar `q_error_code` em todas as chamadas)
    - ‚úÖ Integra√ß√£o com tokenizer (FASE 4.1 completa)
    - ‚úÖ Integra√ß√£o com forward pass (FASE 3.3 completa)
    - ‚úÖ Sampling strategies: Greedy, Temperature, Top-k, Top-p, Combined Top-k+Top-p
    - ‚úÖ Performance benchmarks implementados
  - **Depend√™ncias:** 
    - ‚úÖ FASE 4.1 (Tokenizer) - COMPLETA
    - ‚úÖ FASE 3.3 (Forward Pass) - COMPLETA
  - **Nota:** Todas as chamadas de fun√ß√µes matem√°ticas verificam retorno `q_error_code`.
  
- ‚úÖ **Passo 4.3:** Auditoria de Performance e Otimiza√ß√µes Cr√≠ticas.
  - **Status:** ‚úÖ **COMPLETA** (2025-01-02)
  - **Problema Cr√≠tico Identificado e Corrigido:**
    - üî¥ **Top-p catastr√≥fico:** ~60√ó mais lento que greedy (~6000 ms/token)
    - **Causa Raiz:** Memcpy repetido no binary search (3.84 MB copiado desnecessariamente)
    - **Solu√ß√£o:** Sort completo UMA VEZ + binary search no cumsum prefixo (sem memcpy repetido)
    - **Resultado:** ~11√ó melhoria (5985 ms ‚Üí 532 ms/token)
  - **Status de Performance Atual:**
    - ‚úÖ **Greedy:** ~100 ms/token (perfeito)
    - ‚úÖ **Prefill:** ~26 ms/token (√≥timo)
    - ‚úÖ **Top-p=0.9:** ~532 ms/token (corrigido, ~11√ó melhoria)
    - ‚ö†Ô∏è **Top-k=10:** ~616 ms/token (aceit√°vel, pode melhorar)
  - **Documenta√ß√£o:**
    - `docs/src-docs/AUDIT_PERFORMANCE_TOP_P_CRITICAL.md` - Auditoria detalhada
    - `docs/src-docs/AUDIT_PERFORMANCE_TOP_K.md` - An√°lise de top-k
    - `docs/AUDITORIA_PERFORMANCE_COMPLETA.md` - Resumo consolidado
    - `docs/CORRECAO_TOP_P_IMPLEMENTADA.md` - Documenta√ß√£o da corre√ß√£o

**Crit√©rios Objetivos de Qualidade (FASE 4.1):**
- ‚úÖ **Testes:** 100% pass rate (Release + Debug com sanitizers)
- ‚úÖ **Valida√ß√£o:** Tokenizer validado end-to-end (encode/decode round-trip)
- ‚úÖ **Valida√ß√£o de Erros:** Todos os c√≥digos de erro testados
- ‚úÖ **Sanitizers:** AddressSanitizer, MemorySanitizer passam sem erros
- ‚úÖ **Exemplo Funcional:** Hello World funcionando corretamente

**Crit√©rios Objetivos de Qualidade (FASE 4.2):**
- ‚úÖ **Testes:** 100% pass rate em testes de main loop
- ‚úÖ **Valida√ß√£o:** Loop de gera√ß√£o validado end-to-end
- ‚úÖ **Valida√ß√£o de Erros:** Todos os c√≥digos de erro tratados corretamente
- ‚úÖ **Performance:** Lat√™ncia de gera√ß√£o medida e documentada
  - Greedy: ~100 ms/token
  - Top-p: ~532 ms/token (corrigido de ~6000 ms)
  - Top-k: ~616 ms/token
- ‚úÖ **Sanitizers:** AddressSanitizer, MemorySanitizer passam sem erros
- ‚úÖ **Auditoria de Performance:** Completa com corre√ß√µes cr√≠ticas implementadas

**Checkpoint de Refatora√ß√£o (Ap√≥s FASE 4.2):**
- ‚úÖ **Status:** Conclu√≠do (2025-01-02)
- ‚úÖ **√Åreas Verificadas:**
  - Arquitetura do main loop
  - Integra√ß√£o tokenizer + forward pass
  - Tratamento de erros robusto
  - Performance do loop de gera√ß√£o
  - Otimiza√ß√µes cr√≠ticas de sampling (top-p corrigido)
- ‚úÖ **M√©tricas:** Zero regress√µes, performance otimizada, todos os testes passando

---

## PARTE 2: CAPACIDADE DE TREINAMENTO (Ap√≥s Infer√™ncia Completa)

**Nota:** As fases abaixo devem ser implementadas ap√≥s a conclus√£o da FASE 4 (Tokenizer & Loop), quando o sistema de infer√™ncia estiver completo e funcional. **Status:** ‚úÖ FASE 4 COMPLETA (2025-01-02)

---

### ‚è≥ FASE 2.6: Training Kernels (Planejamento Completo) - **PLANEJAMENTO COMPLETO**

**Objetivo:** Adicionar capacidade de treinamento para future-implementations (Code Agent, Customer Behavior Prediction, SEO AI Specialist).

**Status:** üìã Planejamento completo (2024-12-30). Pronto para implementa√ß√£o ap√≥s FASE 4.2.

**Depend√™ncias:**
- ‚úÖ FASE 4.2 (Main Loop) - Deve estar completa antes de iniciar

**Componentes Planejados:**

- ‚è≥ **Optimizers** (`src/optim/`)
  - **Arquivo:** `src/optim/optimizer.c`, `src/optim/adam.c`
  - **Uso:** Atualiza√ß√£o de pesos durante treinamento (Adam, AdamW)
  - **Tempo Estimado:** 8-12 horas
  - **Caracter√≠sticas:**
    - AVX2-optimized weight updates
    - Arena-based state allocation (zero-malloc)
    - Support for SGD, Adam, AdamW

- ‚è≥ **Loss Functions** (`src/ops/avx2/`)
  - **Arquivos:** `src/ops/avx2/loss_mse.c`, `src/ops/avx2/loss_crossentropy.c`
  - **Uso:** C√°lculo de loss e gradientes para backward pass
  - **Tempo Estimado:** 4-6 horas
  - **Caracter√≠sticas:**
    - AVX2-optimized loss computation
    - Gradient computation for backward pass

- ‚è≥ **Gradient Clipping** (`src/ops/avx2/`)
  - **Arquivo:** `src/ops/avx2/clip.c`
  - **Uso:** Estabiliza√ß√£o de gradientes durante treinamento
  - **Tempo Estimado:** 2-3 horas
  - **Caracter√≠sticas:**
    - AVX2-optimized clipping
    - In-place operation

**Total Estimado (FASE 2.6):** 14-21 horas

**Crit√©rios Objetivos de Qualidade (FASE 2.6 - Pendente):**
- ‚è≥ **Testes:** 100% pass rate em todos os testes de optimizer e loss functions
- ‚è≥ **Precis√£o Num√©rica:** Max absolute difference < 1e-5, Max relative difference < 1e-4 (FP32)
- ‚è≥ **Valida√ß√£o:** Todos os optimizers validados contra refer√™ncias PyTorch
- ‚è≥ **Zero-Malloc:** Nenhuma aloca√ß√£o din√¢mica no hot path (apenas arena)
- ‚è≥ **Performance:** Benchmarks mantidos ou melhorados
- ‚è≥ **Sanitizers:** AddressSanitizer, MemorySanitizer, UndefinedBehaviorSanitizer passam

**Checkpoint de Refatora√ß√£o (Ap√≥s FASE 2.6 - Pendente):**
- ‚è≥ **Status:** Pendente
- ‚è≥ **√Åreas a Verificar:**
  - Consist√™ncia de interface de optimizers
  - Padroniza√ß√£o de tratamento de erros
  - Otimiza√ß√£o de performance AVX2
  - Cobertura de testes completa
- ‚è≥ **Limite de Tempo:** 1 dia

**Documenta√ß√£o de Planejamento:**
- `docs/TRAINING_CAPABILITY_PLAN.md` - Plano completo de capacidade de treinamento

---

### ‚è≥ FASE 2.7: CUDA Support (Google Colab / GPU) - **PLANEJAMENTO COMPLETO**

**Objetivo:** Adicionar suporte CUDA para treinamento acelerado em GPU (Google Colab, NVIDIA GPUs).

**Status:** üìã Planejamento completo (2025-01-02). Pronto para implementa√ß√£o ap√≥s abstra√ß√µes necess√°rias.

**An√°lise Cr√≠tica Aplicada:**
- ‚úÖ **Problema Identificado:** Falta de abstra√ß√£o de device em `q_tensor`
- ‚úÖ **Problema Identificado:** Conflito potencial com Zero-Malloc no hot path
- ‚úÖ **Problema Identificado:** Estrutura de diret√≥rios incompleta para sele√ß√£o de kernel
- ‚úÖ **Solu√ß√£o Proposta:** Abstra√ß√£o de device + gerenciamento unificado de mem√≥ria

**Componentes Planejados:**

- ‚è≥ **Abstra√ß√£o de Device** (`include/qorus_types.h`)
  - **Estrutura:** `q_device_type` enum (CPU, CUDA)
  - **Tempo Estimado:** 2-3 horas
  - **Caracter√≠sticas:**
    - Adicionar campo `device` em `q_tensor`
    - Adicionar campos `kv_device` e `scratch_device` em `q_context`
    - Adicionar campo `cuda_context` em `q_context`

- ‚è≥ **Gerenciamento de Mem√≥ria Unificado** (`src/core/memory.c`)
  - **Fun√ß√µes:** `q_alloc_kv_cache_ex()`, `q_alloc_arena_ex()` com suporte a device
  - **Tempo Estimado:** 4-6 horas
  - **Caracter√≠sticas:**
    - CPU: `aligned_alloc` (como antes)
    - CUDA: `cudaMalloc` (zero-malloc mantido no hot path)
    - Pinned memory apenas para buffers persistentes (Tier 2: KV Cache)
    - Scratchpad usa `cudaMalloc` normal (zero-malloc mantido)

- ‚è≥ **Interface Comum com Sele√ß√£o Autom√°tica** (`src/ops/`)
  - **Fun√ß√µes:** `q_matmul_f32()`, `q_add_f32()`, etc. (wrapper que seleciona kernel)
  - **Tempo Estimado:** 6-8 horas
  - **Caracter√≠sticas:**
    - Interface p√∫blica permanece a mesma (`qorus.h`)
    - Sele√ß√£o autom√°tica de kernel baseada em `device` do tensor
    - Fallback para CPU se CUDA n√£o dispon√≠vel

- ‚è≥ **Kernels CUDA** (`src/ops/cuda/`)
  - **Arquivos:** `q_cuda_utils.cu`, `matmul.cu`, `rope.cu`, etc.
  - **Tempo Estimado:** 20-30 horas
  - **Caracter√≠sticas:**
    - CUDA kernels para opera√ß√µes cr√≠ticas
    - Integra√ß√£o com cuBLAS para MatMul
    - Custom kernels para RoPE, RMSNorm, etc.

- ‚è≥ **Resolu√ß√£o do Problema do mmap no Google Drive** (`src/core/memory.c`)
  - **Fun√ß√£o:** `q_init_memory_smart()` com detec√ß√£o de fuse filesystem
  - **Tempo Estimado:** 2-3 horas
  - **Caracter√≠sticas:**
    - Detecta Google Drive (fuse filesystem)
    - Copia modelo para `/tmp` antes de mmap
    - Mant√©m compatibilidade com sistemas normais

**Total Estimado (FASE 2.7):** 34-50 horas

**Depend√™ncias:**
- ‚úÖ FASE 3.3 (Forward Pass) - COMPLETA (necess√°ria para testar kernels CUDA)
- ‚úÖ FASE 4.2 (Main Loop) - Recomendado estar completa antes de iniciar
- ‚è≥ Abstra√ß√µes de device (pr√©-requisito)

**Nota:** Pode ser implementada em paralelo com FASE 2.6 (Training Kernels) para acelerar treinamento em GPU.

**Crit√©rios Objetivos de Qualidade (FASE 2.7 - Pendente):**
- ‚è≥ **Testes:** 100% pass rate em todos os testes CUDA
- ‚è≥ **Precis√£o Num√©rica:** Max absolute difference < 1e-5, Max relative difference < 1e-4 (FP32)
- ‚è≥ **Valida√ß√£o:** Todos os kernels CUDA validados contra refer√™ncias CPU
- ‚è≥ **Zero-Malloc:** Nenhuma aloca√ß√£o din√¢mica no hot path (apenas `cudaMalloc` na inicializa√ß√£o)
- ‚è≥ **Performance:** Speedup medido vs CPU (objetivo: >2x para opera√ß√µes grandes)
- ‚è≥ **Compatibilidade:** C√≥digo CPU existente continua funcionando sem mudan√ßas
- ‚è≥ **Sanitizers:** CUDA-Memcheck passa sem erros

**Checkpoint de Refatora√ß√£o (Ap√≥s FASE 2.7 - Pendente):**
- ‚è≥ **Status:** Pendente
- ‚è≥ **√Åreas a Verificar:**
  - Abstra√ß√£o de device funcionando corretamente
  - Sele√ß√£o autom√°tica de kernel validada
  - Gerenciamento de mem√≥ria GPU otimizado
  - Compatibilidade CPU mantida
- ‚è≥ **Limite de Tempo:** 1-2 dias

**Documenta√ß√£o de Planejamento:**
- `docs/CUDA_ADAPTATION_PLAN.md` - Plano completo de adapta√ß√£o CUDA (a ser criado)

**An√°lise Cr√≠tica Completa (First Principles Thinking + CoT):**

**Problemas Identificados e Solu√ß√µes:**

1. **Falta de Abstra√ß√£o de Device:**
   - **Problema:** `q_tensor` n√£o distingue entre CPU e GPU, causando crashes se ponteiro GPU for passado para kernel AVX2
   - **Solu√ß√£o:** Adicionar campo `q_device_type device` em `q_tensor`
   - **Impacto:** Permite sele√ß√£o autom√°tica de kernel baseada em device
   - **Prova:** Se `q_tensor.data` aponta para GPU mas kernel AVX2 √© chamado ‚Üí CRASH. Com `device`, sele√ß√£o autom√°tica previne isso.

2. **Conflito com Zero-Malloc:**
   - **Problema:** `cudaHostAlloc` quebra zero-malloc no hot path (√© aloca√ß√£o)
   - **Solu√ß√£o:** Usar `cudaMalloc` normal no hot path, `cudaHostAlloc` apenas para buffers persistentes (Tier 2: KV Cache)
   - **Impacto:** Mant√©m garantia zero-malloc mesmo com CUDA
   - **Prova:** Zero-malloc = zero aloca√ß√µes no hot path. `cudaMalloc` √© aloca√ß√£o, mas apenas na inicializa√ß√£o (n√£o no hot path). `cudaHostAlloc` seria aloca√ß√£o no hot path ‚Üí quebra garantia.

3. **Estrutura de Diret√≥rios:**
   - **Problema:** Falta abstra√ß√£o para sele√ß√£o de kernel (runtime vs compile-time)
   - **Solu√ß√£o:** Interface comum (`q_matmul_f32()`) que seleciona kernel automaticamente baseado em `device`
   - **Impacto:** C√≥digo cliente n√£o precisa mudar, sele√ß√£o transparente
   - **Prova:** Sem abstra√ß√£o, c√≥digo cliente precisa saber qual kernel chamar ‚Üí duplica√ß√£o. Com abstra√ß√£o, uma fun√ß√£o p√∫blica seleciona automaticamente.

4. **Problema do mmap no Google Drive:**
   - **Problema:** Fuse filesystem √© muito lento para mmap (lat√™ncia de milissegundos vs nanossegundos)
   - **Solu√ß√£o:** Detectar fuse e copiar modelo para `/tmp` antes de mmap
   - **Impacto:** Performance normal mesmo no Google Colab
   - **Prova:** Fuse filesystem tem overhead de rede ‚Üí mmap bloqueia. Copiar para `/tmp` (SSD local) ‚Üí mmap r√°pido.

**Estrutura de Implementa√ß√£o:**

```c
// Interface p√∫blica (n√£o muda) - em qorus.h
q_error_code q_matmul_f32(const q_tensor* A, const q_tensor* B, 
                          const q_tensor* C, q_context* ctx);

// Implementa√ß√£o interna seleciona kernel automaticamente - em src/ops/matmul.c
q_error_code q_matmul_f32(const q_tensor* A, const q_tensor* B,
                          const q_tensor* C, q_context* ctx) {
    // Auto-select kernel based on device
    if (A->device == Q_DEVICE_CUDA || B->device == Q_DEVICE_CUDA) {
        return q_matmul_f32_cuda(A, B, C, ctx);
    } else {
        return q_matmul_f32_avx2(A, B, C, ctx);
    }
}
```

**Gerenciamento de Mem√≥ria Unificado:**

```c
// Extens√£o do q_context para suportar GPU - em qorus_types.h
typedef struct {
    // Tier 1: Weights (Read-Only)
    void* weights_mmap;       // CPU: mmap, GPU: NULL (pesos ficam em GPU)
    size_t weights_size;
    
    // Tier 2: KV Cache (Persistent)
    void* kv_buffer;          // CPU: aligned_alloc, GPU: cudaMalloc
    size_t kv_size;
    q_device_type kv_device;  // NEW: Onde est√° o KV cache
    
    // Tier 3: Scratchpad (Transient)
    void* scratch_buffer;     // CPU: aligned_alloc, GPU: cudaMalloc
    size_t scratch_size;
    size_t scratch_head;
    q_device_type scratch_device;  // NEW: Onde est√° o scratchpad
    
    // NEW: CUDA context (se dispon√≠vel)
    void* cuda_context;       // NULL se n√£o usar CUDA
} q_context;
```

**Resolu√ß√£o do Problema do mmap no Google Drive:**

```c
// Fun√ß√£o helper para detectar e copiar se necess√°rio - em src/core/memory.c
q_error_code q_init_memory_smart(q_context* ctx, const char* model_path) {
    // Detectar se √© Google Drive (fuse filesystem)
    struct statfs fs_info;
    if (statfs(model_path, &fs_info) == 0) {
        if (fs_info.f_type == 0x65735546) {  // FUSE magic number
            // √â fuse: copiar para /tmp primeiro
            char tmp_path[PATH_MAX];
            snprintf(tmp_path, sizeof(tmp_path), "/tmp/qorus_model_%d.bin", getpid());
            // Copiar arquivo...
            return q_init_memory(ctx, tmp_path);
        }
    }
    // N√£o √© fuse: usar diretamente
    return q_init_memory(ctx, model_path);
}
```

**Notas Importantes:**
- **Zero-Malloc Mantido:** Usar `cudaMalloc` (n√£o `cudaHostAlloc`) no hot path
- **Compatibilidade:** C√≥digo CPU existente continua funcionando sem mudan√ßas (device padr√£o = CPU)
- **Performance:** Sele√ß√£o de kernel em runtime tem overhead m√≠nimo (< 1 ciclo, apenas compara√ß√£o de enum)
- **Abstra√ß√£o:** Interface p√∫blica n√£o muda, sele√ß√£o autom√°tica transparente

---

### ‚è≥ FASE 3.4: Backward Pass (Training) - **PLANEJAMENTO COMPLETO**

**Objetivo:** Implementar backward pass para propaga√ß√£o de gradientes.

**Status:** üìã Planejamento completo (2024-12-30). Bloqueado por FASE 2.6.

**Componentes Planejados:**

- ‚è≥ **Backward Infrastructure** (`src/core/model.c`)
  - **Fun√ß√£o:** `q_model_backward()`
  - **Uso:** Propaga√ß√£o de gradientes atrav√©s das camadas (gen√©rico)
  - **Tempo Estimado:** 6-8 horas
  - **Caracter√≠sticas:**
    - Forward cache management
    - Gradient propagation framework
    - Funciona com qualquer arquitetura

- ‚è≥ **Layer Backward Implementations**
  - **Attention Backward:** Q/K/V gradients, GQA-aware
  - **MLP Backward:** SwiGLU backward, down projection gradient
  - **RMSNorm Backward:** Weight gradient, input gradient
  - **Residual Backward:** Gradient pass-through
  - **Tempo Estimado:** 12-16 horas

**Total Estimado (FASE 3.4):** 18-24 horas

**Depend√™ncias:**
- ‚úÖ FASE 2.6 (Optimizers, Loss Functions, Gradient Clipping) - Deve estar completa antes de iniciar

**Crit√©rios Objetivos de Qualidade (FASE 3.4 - Pendente):**
- ‚è≥ **Testes:** 100% pass rate em todos os testes de backward pass
- ‚è≥ **Valida√ß√£o:** Gradientes validados contra refer√™ncias PyTorch (gradient checking)
- ‚è≥ **Zero-Malloc:** Nenhuma aloca√ß√£o din√¢mica no hot path (apenas arena)
- ‚è≥ **Performance:** Benchmarks mantidos ou melhorados
- ‚è≥ **Sanitizers:** AddressSanitizer, MemorySanitizer passam sem erros

**Checkpoint de Refatora√ß√£o (Ap√≥s FASE 3.4 - Pendente):**
- ‚è≥ **Status:** Pendente
- ‚è≥ **√Åreas a Verificar:**
  - Arquitetura do backward pass
  - Integra√ß√£o com forward cache
  - Propaga√ß√£o de gradientes validada
  - Performance do backward pass
- ‚è≥ **Limite de Tempo:** 1-2 dias

---

### ‚è≥ FASE 3.5: Training Loop (Training) - **PLANEJAMENTO COMPLETO**

**Objetivo:** Implementar loop de treinamento completo.

**Status:** üìã Planejamento completo (2024-12-30). Bloqueado por FASE 3.4.

**Componentes Planejados:**

- ‚è≥ **Training Loop** (`src/core/model.c`)
  - **Fun√ß√£o:** `q_model_train()`
  - **Uso:** Loop completo de treinamento (epochs, mini-batches) - gen√©rico
  - **Tempo Estimado:** 6-8 horas
  - **Caracter√≠sticas:**
    - Mini-batch shuffling (Fisher-Yates)
    - Forward ‚Üí Loss ‚Üí Backward ‚Üí Optimizer Step ‚Üí Zero Grad
    - Gradient clipping integration
    - Early stopping support
    - Funciona com qualquer arquitetura

- ‚è≥ **Training Utilities**
  - Learning rate scheduling
  - Training metrics tracking
  - Checkpoint saving
  - **Tempo Estimado:** 4-6 horas

**Total Estimado (FASE 3.5):** 10-14 horas

**Depend√™ncias:**
- ‚úÖ FASE 3.4 (Backward Pass) - Deve estar completa antes de iniciar

**Crit√©rios Objetivos de Qualidade (FASE 3.5 - Pendente):**
- ‚è≥ **Testes:** 100% pass rate em todos os testes de training loop
- ‚è≥ **Valida√ß√£o:** Training loop validado end-to-end (converge em dataset pequeno)
- ‚è≥ **Zero-Malloc:** Nenhuma aloca√ß√£o din√¢mica no hot path (apenas arena)
- ‚è≥ **Performance:** Throughput de treinamento medido e documentado
- ‚è≥ **Sanitizers:** AddressSanitizer, MemorySanitizer passam sem erros

**Checkpoint de Refatora√ß√£o (Ap√≥s FASE 3.5 - Pendente):**
- ‚è≥ **Status:** Pendente
- ‚è≥ **√Åreas a Verificar:**
  - Arquitetura do training loop
  - Integra√ß√£o de optimizer
  - Integra√ß√£o de loss function
  - Fluxo de gradientes
  - Performance de treinamento
- ‚è≥ **Limite de Tempo:** 1-2 dias

---

## PARTE 3: EVOLU√á√ÉO PARA v3.0 - FRAMEWORK GEN√âRICO

**Nota:** As fases abaixo devem ser implementadas ap√≥s a conclus√£o das PARTES 1 e 2, quando tanto infer√™ncia quanto treinamento estiverem completos e funcionais.

### Objetivo v3.0

Transformar QorusIA de engine especializado em **framework gen√©rico** sem limita√ß√µes arquiteturais, mantendo:
- ‚úÖ Performance m√°xima (zero-malloc, AVX2)
- ‚úÖ Arquitetura limpa (valida√ß√µes robustas)
- ‚úÖ Flexibilidade total (qualquer arquitetura)

**Depend√™ncias:**
- ‚úÖ PARTE 1: Infer√™ncia completa (FASE 1-4)
- ‚úÖ PARTE 2: Treinamento completo (FASE 2.6-3.5) - Recomendado estar completa antes de iniciar

---

### ‚è≥ FASE 5.0: Core Abstraction (Framework Gen√©rico) - **PLANEJAMENTO COMPLETO**

**Objetivo:** Implementar abstra√ß√£o gen√©rica de camadas e modelos.

**Status:** üìã Planejamento completo (2024-12-30). Pronto para implementa√ß√£o.

**Componentes Planejados:**

- ‚è≥ **Generic Layer Interface** (`include/qorus_types.h`)
  - **Estrutura:** `q_layer` com function pointers (polimorfismo)
  - **Tempo Estimado:** 4-6 horas
  - **Caracter√≠sticas:**
    - 64-byte aligned
    - Function pointers para forward/backward/free
    - Type enum para runtime checking

- ‚è≥ **Generic Model Container** (`src/core/model.c`)
  - **Estrutura:** `q_model` com array de camadas gen√©ricas
  - **Tempo Estimado:** 6-8 horas
  - **Caracter√≠sticas:**
    - 128-byte aligned
    - Forward cache para treinamento
    - Suporte a mmap (zero-copy)

- ‚è≥ **Generic Forward Pass** (`src/core/model.c`)
  - **Fun√ß√£o:** `q_model_forward()` gen√©rica
  - **Tempo Estimado:** 4-6 horas
  - **Caracter√≠sticas:**
    - Polimorfismo via function pointers
    - Forward cache management
    - Valida√ß√µes robustas

- ‚è≥ **Generic Backward Pass** (`src/core/model.c`)
  - **Fun√ß√£o:** `q_model_backward()` gen√©rica
  - **Tempo Estimado:** 6-8 horas
  - **Caracter√≠sticas:**
    - Propaga√ß√£o de gradientes gen√©rica
    - Uso de forward cache
    - Suporte a camadas n√£o-trein√°veis

**Total Estimado (FASE 5.0):** 20-28 horas

**Crit√©rios Objetivos de Qualidade (FASE 5.0 - Pendente):**
- ‚è≥ **Testes:** 100% pass rate em todos os testes de framework gen√©rico
- ‚è≥ **Valida√ß√£o:** Framework gen√©rico validado com modelo Transformer
- ‚è≥ **Zero-Malloc:** Nenhuma aloca√ß√£o din√¢mica no hot path (apenas arena)
- ‚è≥ **Performance:** Overhead de function pointers < 1% (medido)
- ‚è≥ **Sanitizers:** AddressSanitizer, MemorySanitizer passam sem erros

**Checkpoint de Refatora√ß√£o (Ap√≥s FASE 5.0 - Pendente):**
- ‚è≥ **Status:** Pendente
- ‚è≥ **√Åreas a Verificar:**
  - Design de interface gen√©rica
  - Overhead de function pointers otimizado
  - Interface de layer padronizada
  - Zero overhead de performance verificado
- ‚è≥ **Limite de Tempo:** 1-2 dias

**Documenta√ß√£o de Planejamento:**
- `docs/GENERIC_FRAMEWORK_PLAN.md` - Plano completo de framework gen√©rico

---

### ‚è≥ FASE 5.1: Basic Layers (Framework Gen√©rico) - **PLANEJAMENTO COMPLETO**

**Objetivo:** Implementar camadas b√°sicas com interface gen√©rica.

**Status:** üìã Planejamento completo (2024-12-30).

**Camadas Planejadas:**

- ‚è≥ **Linear Layer** (`src/layers/linear.c`)
  - **Interface:** Gen√©rica (`q_layer`)
  - **Tempo Estimado:** 6-8 horas
  - **Caracter√≠sticas:**
    - Forward/backward gen√©ricos
    - Suporte Q4_0 e FP32
    - Gradientes para treinamento

- ‚è≥ **Activation Layers** (`src/layers/activation.c`)
  - **Tipos:** ReLU, GeLU, SiLU, Sigmoid
  - **Tempo Estimado:** 4-6 horas
  - **Caracter√≠sticas:**
    - Forward/backward gen√©ricos
    - AVX2 optimized

- ‚è≥ **Normalization Layers** (`src/layers/normalization.c`)
  - **Tipos:** RMSNorm, LayerNorm, BatchNorm
  - **Tempo Estimado:** 6-8 horas
  - **Caracter√≠sticas:**
    - Forward/backward gen√©ricos
    - AVX2 optimized

- ‚è≥ **Softmax Layer** (`src/layers/softmax.c`)
  - **Interface:** Gen√©rica
  - **Tempo Estimado:** 2-3 horas
  - **Caracter√≠sticas:**
    - Forward/backward gen√©ricos
    - AVX2 optimized

**Total Estimado (FASE 5.1):** 18-25 horas

**Crit√©rios Objetivos de Qualidade (FASE 5.1 - Pendente):**
- ‚è≥ **Testes:** 100% pass rate em todos os testes de layers b√°sicas
- ‚è≥ **Precis√£o Num√©rica:** Max absolute difference < 1e-5, Max relative difference < 1e-4 (FP32)
- ‚è≥ **Valida√ß√£o:** Todas as layers validadas contra refer√™ncias PyTorch
- ‚è≥ **Zero-Malloc:** Nenhuma aloca√ß√£o din√¢mica no hot path (apenas arena)
- ‚è≥ **Performance:** Benchmarks mantidos ou melhorados
- ‚è≥ **Sanitizers:** AddressSanitizer, MemorySanitizer passam sem erros

**Checkpoint de Refatora√ß√£o (Ap√≥s FASE 5.1 - Pendente):**
- ‚è≥ **Status:** Pendente
- ‚è≥ **√Åreas a Verificar:**
  - Consist√™ncia de interface de layers
  - Qualidade de implementa√ß√£o de layers
  - Otimiza√ß√£o de performance
  - Cobertura de testes completa
- ‚è≥ **Limite de Tempo:** 1 dia

---

### ‚è≥ FASE 5.2: Advanced Layers (Framework Gen√©rico) - **PLANEJAMENTO COMPLETO**

**Objetivo:** Implementar camadas avan√ßadas com interface gen√©rica.

**Status:** üìã Planejamento completo (2024-12-30).

**Camadas Planejadas:**

- ‚è≥ **Multi-Head Attention** (`src/layers/mha.c`)
  - **Interface:** Gen√©rica
  - **Tempo Estimado:** 8-10 horas
  - **Caracter√≠sticas:**
    - Suporte GQA
    - Forward/backward gen√©ricos
    - AVX2 optimized

- ‚è≥ **Feed-Forward Network** (`src/layers/ffn.c`)
  - **Interface:** Gen√©rica
  - **Tempo Estimado:** 6-8 horas
  - **Caracter√≠sticas:**
    - Suporte SwiGLU
    - Forward/backward gen√©ricos
    - AVX2 optimized

- ‚è≥ **Transformer Block** (`src/layers/transformer_block.c`)
  - **Interface:** Gen√©rica
  - **Tempo Estimado:** 4-6 horas
  - **Caracter√≠sticas:**
    - Composi√ß√£o de MHA + FFN + RMSNorm
    - Forward/backward gen√©ricos

- ‚è≥ **Embedding Layer** (`src/layers/embedding.c`)
  - **Interface:** Gen√©rica
  - **Tempo Estimado:** 4-6 horas
  - **Caracter√≠sticas:**
    - Token embedding
    - Positional embedding (RoPE)
    - Forward/backward gen√©ricos

**Total Estimado (FASE 5.2):** 22-30 horas

**Crit√©rios Objetivos de Qualidade (FASE 5.2 - Pendente):**
- ‚è≥ **Testes:** 100% pass rate em todos os testes de layers avan√ßadas
- ‚è≥ **Precis√£o Num√©rica:** Max absolute difference < 1e-5, Max relative difference < 1e-4 (FP32)
- ‚è≥ **Valida√ß√£o:** Todas as layers validadas contra refer√™ncias PyTorch
- ‚è≥ **Zero-Malloc:** Nenhuma aloca√ß√£o din√¢mica no hot path (apenas arena)
- ‚è≥ **Performance:** Benchmarks mantidos ou melhorados
- ‚è≥ **Sanitizers:** AddressSanitizer, MemorySanitizer passam sem erros

**Checkpoint de Refatora√ß√£o (Ap√≥s FASE 5.2 - Pendente):**
- ‚è≥ **Status:** Pendente
- ‚è≥ **√Åreas a Verificar:**
  - Arquitetura de layers avan√ßadas
  - Composi√ß√£o de layers
  - Otimiza√ß√£o de performance
  - Testes de layers complexas
- ‚è≥ **Limite de Tempo:** 1-2 dias

---

### ‚è≥ FASE 5.3: Example Model Builders (Framework Gen√©rico) - **PLANEJAMENTO COMPLETO**

**Objetivo:** Criar exemplos de modelos usando framework gen√©rico.

**Status:** üìã Planejamento completo (2024-12-30). Bloqueado por FASE 5.0-5.2.

**Componentes Planejados:**

- ‚è≥ **Transformer Model Builder** (`src/models/transformer_builder.c`)
  - **Fun√ß√£o:** `transformer_build_model()` usando API gen√©rica
  - **Tempo Estimado:** 6-8 horas
  - **Caracter√≠sticas:**
    - Exemplo de modelo Transformer usando framework gen√©rico
    - Zero-copy weight loading
    - Demonstra flexibilidade do framework

- ‚è≥ **Example Testing**
  - **Tempo Estimado:** 4-6 horas
  - **Caracter√≠sticas:**
    - Testes de performance
    - Valida√ß√£o de corre√ß√£o
    - Demonstra uso do framework gen√©rico

- ‚è≥ **Documentation**
  - **Tempo Estimado:** 2-3 horas
  - **Caracter√≠sticas:**
    - Exemplos de uso
    - Guias de migra√ß√£o
    - Documenta√ß√£o de API

**Total Estimado (FASE 5.3):** 12-17 horas

**Depend√™ncias:**
- ‚úÖ FASE 5.0 (Core Abstraction) - Deve estar completa antes de iniciar
- ‚úÖ FASE 5.1 (Basic Layers) - Deve estar completa antes de iniciar
- ‚úÖ FASE 5.2 (Advanced Layers) - Deve estar completa antes de iniciar

**Crit√©rios Objetivos de Qualidade (FASE 5.3 - Pendente):**
- ‚è≥ **Testes:** 100% pass rate em todos os testes de exemplo
- ‚è≥ **Valida√ß√£o:** Modelos exemplo validados end-to-end
- ‚è≥ **Documenta√ß√£o:** Exemplos de uso completos e funcionais
- ‚è≥ **Performance:** Benchmarks mantidos ou melhorados

**Checkpoint de Refatora√ß√£o (Ap√≥s FASE 5.3 - Pendente):**
- ‚è≥ **Status:** Pendente
- ‚è≥ **√Åreas a Verificar:**
  - Completude de migra√ß√£o
  - Compatibilidade reversa
  - Valida√ß√£o de performance
  - Limpeza de c√≥digo
- ‚è≥ **Limite de Tempo:** 1 dia

---

### ‚è≥ FASE 5.4: Additional Architectures (Framework Gen√©rico) - **FUTURO**

**Objetivo:** Suportar arquiteturas adicionais usando framework gen√©rico.

**Arquiteturas Planejadas:**

- ‚è≥ **Simple MLP** (Exemplo: MNIST classifier)
  - **Tempo Estimado:** 4-6 horas
  - **Demonstra:** Flexibilidade do framework gen√©rico

- ‚è≥ **CNN Support** (Futuro)
  - Conv2D layer
  - Pool2D layer
  - Arquiteturas CNN

- ‚è≥ **RNN/LSTM Support** (Futuro)
  - RNN layer
  - LSTM layer
  - Modelos de sequ√™ncia

**Crit√©rios Objetivos de Qualidade (FASE 5.4 - Pendente):**
- ‚è≥ **Testes:** 100% pass rate em todos os testes de arquiteturas adicionais
- ‚è≥ **Valida√ß√£o:** Arquiteturas adicionais validadas end-to-end
- ‚è≥ **Documenta√ß√£o:** Exemplos de uso completos

**Checkpoint de Refatora√ß√£o (Ap√≥s FASE 5.4 - Pendente):**
- ‚è≥ **Status:** Pendente
- ‚è≥ **√Åreas a Verificar:**
  - Prontid√£o para produ√ß√£o
  - Revis√£o final de qualidade de c√≥digo
  - Valida√ß√£o final de performance
  - Completude de documenta√ß√£o
- ‚è≥ **Limite de Tempo:** 2 dias

---

## COMPARA√á√ÉO: v2.0 vs v3.0

### QorusIA v2.0 (Atual)
- ‚úÖ Performance m√°xima (zero-malloc, AVX2)
- ‚úÖ Arquitetura limpa
- ‚ùå Limitado a arquitetura espec√≠fica
- ‚ùå Estrutura hardcoded

### QorusIA v3.0 (Proposto)
- ‚úÖ Performance m√°xima (zero-malloc, AVX2)
- ‚úÖ Arquitetura limpa
- ‚úÖ Gen√©rico (qualquer arquitetura)
- ‚úÖ Composi√ß√£o flex√≠vel
- ‚úÖ F√°cil de estender

**Resultado:** MetaIA's flexibilidade + QorusIA's performance = Framework gen√©rico sem limita√ß√µes.

---

## 5. REGRAS DE CODIFICA√á√ÉO (Para o Cursor)

Cole isso no prompt do Cursor para garantir qualidade:

- **Strict C11:** Use C11 padr√£o. Sem extens√µes GNU a menos que estritamente necess√°rio para AVX.

- **No Mallocs:** Proibido usar `malloc` ou `free` dentro de `src/ops` ou `src/models`. Use a API da Arena.
  - **CUDA:** Usar `cudaMalloc` (n√£o `cudaHostAlloc`) no hot path para manter zero-malloc
  - **Pinned Memory:** Apenas para buffers persistentes (Tier 2), n√£o no hot path

- **Restrict Pointers:** Use `float *restrict a` em kernels matem√°ticos para permitir otimiza√ß√µes agressivas do compilador.

- **Error Handling:** 
  - Fun√ß√µes matem√°ticas retornam `q_error_code` (enum padronizado).
  - Use macros `Q_VALIDATE_OR_RETURN` para valida√ß√µes cr√≠ticas (sempre ativas em Release).
  - Em DEBUG mode: valida√ß√µes abortam com mensagem detalhada.
  - Em Release mode: valida√ß√µes retornam c√≥digo de erro apropriado.
  - Crash (`abort`) apenas em DEBUG mode para facilitar debugging.

- **Comments:** Documente o layout de mem√≥ria esperado em cima de cada kernel (ex: "Espera que A seja [K, N] transposto").

---

## 6. SEGURAN√áA E VALIDA√á√ÉO

### Valida√ß√µes Cr√≠ticas (Sempre Ativas)

Todas as fun√ß√µes matem√°ticas implementam valida√ß√µes cr√≠ticas que est√£o **sempre ativas**, mesmo em Release mode:

- ‚úÖ **Valida√ß√£o de Ponteiros Nulos:** Previne segfaults
- ‚úÖ **Valida√ß√£o de Aliasing:** Previne corrup√ß√£o de dados (input == output)
- ‚úÖ **Valida√ß√£o de Overflow:** Previne wraparound em c√°lculos de √≠ndices
- ‚úÖ **Valida√ß√£o de Alinhamento:** Previne crashes em instru√ß√µes AVX2
  - ‚úÖ Debug detalhado em `Q_VALIDATE_ALIGNED_OR_RETURN` para diagn√≥stico de problemas de alinhamento
  - ‚úÖ Corre√ß√£o de alinhamento em softmax (buffers alinhados para cada linha)
- ‚úÖ **Valida√ß√£o de Contiguidade:** Previne leitura de mem√≥ria inv√°lida em MatMul
  - ‚úÖ Valida√ß√£o de `nb[0] == expected_stride` em `q_gemv_q4_f32_avx2`
  - ‚úÖ Falha com erro claro se tensor n√£o for cont√≠guo (v1.0 limitation)
  - ‚úÖ Documenta√ß√£o clara de limita√ß√£o arquitetural
- ‚úÖ **Valida√ß√£o de Tipo:** Previne uso incorreto de dados quantizados
- ‚úÖ **Valida√ß√£o de Dimens√µes:** Previne acesso fora dos limites

### Testes Adversariais

**Status:** ‚úÖ **COMPLETO** (2025-01-02)

Testes adversariais completos implementados para validar robustez do c√≥digo:
- ‚úÖ **19 testes adversariais** para `llama_forward()` (100% pass rate)
- ‚úÖ **24 testes adversariais** para tokenizer (100% pass rate)
- ‚úÖ Cobertura completa: NULL pointers, edge cases, memory safety, large sequences, misaligned memory, corrupted data, numerical stability
- ‚úÖ Metodologia Lead SDET: Scenario Map, Acceptance Criteria, Blinded Implementation (AAA pattern)

### Macros de Valida√ß√£o

```c
// Exemplo de uso em fun√ß√µes matem√°ticas
q_error_code q_gemv_q4_f32_avx2(...) {
    Q_VALIDATE_PTR_OR_RETURN(weights, Q_ERR_INVALID_ARG);
    Q_VALIDATE_OR_RETURN(input != output, Q_ERR_ALIASING);
    Q_VALIDATE_MULTIPLE_OR_RETURN(N, 32, Q_ERR_INVALID_SIZE);
    // ... implementa√ß√£o ...
    return Q_OK;
}
```

### C√≥digos de Erro Padronizados

```c
typedef enum {
    Q_OK = 0,
    Q_ERR_INVALID_ARG = -10,      // Argumento inv√°lido
    Q_ERR_ALIASING = -11,         // Aliasing detectado
    Q_ERR_OVERFLOW = -12,         // Overflow detectado
    Q_ERR_MISALIGNED = -13,       // Ponteiro desalinhado
    Q_ERR_INVALID_DTYPE = -14,    // Tipo de dado inv√°lido
    Q_ERR_INVALID_SIZE = -15      // Tamanho inv√°lido
    // ... outros c√≥digos ...
} q_error_code;
```

### Performance

- **Overhead M√≠nimo:** Valida√ß√µes usam `__builtin_expect` para otimizar branch prediction
- **Custo Estimado:** < 1 ciclo por valida√ß√£o quando passa (caso comum)
- **Custo Quando Falha:** Retorno imediato de erro (sem processamento desnecess√°rio)

### Performance Benchmarks (2025-01-02)

**Status Atual de Performance:**
- ‚úÖ **Greedy Sampling:** ~100 ms/token (baseline perfeito)
- ‚úÖ **Prefill:** ~26 ms/token (excelente)
- ‚úÖ **Top-p=0.9:** ~532 ms/token (corrigido, ~11√ó melhoria de ~6000 ms)
- ‚ö†Ô∏è **Top-k=10:** ~616 ms/token (aceit√°vel, complexidade correta O(V + k log k))
- ‚ö†Ô∏è **Top-k+Top-p:** ~1029 ms/token (aceit√°vel, pode melhorar)

**Otimiza√ß√µes Cr√≠ticas Implementadas:**
- ‚úÖ **Top-p:** Eliminado memcpy repetido no binary search (sort UMA VEZ + cumsum prefixo)
- ‚úÖ **Valida√ß√£o:** Auditoria completa de performance com corre√ß√µes implementadas
- ‚ö†Ô∏è **Top-k:** Otimiza√ß√µes recomendadas (SIMD init, renormaliza√ß√£o otimizada)

**Documenta√ß√£o de Performance:**
- `docs/AUDITORIA_PERFORMANCE_COMPLETA.md` - Resumo consolidado
- `docs/src-docs/AUDIT_PERFORMANCE_TOP_P_CRITICAL.md` - Auditoria detalhada de top-p
- `docs/src-docs/AUDIT_PERFORMANCE_TOP_K.md` - An√°lise de top-k
- `docs/CORRECAO_TOP_P_IMPLEMENTADA.md` - Documenta√ß√£o da corre√ß√£o cr√≠tica

---

## 7. MELHORIAS DE ROBUSTEZ

### Aritm√©tica de Ponteiros Robusta

**Implementa√ß√£o:** Todas as opera√ß√µes de aritm√©tica de ponteiros usam `size_t` para c√°lculos de offset, garantindo m√°xima robustez mesmo em casos extremos.

**Exemplo em `q_gemv_q4_f32_avx2`:**
```c
// ROBUSTNESS: Use size_t for offset calculations to prevent uint32_t wraparound
const size_t block_base = (size_t)(bg * 4);
const size_t tail_start = (size_t)(num_block_groups * 4);
const size_t row_offset = (size_t)i * (size_t)blocks_per_row;
```

**Benef√≠cios:**
- ‚úÖ Elimina qualquer possibilidade de wraparound em `uint32_t` antes da convers√£o para aritm√©tica de ponteiros
- ‚úÖ Consist√™ncia de tipos em todo o c√≥digo
- ‚úÖ Zero overhead: compilador otimiza igualmente
- ‚úÖ Dupla camada de prote√ß√£o (valida√ß√£o + tipo mais seguro)

### Documenta√ß√£o de Comportamento

**Wrapper P√∫blico para Testes:** Fun√ß√µes p√∫blicas de teste incluem valida√ß√£o NULL e documenta√ß√£o clara do comportamento esperado.

**Exemplo em `q_dequantize_q4_0_block_avx2_public`:**
```c
// ROBUSTNESS: Validate inputs (only in public wrapper, not in hot path)
// This prevents crashes in test scenarios while maintaining zero overhead
// in production code paths that use the inline version directly
if (__builtin_expect(block == NULL || output == NULL, 0)) {
    return; // Silently return - acceptable for test code defensive programming
}
```

**Filosofia:**
- Hot path usa vers√µes inline sem overhead de valida√ß√£o
- Wrappers p√∫blicos para testes incluem valida√ß√£o defensiva
- Comportamento claramente documentado

### Valida√ß√£o de Overflow em M√∫ltiplas Camadas

**Estrat√©gia:** Valida√ß√µes de overflow em m√∫ltiplos pontos cr√≠ticos:

1. **Valida√ß√£o de Dimens√µes:** `Q_VALIDATE_NO_OVERFLOW_OR_RETURN(M, blocks_per_row)`
2. **C√°lculo Seguro de Offset:** Uso de `size_t` para aritm√©tica de ponteiros
3. **Valida√ß√£o de Alinhamento:** `safe_align_size()` previne overflow no alinhamento
4. **Valida√ß√£o de Adi√ß√£o:** `ctx->scratch_head > SIZE_MAX - aligned_size` previne overflow na adi√ß√£o

**Resultado:** M√∫ltiplas camadas de prote√ß√£o garantem robustez m√°xima sem impacto na performance.

---

## 8. PR√ìXIMOS PASSOS

### ‚úÖ FASE 4.2 (Main Loop) - **COMPLETA**

**Status:** ‚úÖ **COMPLETA** (2025-01-02)

**Objetivo:** Implementar loop principal de gera√ß√£o de texto.

**Depend√™ncias:** 
- ‚úÖ FASE 4.1 (Tokenizer) - COMPLETA
- ‚úÖ FASE 3.3 (Forward Pass) - COMPLETA

**Implementa√ß√£o:**
- ‚úÖ Loop de gera√ß√£o completo (Tokenize ‚Üí Forward ‚Üí Sample ‚Üí Print ‚Üí Update Cache)
- ‚úÖ Suporte a m√∫ltiplas estrat√©gias de sampling (Greedy, Temperature, Top-k, Top-p)
- ‚úÖ Benchmarks de performance implementados
- ‚úÖ Auditoria de performance completa com corre√ß√µes cr√≠ticas

**Pr√≥xima Fase Recomendada:**
- **FASE 2.6:** Training Kernels (Optimizers, Loss Functions, Gradient Clipping)
- **FASE 2.7:** CUDA Support (Google Colab / GPU)

### Implementa√ß√£o Futura: PARTE 2 - Capacidade de Treinamento

**Pr√©-requisito:** FASE 4.2 (Main Loop) deve estar completa antes de iniciar.

**Ordem de Implementa√ß√£o Recomendada:**

1. **FASE 2.6: Training Kernels**
   > **"Atue como Qorus-Architect. Vamos implementar a FASE 2.6. Comece com os Optimizers seguindo o planejamento completo em `docs/TRAINING_CAPABILITY_PLAN.md`. Use o framework MFR + CoT + Mathematical Proof + TDD conforme `docs/.cursorrules`."**
   - Optimizers (Adam, AdamW) - Base para treinamento
   - Loss Functions (MSE, CrossEntropy) - Necess√°rio para backward
   - Gradient Clipping - Estabiliza√ß√£o de treinamento

2. **FASE 2.7: CUDA Support** (Pode ser paralelo a FASE 2.6)
   - Abstra√ß√£o de device
   - Gerenciamento de mem√≥ria GPU
   - Kernels CUDA

3. **FASE 3.4: Backward Pass**
   - Propaga√ß√£o de gradientes atrav√©s das camadas

4. **FASE 3.5: Training Loop**
   - Loop completo de treinamento (epochs, mini-batches)

### Implementa√ß√£o Futura: PARTE 3 - Framework Gen√©rico v3.0

**Pr√©-requisito:** PARTE 1 (Infer√™ncia) e PARTE 2 (Treinamento) devem estar completas antes de iniciar.

**Ordem de Implementa√ß√£o Recomendada:**

1. **FASE 5.0: Core Abstraction**
   > **"Atue como Qorus-Architect. Vamos implementar a FASE 5.0. Comece com a Generic Layer Interface seguindo o planejamento completo em `docs/GENERIC_FRAMEWORK_PLAN.md`. Use o framework MFR + CoT + Mathematical Proof + TDD conforme `docs/.cursorrules`."**
   - Generic Layer Interface (polimorfismo via function pointers)
   - Generic Model Container
   - Generic Forward/Backward Pass

2. **FASE 5.1: Basic Layers**
   - Linear Layer
   - Activation Layers (ReLU, GeLU, SiLU, Sigmoid)
   - Normalization Layers (RMSNorm, LayerNorm, BatchNorm)
   - Softmax Layer

3. **FASE 5.2: Advanced Layers**
   - Multi-Head Attention (MHA)
   - Feed-Forward Network (FFN)
   - Transformer Block
   - Embedding Layer

4. **FASE 5.3: Example Model Builders**
   - Transformer Model Builder usando API gen√©rica
   - Exemplos de uso e documenta√ß√£o

5. **FASE 5.4: Additional Architectures** (Futuro)
   - Simple MLP
   - CNN Support
   - RNN/LSTM Support

### Comando Inicial (Para Novos Desenvolvedores)

Para come√ßar do zero, pe√ßa ao Cursor:

> **"Atue como Qorus-Architect. Vamos iniciar a Fase 1. Primeiro, crie a estrutura de diret√≥rios e os arquivos de cabe√ßalho `include/qorus_types.h` e `include/qorus.h` com as defini√ß√µes de Tensor e Contexto conforme o Blueprint v2.0."**

Isso garante que o projeto comece com a estrutura correta.

---

## 9. REFER√äNCIAS DE PLANEJAMENTO

**Documentos Executivos:**
- `docs/PROJECT_VISION.md` - **Vis√£o completa do projeto (in√≠cio ‚Üí atual ‚Üí fim)**
- `docs/TIMELINE.md` - **Timeline de desenvolvimento com estimativas e depend√™ncias**
- `docs/INDEX.md` - **√çndice mestre da documenta√ß√£o - guia de navega√ß√£o**

**Documentos de Planejamento (FASE 2.5 - Inference Kernels):**
- `docs/KERNEL_PORTATION_PLAN.md` - Plano completo de porta√ß√£o seguindo MFR + CoT + Mathematical Proof + TDD
- `docs/KERNEL_IMPLEMENTATION_DETAILS.md` - Guia de implementa√ß√£o com c√≥digo completo e exemplos
- `docs/PLANNING_SUMMARY.md` - Resumo executivo do planejamento

**Documentos de Planejamento (FASE 2.6 - Training Capability):**
- `docs/TRAINING_CAPABILITY_PLAN.md` - Plano completo de capacidade de treinamento (MFR + CoT + Proof + TDD)

**Documentos de Planejamento (FASE 5.0+ - Generic Framework v3.0):**
- `docs/GENERIC_FRAMEWORK_PLAN.md` - **Plano completo de framework gen√©rico (MFR + CoT + Proof + TDD)**

**Documentos de Planejamento (FASE 2.7 - CUDA Support):**
- `docs/CUDA_ADAPTATION_PLAN.md` - **Plano completo de adapta√ß√£o CUDA para Google Colab / GPU (MFR + CoT + Proof + TDD)** (a ser criado)

**Documenta√ß√£o de Qualidade:**
- `docs/REFACTORING_CHECKPOINTS.md` - **Procedimentos de checkpoint de refatora√ß√£o e garantia de qualidade**

**Documenta√ß√£o T√©cnica:**
- `docs/STATUS.md` - Status detalhado do projeto
- `docs/QUICK_REFERENCE.md` - Refer√™ncia r√°pida
- `docs/FASE_3.3_ANALYSIS.md` - An√°lise do forward pass
- `docs/TOKENIZER_IMPLEMENTATION.md` - **Documenta√ß√£o completa do tokenizer (FASE 4.1)**
- `docs/PRECISION_STANDARDS.md` - Padr√µes de precis√£o num√©rica
- `docs/ASYMPTOTIC_ANALYSIS.md` - An√°lise assint√≥tica
- `docs/.cursorrules` - Metodologia de desenvolvimento (MFR + CoT + Proof + TDD)

**Documenta√ß√£o de Performance e Auditoria:**
- `docs/AUDITORIA_PERFORMANCE_COMPLETA.md` - **Resumo consolidado de auditoria de performance**
- `docs/src-docs/AUDIT_PERFORMANCE_TOP_P_CRITICAL.md` - **Auditoria detalhada de top-p (gargalo cr√≠tico corrigido)**
- `docs/src-docs/AUDIT_PERFORMANCE_TOP_K.md` - **An√°lise de top-k**
- `docs/CORRECAO_TOP_P_IMPLEMENTADA.md` - **Documenta√ß√£o da corre√ß√£o cr√≠tica de top-p**
- `docs/src-docs/INDEX_AUDITORIAS.md` - **√çndice de todas as auditorias de performance**
