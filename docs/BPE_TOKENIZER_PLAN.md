# üéØ PLANEJAMENTO: Tokenizer BPE Real - Protocolo de Engenharia

**Data:** 2025-01-02  
**Metodologia:** First Principles Thinking + Model-First Reasoning + Chain of Thought + Mathematical Proof + TDD  
**Objetivo:** Implementar algoritmo BPE (Byte Pair Encoding) completo para produ√ß√£o

---

## FASE 1: Decomposi√ß√£o por Primeiros Princ√≠pios (First Principles)

### 1.1 Restri√ß√µes F√≠sicas Reais

**Mem√≥ria:**
- **Vocabul√°rio:** O(n) onde n = vocab_size (t√≠pico: 32K-128K tokens)
- **Merge Rules:** O(m) onde m = num_merges (t√≠pico: 10K-50K merges)
- **Texto de Entrada:** O(t) onde t = text_length (vari√°vel, at√© max_seq_len)
- **Buffer de Sa√≠da:** O(t) tokens (pode ser menor que texto devido a merges)

**CPU:**
- **Regex Splitting:** O(t) - uma passada pelo texto
- **Merge Lookup:** O(m √ó k) onde k = n√∫mero de pares adjacentes no texto
- **Merge Application:** O(k) - cada merge reduz o n√∫mero de tokens
- **Hot Path:** Encoding √© chamado por token gerado (lat√™ncia cr√≠tica)

**Cache:**
- **Vocab Lookup:** Cache-friendly (array linear)
- **Merge Lookup:** Pode ser cache-unfriendly se n√£o otimizado (hash table prefer√≠vel)

### 1.2 O que √© Matematicamente Necess√°rio

**Algoritmo BPE (Greedy):**
1. **Regex Splitting:** Dividir texto em subword units usando regex
   - Padr√£o comum: `'s|'t|'re|'ve|'m|'ll|'d| ?\p{L}+| ?\p{N}+| ?[^\s\p{L}\p{N}]+|\s+(?!\S)|\s+`
   - Alternativa simples: bytes individuais (fallback)

2. **Inicializa√ß√£o:** Converter cada subword unit para lista de token IDs (bytes)
   - Cada caractere UTF-8 ‚Üí sequ√™ncia de bytes ‚Üí token IDs base

3. **Merge Iterativo (Greedy):**
   - Para cada merge rule em ordem de prioridade (√≠ndice = prioridade):
     - Encontrar todos os pares adjacentes (token_id1, token_id2) no texto
     - Se par existe, substituir pelo merged_id
     - Repetir at√© n√£o haver mais merges aplic√°veis
   - **Invariante:** Cada merge reduz o n√∫mero de tokens

4. **Convers√£o Final:** Lista de token IDs ‚Üí array de uint32_t

**Complexidade Matem√°tica:**
- **Lower Bound Te√≥rico:** O(t + m √ó k) onde:
  - t = text_length (splitting)
  - m = num_merges (itera√ß√£o)
  - k = n√∫mero m√©dio de pares por itera√ß√£o (‚â§ t)

### 1.3 Custo M√≠nimo Te√≥rico (Lower Bound)

**Tempo:**
- **Splitting:** Œ©(t) - deve ler todo o texto
- **Merge Lookup:** Œ©(m) - deve verificar todas as regras (pior caso)
- **Merge Application:** Œ©(k) - deve processar todos os pares
- **Lower Bound Total:** Œ©(t + m √ó k)

**Espa√ßo:**
- **Vocab:** Œ©(n √ó L) onde L = comprimento m√©dio do token
- **Merges:** Œ©(m) - array de estruturas
- **Texto Tokenizado:** Œ©(t) - lista de token IDs (intermedi√°ria)
- **Lower Bound Total:** Œ©(n √ó L + m + t)

### 1.4 Crit√©rios de Parada (Thresholds)

**Threshold Assint√≥tico:**
- Solu√ß√£o proposta ‚â§ Lower Bound √ó 1.1 (10% overhead m√°ximo)
- **Valida√ß√£o:** O(t + m √ó k) ‚â§ Œ©(t + m √ó k) √ó 1.1 ‚úì (algoritmo greedy √© √≥timo)

**Threshold Constante:**
- **Regex Splitting:** ‚â§ 2x do custo de memcpy (1 ciclo/byte)
- **Merge Lookup:** Hash table O(1) lookup ‚â§ 2x do acesso direto a array
- **Merge Application:** In-place replacement ‚â§ 2x do custo de memcpy

**Itera√ß√£o M√°xima:**
- Se ap√≥s 3 itera√ß√µes n√£o convergir para dentro dos thresholds, aceitar solu√ß√£o atual e documentar trade-off

---

## FASE 2: Model-First Reasoning (Estrutura do Problema)

### 2.1 Entidades e Estruturas de Dados

**Estrutura Existente (`q_tokenizer`):**
```c
typedef struct {
    char** vocab;              // Array de token strings [vocab_size]
    uint32_t vocab_size;       // Total vocabulary size
    q_bpe_merge* merges;      // Array de BPE merge rules [num_merges]
    uint32_t num_merges;       // Number of BPE merges
    uint32_t bos_token_id;     // Beginning of sequence token ID
    uint32_t eos_token_id;     // End of sequence token ID
    uint32_t pad_token_id;     // Padding token ID
    bool initialized;          // True if tokenizer loaded successfully
} q_tokenizer;
```

**Nova Estrutura Auxiliar (Interna):**
```c
// Estrutura para representar token durante processamento BPE
typedef struct {
    uint32_t* token_ids;       // Array de token IDs (din√¢mico)
    size_t count;              // N√∫mero de tokens
    size_t capacity;           // Capacidade alocada
} bpe_token_list;

// Hash table para lookup r√°pido de merges (opcional, otimiza√ß√£o)
// Key: (token_id1 << 16) | token_id2 (uint64_t)
// Value: merged_id (uint32_t)
// Estrutura: Array de buckets com chaining (simples)
```

**Layout de Mem√≥ria:**
- **Vocab:** Array de ponteiros ‚Üí strings alocadas separadamente
- **Merges:** Array cont√≠guo de `q_bpe_merge` (12 bytes cada)
- **Token List:** Array din√¢mico de `uint32_t` (4 bytes cada)
- **Alinhamento:** N√£o cr√≠tico (n√£o usa SIMD), mas manter cache-friendly

### 2.2 Estados e Invariantes

**Pr√©-condi√ß√µes (`q_tokenizer_encode`):**
- `tok != NULL` e `tok->initialized == true`
- `text != NULL` (string v√°lida, null-terminated)
- `tokens_out != NULL` e `max_tokens > 0`
- `tok->vocab != NULL` e `tok->vocab_size > 0`
- `tok->merges != NULL` ou `tok->num_merges == 0`
- Todos os token IDs em merges s√£o v√°lidos (< vocab_size)

**P√≥s-condi√ß√µes:**
- `tokens_out[0..num_tokens-1]` cont√©m token IDs v√°lidos
- `num_tokens_out` cont√©m n√∫mero de tokens gerados
- Se `add_bos == true`, `tokens_out[0] == tok->bos_token_id`
- Se `add_eos == true`, `tokens_out[num_tokens-1] == tok->eos_token_id`
- Todos os tokens s√£o v√°lidos (< vocab_size ou tokens especiais)

**Invariantes de Loop (Merge Iterativo):**
- **Invariante 1:** N√∫mero de tokens nunca aumenta (s√≥ diminui ou mant√©m)
- **Invariante 2:** Ordem relativa dos tokens preservada (apenas pares adjacentes s√£o fundidos)
- **Invariante 3:** Cada merge aplicado corresponde a uma regra v√°lida em `tok->merges`
- **Invariante 4:** √çndice de merge processado s√≥ aumenta (n√£o retrocede)

**Estados Intermedi√°rios:**
1. **Estado Inicial:** Texto ‚Üí lista de bytes (token IDs base)
2. **Estado Intermedi√°rio:** Lista de token IDs ap√≥s cada merge aplicado
3. **Estado Final:** Lista de token IDs ap√≥s todos os merges aplic√°veis

### 2.3 Grafo de Depend√™ncia

**Depend√™ncias Funcionais:**
```
(q_tokenizer_encode) 
  ‚Üí (regex_split_text)           [FASE 4.1]
  ‚Üí (bytes_to_token_ids)         [FASE 4.2]
  ‚Üí (apply_bpe_merges)           [FASE 4.3]
    ‚Üí (find_merge_pairs)         [FASE 4.3.1]
    ‚Üí (apply_single_merge)       [FASE 4.3.2]
  ‚Üí (add_special_tokens)         [FASE 4.4]
```

**Depend√™ncias de Dados:**
- `q_tokenizer_encode` depende de `q_tokenizer` (carregado via `q_tokenizer_load`)
- `apply_bpe_merges` depende de `tok->merges` e `tok->num_merges`
- `bytes_to_token_ids` depende de `tok->vocab` e `tok->vocab_size`

**Race Conditions:**
- **Nenhuma:** Fun√ß√£o √© thread-safe se `tok` n√£o √© modificado durante encoding
- **Valida√ß√£o:** `tok->initialized` deve ser lido antes de qualquer acesso

**Valida√ß√£o de Ciclos:**
- ‚úÖ Sem ciclos detectados (grafo ac√≠clico)

---

## FASE 3: Prova e An√°lise (The "Proof")

### 3.1 An√°lise Assint√≥tica

**Tempo de Execu√ß√£o:**

**Caso M√©dio:**
- **Regex Splitting:** O(t) onde t = text_length
- **Bytes to Token IDs:** O(t) - uma passada
- **Merge Lookup:** O(m √ó k_avg) onde:
  - m = num_merges
  - k_avg = n√∫mero m√©dio de pares por itera√ß√£o (‚â§ t)
- **Merge Application:** O(k_avg) - substitui√ß√£o in-place
- **Total:** O(t + m √ó k_avg)

**Pior Caso:**
- **Regex Splitting:** O(t) - mesmo
- **Merge Lookup:** O(m √ó t) - todos os merges aplic√°veis em cada posi√ß√£o
- **Merge Application:** O(t) - m√°ximo de t/2 merges
- **Total:** O(t + m √ó t) = O(m √ó t)

**Compara√ß√£o com Lower Bound:**
- Lower Bound: Œ©(t + m √ó k)
- Solu√ß√£o Proposta: O(t + m √ó k_avg) (caso m√©dio)
- **Valida√ß√£o:** O(t + m √ó k_avg) ‚â§ Œ©(t + m √ó k) √ó 1.1 ‚úì
- **Conclus√£o:** Algoritmo greedy √© √≥timo (dentro do threshold)

**Espa√ßo de Execu√ß√£o:**

**Stack:**
- Vari√°veis locais: O(1) - ponteiros e contadores
- Recurs√£o: Nenhuma (iterativo)

**Heap:**
- Token List intermedi√°ria: O(t) - pior caso (sem merges)
- Hash table (opcional): O(m) - se implementada
- **Total:** O(t + m)

**Compara√ß√£o com Lower Bound:**
- Lower Bound: Œ©(t + m)
- Solu√ß√£o Proposta: O(t + m)
- **Valida√ß√£o:** O(t + m) = Œ©(t + m) ‚úì (√≥timo)

### 3.2 Demonstra√ß√£o L√≥gica

**Corre√ß√£o do Algoritmo Greedy:**

**Teorema:** O algoritmo greedy aplica merges em ordem de prioridade e produz tokeniza√ß√£o v√°lida.

**Prova:**
1. **Base:** Lista inicial de token IDs √© v√°lida (bytes v√°lidos)
2. **Indu√ß√£o:** Se lista √© v√°lida antes de aplicar merge i, ent√£o ap√≥s aplicar merge i:
   - Par (token_id1, token_id2) √© substitu√≠do por merged_id
   - merged_id √© v√°lido (garantido por `q_tokenizer_load`)
   - N√∫mero de tokens diminui ou mant√©m (invariante)
   - Ordem relativa preservada (apenas pares adjacentes)
3. **Conclus√£o:** Lista final √© v√°lida

**Preserva√ß√£o de Precis√£o:**
- N√£o h√° opera√ß√µes num√©ricas (apenas lookup e substitui√ß√£o)
- Token IDs s√£o inteiros (sem perda de precis√£o)
- **Valida√ß√£o:** Algoritmo preserva informa√ß√£o completamente

### 3.3 Simula√ß√£o de Falha (Failure Mode Analysis)

**Resultado Correto (Target):**
- Texto "Hello World" ‚Üí tokens [72, 101, 108, 108, 111, 32, 87, 111, 114, 108, 100] (sem merges)
- Com merges: texto ‚Üí tokens reduzidos (ex: [72, 101, 108, 108, 111, 32, 87, 111, 114, 108, 100] ‚Üí [72, 101, 108, 108, 111, 32, 87, 111, 114, 108, 100] ap√≥s aplicar merges)
- Decodifica√ß√£o reversa produz texto original (perda zero)

**Exemplos de Resultado Ruim/Errado (Anti-Patterns):**

1. **Uso de Array Est√°tico para Token List:**
   - **Problema:** Buffer overflow se texto muito longo
   - **Sintoma:** Crash ou corrup√ß√£o de mem√≥ria
   - **Preven√ß√£o:** Aloca√ß√£o din√¢mica com crescimento exponencial

2. **Lookup Linear de Merges:**
   - **Problema:** O(m) lookup para cada par ‚Üí O(m √ó t) total
   - **Sintoma:** Performance degradada com muitos merges
   - **Preven√ß√£o:** Hash table O(1) lookup

3. **Aplica√ß√£o de Merges em Ordem Errada:**
   - **Problema:** Merge de prioridade baixa aplicado antes de alta
   - **Sintoma:** Tokeniza√ß√£o incorreta (n√£o corresponde ao treinamento)
   - **Preven√ß√£o:** Iterar merges em ordem de √≠ndice (prioridade)

4. **Race Condition em Buffer Compartilhado:**
   - **Problema:** M√∫ltiplas threads modificando mesma lista
   - **Sintoma:** Corrup√ß√£o de dados ou crash
   - **Preven√ß√£o:** Fun√ß√£o thread-safe (sem estado global mut√°vel)

5. **Falta de Valida√ß√£o de Token IDs:**
   - **Problema:** Token ID inv√°lido causa segfault em lookup
   - **Sintoma:** Crash em `tok->vocab[invalid_id]`
   - **Preven√ß√£o:** Validar todos os token IDs antes de lookup

### 3.4 Especifica√ß√£o Test√°vel

**Assinatura da Fun√ß√£o:**
```c
q_error_code q_tokenizer_encode(
    q_tokenizer* restrict tok,
    const char* restrict text,
    uint32_t* restrict tokens_out,
    uint32_t* restrict num_tokens_out,
    uint32_t max_tokens,
    bool add_bos,
    bool add_eos
);
```

**Pr√©-condi√ß√µes:**
- `tok != NULL` e `tok->initialized == true`
- `text != NULL` (string v√°lida, null-terminated)
- `tokens_out != NULL` e `max_tokens > 0`
- `num_tokens_out != NULL`

**P√≥s-condi√ß√µes:**
- Se sucesso: `*num_tokens_out` cont√©m n√∫mero de tokens gerados (‚â§ max_tokens)
- `tokens_out[0..*num_tokens_out-1]` cont√©m token IDs v√°lidos
- Se `add_bos == true`: `tokens_out[0] == tok->bos_token_id`
- Se `add_eos == true`: `tokens_out[*num_tokens_out-1] == tok->eos_token_id`
- Retorna `Q_OK` em sucesso, c√≥digo de erro em falha

**Teste de Especifica√ß√£o (Matem√°tico):**
- **Input:** `text = "Hello"`, `add_bos = false`, `add_eos = false`
- **Output Esperado:** `tokens_out = [72, 101, 108, 108, 111]`, `num_tokens_out = 5`
- **Valida√ß√£o:** 
  - N√∫mero de tokens = comprimento do texto (sem merges)
  - Cada token ID corresponde ao byte value do caractere
  - Decodifica√ß√£o reversa produz "Hello"

**Teste de Especifica√ß√£o (Com Merges):**
- **Input:** `text = "hello"`, merges contendo `(108, 108) -> 500` (merge de "ll")
- **Output Esperado:** `tokens_out = [104, 101, 500, 111]`, `num_tokens_out = 4`
- **Valida√ß√£o:**
  - N√∫mero de tokens < comprimento do texto (merge aplicado)
  - Token ID 500 corresponde ao merge de "ll"
  - Decodifica√ß√£o reversa produz "hello"

---

## FASE 4: Chain-of-Thought e Execu√ß√£o (Passo a Passo)

### 4.1 Definir Interface (Header)

**Arquivo:** `include/qorus.h`

**Fun√ß√£o Principal (J√° existe, manter assinatura):**
```c
q_error_code q_tokenizer_encode(
    q_tokenizer* restrict tok,
    const char* restrict text,
    uint32_t* restrict tokens_out,
    uint32_t* restrict num_tokens_out,
    uint32_t max_tokens,
    bool add_bos,
    bool add_eos
);
```

**Fun√ß√µes Auxiliares Internas (static):**
```c
// Regex splitting (simplificado para bytes se regex n√£o dispon√≠vel)
static q_error_code split_text_to_bytes(
    const char* restrict text,
    uint8_t* restrict bytes_out,
    size_t* restrict num_bytes_out,
    size_t max_bytes
);

// Converter bytes para token IDs base
static q_error_code bytes_to_token_ids(
    const q_tokenizer* restrict tok,
    const uint8_t* restrict bytes,
    size_t num_bytes,
    uint32_t* restrict token_ids_out,
    size_t* restrict num_tokens_out,
    size_t max_tokens
);

// Aplicar merges BPE (greedy)
static q_error_code apply_bpe_merges(
    const q_tokenizer* restrict tok,
    uint32_t* restrict token_ids,
    size_t* restrict num_tokens,
    size_t max_tokens
);

// Adicionar tokens especiais (BOS/EOS)
static q_error_code add_special_tokens(
    const q_tokenizer* restrict tok,
    uint32_t* restrict tokens,
    size_t* restrict num_tokens,
    size_t max_tokens,
    bool add_bos,
    bool add_eos
);
```

### 4.2 Implementar Teste de Unidade (TDD)

**Arquivo:** `tests/test_bpe_tokenizer.c`

**Estrat√©gia TDD:**
1. Criar teste que valida especifica√ß√£o matem√°tica (FASE 3.4)
2. Teste deve falhar inicialmente (tokenizer dummy n√£o implementa BPE)
3. Implementar c√≥digo m√≠nimo para passar no teste
4. Refinar e otimizar

**Testes Cr√≠ticos:**
- ‚úÖ Teste b√°sico: "Hello" ‚Üí [72, 101, 108, 108, 111]
- ‚úÖ Teste com merge: "hello" com merge (108,108)‚Üí500 ‚Üí [104, 101, 500, 111]
- ‚úÖ Teste com BOS/EOS: "Hi" com add_bos/add_eos ‚Üí [bos, 72, 105, eos]
- ‚úÖ Teste de buffer pequeno: deve retornar Q_ERR_ARENA_OOM
- ‚úÖ Teste de texto vazio: deve retornar tokens vazios (ou apenas BOS/EOS)
- ‚úÖ Teste de texto longo: validar que n√£o h√° overflow

**Integra√ß√£o com `@gereteste.md`:**
- Gerar su√≠te adversarial completa ap√≥s testes b√°sicos passarem
- Testes adversarial: texto malicioso, merges inv√°lidos, etc.

### 4.3 Implementar Kernel/L√≥gica (Draft)

**Arquivo:** `src/tokenizer/bpe.c` (novo arquivo)

**Algoritmo Principal (`q_tokenizer_encode`):**
```c
q_error_code q_tokenizer_encode(...) {
    // 1. Valida√ß√£o de inputs (j√° implementado)
    
    // 2. Splitting: texto ‚Üí bytes
    uint8_t bytes[MAX_TEXT_BYTES];
    size_t num_bytes;
    split_text_to_bytes(text, bytes, &num_bytes, MAX_TEXT_BYTES);
    
    // 3. Bytes ‚Üí token IDs base
    uint32_t token_ids[MAX_TOKENS];
    size_t num_tokens;
    bytes_to_token_ids(tok, bytes, num_bytes, token_ids, &num_tokens, max_tokens);
    
    // 4. Aplicar merges BPE (greedy)
    apply_bpe_merges(tok, token_ids, &num_tokens, max_tokens);
    
    // 5. Adicionar tokens especiais
    add_special_tokens(tok, token_ids, &num_tokens, max_tokens, add_bos, add_eos);
    
    // 6. Copiar para output
    memcpy(tokens_out, token_ids, num_tokens * sizeof(uint32_t));
    *num_tokens_out = num_tokens;
    
    return Q_OK;
}
```

**Algoritmo de Merge (`apply_bpe_merges`):**
```c
static q_error_code apply_bpe_merges(...) {
    bool changed = true;
    
    // Iterar enquanto houver mudan√ßas
    while (changed) {
        changed = false;
        
        // Para cada merge rule em ordem de prioridade
        for (uint32_t i = 0; i < tok->num_merges; i++) {
            uint32_t id1 = tok->merges[i].token_id1;
            uint32_t id2 = tok->merges[i].token_id2;
            uint32_t merged = tok->merges[i].merged_id;
            
            // Encontrar todos os pares (id1, id2) adjacentes
            for (size_t j = 0; j < num_tokens - 1; j++) {
                if (token_ids[j] == id1 && token_ids[j+1] == id2) {
                    // Aplicar merge: substituir par por merged_id
                    token_ids[j] = merged;
                    // Remover token_ids[j+1] (shift left)
                    memmove(&token_ids[j+1], &token_ids[j+2], 
                            (num_tokens - j - 2) * sizeof(uint32_t));
                    num_tokens--;
                    changed = true;
                    j--; // Re-check esta posi√ß√£o (pode haver outro merge)
                }
            }
        }
    }
    
    return Q_OK;
}
```

### 4.4 Otimiza√ß√£o (Vectoriza√ß√£o/Memory Access)

**Otimiza√ß√µes Planejadas:**

1. **Hash Table para Merge Lookup:**
   - **Problema:** Lookup linear O(m) para cada par
   - **Solu√ß√£o:** Hash table O(1) lookup
   - **Implementa√ß√£o:** Array de buckets com chaining simples
   - **Key:** `(token_id1 << 16) | token_id2` (uint64_t)
   - **Valida√ß√£o:** Reduz complexidade de O(m √ó t) para O(t + m)

2. **In-place Merge Application:**
   - **Problema:** `memmove` √© custoso para grandes shifts
   - **Solu√ß√£o:** Two-pointer technique (escrever resultado em novo array)
   - **Trade-off:** O(t) espa√ßo extra vs O(t¬≤) tempo de memmove
   - **Decis√£o:** Usar two-pointer para textos longos (>1000 tokens)

3. **Early Termination:**
   - **Problema:** Continua iterando mesmo sem mudan√ßas
   - **Solu√ß√£o:** Flag `changed` j√° implementada
   - **Valida√ß√£o:** Reduz itera√ß√µes desnecess√°rias

### 4.5 Verifica√ß√£o de Limites e Erros

**Valida√ß√µes Cr√≠ticas:**

1. **Buffer Overflow:**
   - Validar `num_tokens <= max_tokens` ap√≥s cada opera√ß√£o
   - Retornar `Q_ERR_ARENA_OOM` se exceder

2. **Token ID Inv√°lido:**
   - Validar todos os token IDs antes de lookup em vocab
   - Validar merges durante `q_tokenizer_load`

3. **Texto Vazio:**
   - Tratar texto vazio corretamente (retornar apenas BOS/EOS se solicitado)

4. **Merge Rules Inv√°lidas:**
   - Validar que `token_id1`, `token_id2`, `merged_id` s√£o v√°lidos (< vocab_size)
   - Validar durante `q_tokenizer_load` (n√£o em hot path)

---

## FASE 5: Checkpoints e Fatora√ß√£o

### Checkpoint 1: Compila√ß√£o Limpa
- ‚úÖ Compilar sem warnings (`-Wall -Wextra -Werror`)
- ‚úÖ Sem erros de sintaxe
- ‚úÖ Sem erros de tipo

### Checkpoint 2: Teste B√°sico Passa
- ‚úÖ Teste de especifica√ß√£o matem√°tica (FASE 3.4) passa
- ‚úÖ Sanity check: "Hello" ‚Üí tokens corretos
- ‚úÖ Valida√ß√£o de BOS/EOS funciona

### Checkpoint 3: An√°lise Est√°tica Limpa
- ‚úÖ `cppcheck` sem erros cr√≠ticos
- ‚úÖ `clang-tidy` sem warnings importantes
- ‚úÖ Sem memory leaks detect√°veis

### Checkpoint 4: M√©tricas Quantitativas Validadas

**Complexidade Assint√≥tica:**
- ‚úÖ O(t + m √ó k_avg) ‚â§ Lower Bound √ó 1.1 ‚úì
- ‚úÖ Hash table reduz para O(t + m) (caso m√©dio)

**Cobertura de Testes:**
- ‚úÖ ‚â• 90% branch coverage
- ‚úÖ Todos os failure modes da FASE 3.3 testados
- ‚úÖ Testes adversarial completos (`@gereteste.md`)

**Race Conditions:**
- ‚úÖ Zero race conditions detect√°veis (an√°lise est√°tica)
- ‚úÖ Fun√ß√£o thread-safe (sem estado global mut√°vel)

### Fatora√ß√£o (Complexidade Ciclom√°tica)

**Fun√ß√£o `apply_bpe_merges`:**
- **V(G) Estimado:** ~5-7 (loops aninhados, condicionais)
- **Linhas:** ~50-70
- **N√≠veis de Indenta√ß√£o:** 3 (while ‚Üí for ‚Üí if)
- **Crit√©rio:** V(G) = 7 ‚â§ 10 ‚úì, linhas = 70 > 50 mas V(G) baixo ‚úì
- **Conclus√£o:** Aceit√°vel, mas considerar refatora√ß√£o se crescer

**Fun√ß√£o `q_tokenizer_encode`:**
- **V(G) Estimado:** ~3-4 (sequencial com valida√ß√µes)
- **Linhas:** ~30-40
- **N√≠veis de Indenta√ß√£o:** 2
- **Crit√©rio:** V(G) = 4 ‚â§ 10 ‚úì, linhas = 40 ‚â§ 50 ‚úì
- **Conclus√£o:** Aceit√°vel

---

## FASE 6: O Artefato de Execu√ß√£o (Machine-Readable Output)

### Contexto Ancorado

**Arquivos que ser√£o Criados:**
- `src/tokenizer/bpe.c` - Implementa√ß√£o completa do BPE tokenizer
- `tests/test_bpe_tokenizer.c` - Testes unit√°rios completos
- `tests/test_bpe_tokenizer_adversarial.c` - Testes adversarial (via `@gereteste.md`)

**Arquivos que ser√£o Modificados:**
- `include/qorus.h` - Manter assinatura existente (j√° correta)
- `src/tokenizer/dummy_tokenizer.c` - Manter como fallback ou remover ap√≥s valida√ß√£o
- `Makefile` - Adicionar `bpe.c` aos sources e criar target de teste
- `docs/TOKENIZER_IMPLEMENTATION.md` - Atualizar documenta√ß√£o

**Arquivos de Refer√™ncia:**
- `src/tokenizer/dummy_tokenizer.c` - Estrutura e padr√µes de c√≥digo
- `include/qorus_types.h` - Defini√ß√µes de `q_tokenizer` e `q_bpe_merge`
- `tools/convert_llama.py` - Formato bin√°rio do tokenizer

### Checklist de Implementa√ß√£o

**FASE 4.1: Interface**
- [ ] Verificar assinatura de `q_tokenizer_encode` em `include/qorus.h` (j√° existe)
- [ ] Definir fun√ß√µes auxiliares internas (static) em `bpe.c`

**FASE 4.2: Testes (TDD)**
- [ ] Criar `tests/test_bpe_tokenizer.c` com teste de especifica√ß√£o matem√°tica
- [ ] Teste b√°sico: "Hello" ‚Üí [72, 101, 108, 108, 111]
- [ ] Teste com merge: "hello" com merge (108,108)‚Üí500
- [ ] Teste com BOS/EOS
- [ ] Teste de buffer pequeno (Q_ERR_ARENA_OOM)
- [ ] Teste de texto vazio
- [ ] Executar testes (devem falhar inicialmente - TDD)

**FASE 4.3: Implementa√ß√£o Base**
- [ ] Criar `src/tokenizer/bpe.c`
- [ ] Implementar `split_text_to_bytes` (simplificado: bytes diretos)
- [ ] Implementar `bytes_to_token_ids`
- [ ] Implementar `apply_bpe_merges` (algoritmo greedy b√°sico)
- [ ] Implementar `add_special_tokens`
- [ ] Implementar `q_tokenizer_encode` (orquestra√ß√£o)
- [ ] Compilar e corrigir erros (Checkpoint 1)

**FASE 4.4: Otimiza√ß√£o**
- [ ] Implementar hash table para merge lookup
- [ ] Otimizar `apply_bpe_merges` com two-pointer technique
- [ ] Adicionar early termination (j√° implementado com flag `changed`)
- [ ] Validar performance (benchmark se necess√°rio)

**FASE 4.5: Valida√ß√£o e Erros**
- [ ] Adicionar valida√ß√£o de buffer overflow em todas as fun√ß√µes
- [ ] Adicionar valida√ß√£o de token IDs inv√°lidos
- [ ] Tratar texto vazio corretamente
- [ ] Validar merge rules durante `q_tokenizer_load` (se n√£o j√° feito)

**FASE 5: Checkpoints**
- [ ] Checkpoint 1: Compila√ß√£o limpa sem warnings
- [ ] Checkpoint 2: Testes b√°sicos passam
- [ ] Checkpoint 3: An√°lise est√°tica limpa (cppcheck, clang-tidy)
- [ ] Checkpoint 4: M√©tricas quantitativas validadas

**FASE 6: Testes Adversarial**
- [ ] Usar `@gereteste.md` para gerar su√≠te adversarial completa
- [ ] Testes de texto malicioso (caracteres especiais, Unicode)
- [ ] Testes de merges inv√°lidos
- [ ] Testes de performance (textos longos)
- [ ] Valida√ß√£o com tokenizers de refer√™ncia (sentencepiece, tiktoken)

**Integra√ß√£o e Documenta√ß√£o**
- [ ] Atualizar `Makefile` para incluir `bpe.c`
- [ ] Criar target `test-bpe-tokenizer` no Makefile
- [ ] Atualizar `docs/TOKENIZER_IMPLEMENTATION.md`
- [ ] Decidir: manter `dummy_tokenizer.c` ou remover ap√≥s valida√ß√£o
- [ ] Atualizar `README.md` com instru√ß√µes de uso

### Pseudo-C√≥digo/Spec

**Algoritmo Principal (`q_tokenizer_encode`):**
```
FUNCTION q_tokenizer_encode(tok, text, tokens_out, num_tokens_out, max_tokens, add_bos, add_eos):
    // 1. Valida√ß√£o
    VALIDATE tok != NULL AND tok->initialized == true
    VALIDATE text != NULL
    VALIDATE tokens_out != NULL AND max_tokens > 0
    
    // 2. Splitting: texto ‚Üí bytes
    bytes = ALLOCATE(uint8_t[MAX_TEXT_BYTES])
    num_bytes = split_text_to_bytes(text, bytes)
    
    // 3. Bytes ‚Üí token IDs base
    token_ids = ALLOCATE(uint32_t[max_tokens])
    num_tokens = bytes_to_token_ids(tok, bytes, num_bytes, token_ids)
    
    // 4. Aplicar merges BPE (greedy)
    apply_bpe_merges(tok, token_ids, &num_tokens)
    
    // 5. Adicionar tokens especiais
    add_special_tokens(tok, token_ids, &num_tokens, add_bos, add_eos)
    
    // 6. Validar buffer
    IF num_tokens > max_tokens:
        RETURN Q_ERR_ARENA_OOM
    
    // 7. Copiar para output
    COPY token_ids TO tokens_out
    *num_tokens_out = num_tokens
    
    RETURN Q_OK
```

**Algoritmo de Merge (`apply_bpe_merges`):**
```
FUNCTION apply_bpe_merges(tok, token_ids, num_tokens):
    changed = true
    
    WHILE changed:
        changed = false
        
        FOR i = 0 TO tok->num_merges - 1:
            id1 = tok->merges[i].token_id1
            id2 = tok->merges[i].token_id2
            merged = tok->merges[i].merged_id
            
            FOR j = 0 TO num_tokens - 2:
                IF token_ids[j] == id1 AND token_ids[j+1] == id2:
                    // Aplicar merge
                    token_ids[j] = merged
                    SHIFT_LEFT(token_ids, j+1, num_tokens)
                    num_tokens--
                    changed = true
                    j--  // Re-check esta posi√ß√£o
    
    RETURN Q_OK
```

### Valida√ß√£o de Thresholds

**Complexidade Assint√≥tica:**
- ‚úÖ Lower Bound: Œ©(t + m √ó k)
- ‚úÖ Solu√ß√£o Proposta: O(t + m √ó k_avg) (caso m√©dio)
- ‚úÖ Com Hash Table: O(t + m) (caso m√©dio)
- ‚úÖ Valida√ß√£o: O(t + m) ‚â§ Œ©(t + m √ó k) √ó 1.1 ‚úì (hash table melhora)

**Fatores Constantes:**
- ‚úÖ Regex Splitting: ~1 ciclo/byte (memcpy-like) ‚â§ 2x te√≥rico ‚úì
- ‚úÖ Hash Lookup: ~5-10 ciclos (cache hit) ‚â§ 2x acesso direto ‚úì
- ‚úÖ Merge Application: In-place shift ‚â§ 2x memcpy ‚úì

**Conclus√£o:** Solu√ß√£o proposta est√° dentro dos thresholds da FASE 1.4 ‚úì

---

## Pr√≥ximos Passos Imediatos

1. **Criar arquivo `src/tokenizer/bpe.c`** com estrutura b√°sica
2. **Criar `tests/test_bpe_tokenizer.c`** com testes de especifica√ß√£o (TDD)
3. **Implementar fun√ß√µes auxiliares** uma por uma, validando com testes
4. **Otimizar com hash table** ap√≥s implementa√ß√£o b√°sica funcionar
5. **Gerar testes adversarial** usando `@gereteste.md`
6. **Validar com tokenizers de refer√™ncia** (sentencepiece, tiktoken)

---

## FASE 7: Status de Implementa√ß√£o

**Data de Conclus√£o:** 2025-01-02  
**Status:** ‚úÖ **IMPLEMENTA√á√ÉO COMPLETA**

### Arquivos Implementados

1. **`src/tokenizer/bpe.c`** - Implementa√ß√£o completa do BPE tokenizer
   - ‚úÖ `q_tokenizer_load()` - Carrega tokenizer do arquivo bin√°rio
   - ‚úÖ `q_tokenizer_encode()` - Algoritmo BPE greedy completo
   - ‚úÖ `q_tokenizer_decode()` - Decodifica tokens para texto
   - ‚úÖ `q_tokenizer_free()` - Libera recursos
   - ‚úÖ Fun√ß√µes auxiliares: `split_text_to_bytes()`, `bytes_to_token_ids()`, `apply_bpe_merges()`, `add_special_tokens()`

2. **`tests/test_bpe_tokenizer.c`** - Testes de especifica√ß√£o (TDD)
   - ‚úÖ 6 testes cobrindo todos os casos cr√≠ticos
   - ‚úÖ Todos os testes passando

3. **`Makefile`** - Target `test-bpe-tokenizer` adicionado

### Valida√ß√µes Confirmadas

- ‚úÖ **Compila√ß√£o:** Sem warnings (`-Wall -Wextra -Werror`)
- ‚úÖ **Testes de Especifica√ß√£o:** 6/6 passando
- ‚úÖ **Teste de Integra√ß√£o:** `test-tokenizer` passando
- ‚úÖ **Complexidade:** O(t + m √ó k_avg) conforme planejado
- ‚úÖ **Memory Safety:** Aloca√ß√£o din√¢mica, cleanup em caso de erro

### Limita√ß√µes Conhecidas (v1.0)

1. **UTF-8 Simplificado:** Tratamento byte-a-byte (n√£o decodifica caracteres multibyte corretamente)
2. **Regex Splitting:** N√£o implementado (fallback para bytes diretos)
3. **Hash Table:** Lookup linear O(m) para merges (otimiza√ß√£o futura)

### Pr√≥ximos Passos (Opcional)

1. **Otimiza√ß√£o:** Hash table para lookup de merges O(1)
2. **UTF-8 Completo:** Suporte completo a caracteres multibyte
3. **Regex Splitting:** Padr√£o BPE completo (ex: GPT-2)
4. **Testes Adversarial:** Usar `@gereteste.md` para gerar su√≠te completa

---

**Status:** ‚úÖ **IMPLEMENTA√á√ÉO COMPLETA E VALIDADA**

