# üéØ PLANEJAMENTO: Aplica√ß√£o dos Tr√™s Passos Cr√≠ticos
# Protocolo de Engenharia - Ordem Inteligente de Execu√ß√£o

**Data:** 2025-01-02  
**Objetivo:** Completar FASE 4.2 (Main Application), Melhorias BPE Tokenizer, e Preparar Training na ordem mais eficiente  
**Metodologia:** First Principles + Model-First Reasoning + Chain-of-Thought

---

## FASE 1: Decomposi√ß√£o por Primeiros Princ√≠pios

### 1.1 Restri√ß√µes F√≠sicas Reais

**Restri√ß√£o 1: Depend√™ncias de C√≥digo**
- **FASE 4.2 (Main)** depende de: Tokenizer ‚úÖ, Forward Pass ‚úÖ, KV Cache ‚úÖ
- **Melhorias BPE** dependem de: BPE Tokenizer base ‚úÖ
- **Training** depende de: Forward Pass ‚úÖ, Backward Pass ‚ùå, Optimizers ‚ùå, Loss Functions ‚ùå

**Restri√ß√£o 2: Ordem de Complexidade**
- **FASE 4.2:** Baixa complexidade (orquestra√ß√£o de componentes existentes)
- **Melhorias BPE:** M√©dia complexidade (parsing UTF-8, regex)
- **Training:** Alta complexidade (backward pass, gradients, optimizers)

**Restri√ß√£o 3: Valor de Neg√≥cio**
- **FASE 4.2:** Alto valor (sistema funcional end-to-end)
- **Melhorias BPE:** M√©dio valor (qualidade de tokeniza√ß√£o)
- **Training:** Alto valor (mas requer mais infraestrutura)

### 1.2 Necessidades Matem√°ticas

**FASE 4.2 (Main Application):**
- **Sampling:** Distribui√ß√£o de probabilidade sobre vocabul√°rio (softmax output)
  - **Greedy:** O(V) onde V = vocab_size
  - **Top-k/Top-p:** O(V + k log k) usando partial sort (n√£o full sort O(V log V))
- **KV Cache Update:** Parte integrante do forward pass F (O(L √ó D) onde L = layers, D = head_dim)
- **Loop de Gera√ß√£o:** Itera√ß√£o determin√≠stica com estado persistente

**Melhorias BPE Tokenizer:**
- **UTF-8 Decoding:** Mapeamento byte ‚Üí c√≥digo ponto Unicode (RFC 3629)
- **Regex Splitting:** Tokeniza√ß√£o por padr√µes (ex: GPT-2: `'s|'t|'re|'ve|'m|'ll|'d| ?\p{L}+| ?\p{N}+| ?[^\s\p{L}\p{N}]+|\s+(?!\S)|\s+`)

**Training:**
- **Backward Pass:** Chain rule aplicado a cada opera√ß√£o (gradientes)
- **Optimizers:** Adam/AdamW com momentum e adaptive learning rates
- **Loss Functions:** CrossEntropy com softmax, MSE para regress√£o

### 1.3 Custo M√≠nimo Te√≥rico (Lower Bound)

**FASE 4.2:**
- **Sampling (greedy):** O(V) onde V = vocab_size (necess√°rio iterar sobre vocabul√°rio)
- **Sampling (top-k/top-p):** O(V + k log k) usando partial sort (n√£o full sort O(V log V))
  - **Lower Bound:** O(V) para greedy, O(V + k log k) para top-k/top-p
- **KV Cache Update:** O(L √ó D) onde L = n_layers, D = head_dim (parte integrante de F)
  - **Nota:** KV Cache update est√° inclu√≠do no custo F do forward pass
- **Loop de Gera√ß√£o:** O(T √ó F) onde T = tokens gerados, F = custo forward pass (inclui KV cache update)
- **Lower Bound:** O(T √ó (F + V)) para greedy, O(T √ó (F + V + k log k)) para top-k/top-p

**Melhorias BPE:**
- **UTF-8 Decoding:** O(n) onde n = bytes (necess√°rio processar cada byte)
- **Regex Splitting:** O(n) onde n = texto (usando RE2 ou FSM para evitar backtracking O(n¬≤))
  - **Mitiga√ß√£o:** RE2 (regex sem backtracking) ou FSM customizado garante O(n)
- **BPE Merges:** O(t) onde t = tokens (com hash table O(1) lookup, n√£o O(m √ó t))
- **Lower Bound:** O(n + t) - n√£o h√° como evitar escanear texto e processar tokens

**Training:**
- **Backward Pass:** O(F) onde F = custo forward pass (mesma ordem de magnitude)
- **Optimizer Update:** O(P) onde P = par√¢metros (necess√°rio atualizar cada par√¢metro)
- **Lower Bound:** O(F + P) - n√£o h√° como evitar computar gradientes e atualizar par√¢metros

### 1.4 Crit√©rios de Parada (Thresholds)

**Threshold Assint√≥tico:** Solu√ß√£o proposta ‚â§ Lower Bound √ó 1.1 (10% overhead m√°ximo)

**Threshold Constante:** Fatores constantes ‚â§ 2x do te√≥rico

**Itera√ß√£o M√°xima:** 3 itera√ß√µes para convergir para dentro dos thresholds

**Valida√ß√£o (Compara√ß√£o com Lower Bound Real):**
- **FASE 4.2 (greedy):** O(T √ó (F + V)) ‚â§ O(T √ó (F + V)) √ó 1.1 ‚úì
- **FASE 4.2 (top-k/top-p):** O(T √ó (F + V + k log k)) ‚â§ O(T √ó (F + V + k log k)) √ó 1.1 ‚úì
  - **Nota:** Partial sort O(k log k) em vez de full sort O(V log V) mant√©m threshold
- **Melhorias BPE:** O(n + t) ‚â§ O(n + t) √ó 1.1 ‚úì (com RE2/FSM garantindo O(n) para regex)
- **Training:** O(F + P + V) ‚â§ O(F + P + V) √ó 1.1 ‚úì (backward pass √© O(F), optimizer √© O(P), loss √© O(V))

---

## FASE 2: Model-First Reasoning

### 2.1 Entidades e Estruturas de Dados

**FASE 4.2 (Main Application):**

```c
// Estrutura de estado do loop de gera√ß√£o
typedef struct {
    q_context* ctx;           // Contexto de mem√≥ria
    q_model* model;           // Modelo carregado
    q_tokenizer* tokenizer;   // Tokenizer carregado
    uint32_t* prompt_tokens;  // Tokens do prompt inicial
    uint32_t num_prompt_tokens;
    uint32_t* generated_tokens; // Tokens gerados
    uint32_t num_generated_tokens;
    uint32_t max_tokens;      // Limite de tokens a gerar
    float temperature;        // Temperatura para sampling
    uint32_t top_k;           // Top-k sampling
    float top_p;              // Nucleus sampling
} q_generation_state;
```

**Melhorias BPE Tokenizer:**

```c
// Estrutura para regex patterns (GPT-2 style)
typedef struct {
    const char* pattern;      // Padr√£o regex (compilado)
    uint32_t priority;        // Prioridade de aplica√ß√£o
} bpe_regex_pattern;

// Estrutura para UTF-8 decoding state
typedef struct {
    uint8_t bytes[4];         // Buffer para caracteres multibyte
    uint8_t num_bytes;        // N√∫mero de bytes no buffer
    bool valid;               // Se sequ√™ncia √© v√°lida
} utf8_decoder_state;
```

**Training:**

```c
// Estrutura para gradients
typedef struct {
    q_tensor* grad;           // Gradientes (mesma shape que par√¢metros)
    q_tensor* param;          // Par√¢metros originais
    q_dtype dtype;            // Tipo de dado
} q_gradient;

// Estrutura para optimizer state (Adam/AdamW)
typedef struct {
    float* m;                 // First moment estimate
    float* v;                 // Second moment estimate
    float beta1;              // Decay rate for first moment
    float beta2;              // Decay rate for second moment
    float epsilon;            // Small constant for numerical stability
    uint32_t t;               // Time step
} q_adam_state;
```

### 2.2 Estados e Invariantes

**FASE 4.2:**

**Pr√©-condi√ß√µes:**
- `ctx != NULL && ctx->initialized == true`
- `model != NULL && model->initialized == true`
- `tokenizer != NULL && tokenizer->initialized == true`
- `prompt_tokens != NULL && num_prompt_tokens > 0`
- `temperature >= 0.0f && temperature <= MAX_TEMPERATURE && isfinite(temperature)`
  - **Nota:** `temperature = 0.0` permite greedy sampling (argmax)
- `max_tokens > 0`
- **Thread Safety:** Implementa√ß√£o ser√° single-threaded (sem locks necess√°rios)

**P√≥s-condi√ß√µes:**
- `generated_tokens != NULL && num_generated_tokens <= max_tokens`
- `ctx->scratch_head` resetado ap√≥s cada token gerado
- KV Cache atualizado com novos tokens

**Invariantes de Loop:**
- `num_generated_tokens <= max_tokens`
- `pos == num_prompt_tokens + num_generated_tokens` (posi√ß√£o atual no contexto)
- KV Cache cont√©m tokens [0..pos-1]

**Melhorias BPE:**

**Pr√©-condi√ß√µes:**
- `text != NULL && strlen(text) > 0`
- `tokenizer != NULL && tokenizer->initialized == true`
- UTF-8 v√°lido (se aplic√°vel)

**P√≥s-condi√ß√µes:**
- `tokens_out != NULL && num_tokens_out > 0`
- Todos os tokens v√°lidos (`token_id < vocab_size`)
- BOS/EOS adicionados se solicitado

**Invariantes:**
- UTF-8 decoder state v√°lido ap√≥s cada byte processado
- Regex patterns aplicados em ordem de prioridade

**Training:**

**Pr√©-condi√ß√µes:**
- `model != NULL && model->initialized == true`
- `input != NULL && target != NULL`
- `optimizer != NULL && optimizer->initialized == true`
- Forward pass executado antes de backward pass

**P√≥s-condi√ß√µes:**
- Gradientes computados para todos os par√¢metros
- Par√¢metros atualizados via optimizer
- Loss computado e retornado

**Invariantes:**
- Gradientes t√™m mesma shape que par√¢metros correspondentes
- Optimizer state atualizado ap√≥s cada step

### 2.3 Grafo de Depend√™ncia

**Grafo Completo:**

```
(FASE 4.2, Tokenizer) -> Tokenizer j√° existe ‚úÖ
(FASE 4.2, Forward Pass) -> Forward Pass j√° existe ‚úÖ
(FASE 4.2, Sampling) -> Precisa implementar
(FASE 4.2, KV Cache Update) -> KV Cache j√° existe ‚úÖ

(Melhorias BPE, BPE Base) -> BPE base j√° existe ‚úÖ
(Melhorias BPE, UTF-8) -> Precisa implementar
(Melhorias BPE, Regex) -> Precisa implementar

(Training, Forward Pass) -> Forward Pass j√° existe ‚úÖ
(Training, Backward Pass) -> Precisa implementar
(Training, Optimizers) -> Precisa implementar
(Training, Loss Functions) -> Precisa implementar
(Backward Pass, Gradients) -> Precisa implementar
(Optimizers, Gradients) -> Precisa implementar
```

**An√°lise de Ciclos:** Nenhum ciclo detectado ‚úì

**Ordem de Execu√ß√£o Recomendada:**

1. **FASE 4.2 (Main Application)** - Depend√™ncias: ‚úÖ Tokenizer, ‚úÖ Forward Pass
2. **Melhorias BPE Tokenizer** - Depend√™ncias: ‚úÖ BPE Base (pode ser feito em paralelo ou ap√≥s FASE 4.2)
3. **Training (FASE 2.6, 3.4, 3.5)** - Depend√™ncias: ‚úÖ Forward Pass, ‚ùå Backward Pass, ‚ùå Optimizers

**Justificativa:**
- FASE 4.2 completa infer√™ncia end-to-end (alto valor, baixa complexidade)
- Melhorias BPE n√£o bloqueiam nada (pode ser feito em paralelo)
- Training requer mais infraestrutura (deve vir por √∫ltimo)

---

## FASE 3: Prova e An√°lise

### 3.1 An√°lise Assint√≥tica

**FASE 4.2 (Main Application):**

**Tempo:**
- **Sampling (greedy):** O(V) onde V = vocab_size (iterar sobre vocabul√°rio)
- **Sampling (top-k/top-p):** O(V + k log k) usando partial sort (n√£o full sort O(V log V))
  - **Implementa√ß√£o:** `nth_element()` para encontrar top-k, depois `sort()` apenas top-k
- **Forward Pass:** O(F) onde F = custo forward pass (inclui KV Cache update O(L √ó D))
- **Loop de Gera√ß√£o:** O(T √ó (F + V)) para greedy, O(T √ó (F + V + k log k)) para top-k/top-p
- **Total:** O(T √ó (F + V)) para greedy, O(T √ó (F + V + k log k)) para top-k/top-p

**Espa√ßo:**
- **Stack:** O(1) - apenas estado do loop
- **Heap:** O(T) - tokens gerados, O(F) - KV Cache (j√° alocado), O(V) - buffer para sorting (top-k/top-p)
- **Total:** O(T + F + V) - linear no n√∫mero de tokens, tamanho do modelo e vocabul√°rio

**Valida√ß√£o (Compara√ß√£o com Lower Bound):**
- **Greedy:** O(T √ó (F + V)) ‚â§ O(T √ó (F + V)) √ó 1.1 ‚úì
- **Top-k/Top-p:** O(T √ó (F + V + k log k)) ‚â§ O(T √ó (F + V + k log k)) √ó 1.1 ‚úì
  - **Nota:** Partial sort mant√©m threshold (k << V, ent√£o k log k << V log V)

**Melhorias BPE Tokenizer:**

**Tempo:**
- **UTF-8 Decoding:** O(n) onde n = bytes (processar cada byte uma vez)
- **Regex Splitting:** O(n) onde n = texto (usando RE2 ou FSM para evitar backtracking)
  - **Mitiga√ß√£o:** RE2 (regex sem backtracking) garante O(n) mesmo com padr√µes complexos
  - **Alternativa:** FSM customizado para padr√µes GPT-2 espec√≠ficos (sem regex engine)
- **BPE Merges:** O(t) onde t = tokens (com hash table O(1) lookup, n√£o O(m √ó t))
  - **Nota:** Hash table j√° implementada em `bpe.c`, ent√£o lookup √© O(1) amortizado
- **Total:** O(n + t) - linear no tamanho do texto e n√∫mero de tokens

**Espa√ßo:**
- **Stack:** O(1) - estado do decoder
- **Heap:** O(t) - tokens intermedi√°rios, O(m) - hash table (j√° alocada)
- **Total:** O(t + m) - linear no n√∫mero de tokens e merges

**Valida√ß√£o (Compara√ß√£o com Lower Bound):**
- **Lower Bound:** O(n + t) - n√£o h√° como evitar escanear texto e processar tokens
- **Implementa√ß√£o:** O(n + t) ‚â§ O(n + t) √ó 1.1 ‚úì (com RE2/FSM garantindo O(n) para regex)

**Training:**

**Tempo:**
- **Backward Pass:** O(F) onde F = custo forward pass (mesma ordem de magnitude)
- **Optimizer Update:** O(P) onde P = par√¢metros (atualizar cada par√¢metro)
- **Loss Computation:** O(V) onde V = vocab_size (softmax)
- **Total:** O(F + P) - dominado por backward pass e optimizer

**Espa√ßo:**
- **Stack:** O(1) - estado do optimizer
- **Heap:** O(P) - gradientes, O(P) - optimizer state (momentum)
- **Total:** O(P) - linear no n√∫mero de par√¢metros

**Valida√ß√£o:** O(F + P) ‚â§ O(F + P) √ó 1.1 ‚úì (backward pass √© O(F), optimizer √© O(P))

### 3.2 Demonstra√ß√£o L√≥gica

**FASE 4.2 - Sampling:**

**Problema:** Selecionar token do vocabul√°rio baseado em distribui√ß√£o de probabilidade.

**Solu√ß√£o:** 
1. Aplicar temperatura: `logits[i] = logits[i] / temperature` (ou `argmax` se `temperature = 0.0`)
2. Aplicar softmax: `probs[i] = exp(logits[i] - max) / sum(exp(logits - max))`
3. Sampling:
   - **Greedy:** `argmax(probs)` - O(V)
   - **Top-k:** Partial sort O(V + k log k) usando `nth_element()` + `sort()` apenas top-k
   - **Top-p:** Partial sort O(V + k log k) + cumulative sum at√© threshold

**Prova de Corre√ß√£o:**
- **Temperatura:** Preserva ordem relativa, apenas escala (n√£o afeta corre√ß√£o)
  - **Greedy (temp=0):** `argmax` √© determin√≠stico e correto
- **Softmax:** Garante `sum(probs) = 1.0` (distribui√ß√£o v√°lida)
- **Top-k/Top-p:** Reduz espa√ßo de busca sem alterar distribui√ß√£o relativa
  - **Partial Sort:** `nth_element()` encontra top-k em O(V), `sort()` apenas top-k em O(k log k)
  - **Complexidade:** O(V + k log k) << O(V log V) quando k << V (t√≠pico: k=10, V=128K)

**Melhorias BPE - UTF-8:**

**Problema:** Decodificar sequ√™ncia de bytes UTF-8 em c√≥digos ponto Unicode.

**Solu√ß√£o:** 
1. Identificar n√∫mero de bytes do caractere (primeiro byte)
2. Validar sequ√™ncia (bytes seguintes come√ßam com `10xxxxxx`)
3. Combinar bits para formar c√≥digo ponto

**Prova de Corre√ß√£o:**
- **RFC 3629:** Algoritmo segue especifica√ß√£o padr√£o
- **Valida√ß√£o:** Bytes inv√°lidos detectados e tratados (fallback para byte literal)

**Training - Backward Pass:**

**Problema:** Computar gradientes via chain rule.

**Solu√ß√£o:**
1. Forward pass armazena valores intermedi√°rios
2. Backward pass aplica chain rule: `grad_input = grad_output √ó ‚àÇoutput/‚àÇinput`
3. Gradientes propagados de sa√≠da para entrada

**Prova de Corre√ß√£o:**
- **Chain Rule:** Matematicamente correto (c√°lculo diferencial)
- **Precis√£o:** Gradientes computados com mesma precis√£o que forward pass

### 3.3 Simula√ß√£o de Falha (Failure Mode Analysis)

**FASE 4.2:**

**Resultado Correto (Target):**
- Loop de gera√ß√£o produz tokens v√°lidos (`token_id < vocab_size`)
- KV Cache atualizado corretamente ap√≥s cada token
- Sampling produz distribui√ß√£o v√°lida (soma = 1.0)
- Erros tratados graciosamente (retorna `q_error_code`)

**Exemplo de Resultado Ruim/Errado (Anti-Pattern):**
- **Race Condition:** M√∫ltiplas threads acessando KV Cache sem sincroniza√ß√£o
  - **Mitiga√ß√£o:** Implementa√ß√£o single-threaded (sem locks necess√°rios)
- **Memory Leak:** Tokens gerados n√£o liberados ap√≥s gera√ß√£o
- **Invalid Sampling:** Probabilidades n√£o somam 1.0 (softmax incorreto)
- **Sampling Performance:** Full sort O(V log V) em vez de partial sort O(V + k log k)
  - **Mitiga√ß√£o:** Usar `nth_element()` + `sort()` apenas top-k
- **Silent Failure:** Erros n√£o reportados (retorna `Q_OK` quando deveria retornar erro)

**Melhorias BPE:**

**Resultado Correto (Target):**
- UTF-8 decodificado corretamente (c√≥digos ponto v√°lidos)
- Regex patterns aplicados em ordem de prioridade
- Tokens v√°lidos (`token_id < vocab_size`)
- BOS/EOS adicionados corretamente

**Exemplo de Resultado Ruim/Errado (Anti-Pattern):**
- **UTF-8 Malformed:** Sequ√™ncias inv√°lidas n√£o tratadas (crash)
- **Regex Performance:** O(n¬≤) devido a backtracking excessivo (catastrophic backtracking)
  - **Mitiga√ß√£o:** Usar RE2 (regex sem backtracking) ou FSM customizado
  - **Valida√ß√£o:** Testes adversarial com padr√µes que causam backtracking
- **Memory Leak:** Buffers intermedi√°rios n√£o liberados
- **Invalid Tokens:** Tokens fora do vocabul√°rio gerados

**Training:**

**Resultado Correto (Target):**
- Gradientes computados corretamente (valida√ß√£o via gradient checking)
- Optimizer atualiza par√¢metros corretamente (converg√™ncia em dataset pequeno)
- Loss diminui ao longo do treinamento
- Zero memory leaks (gradientes liberados ap√≥s uso)

**Exemplo de Resultado Ruim/Errado (Anti-Pattern):**
- **Gradient Explosion:** Gradientes muito grandes (n√£o normalizados)
- **Vanishing Gradients:** Gradientes muito pequenos (problema de profundidade)
- **Optimizer Divergence:** Par√¢metros explodem (learning rate muito alto)
- **Memory Leak:** Optimizer state n√£o liberado

### 3.4 Especifica√ß√£o Test√°vel

**FASE 4.2 - Sampling Function:**

**Assinatura:**
```c
q_error_code q_sample_token(
    const float* logits,        // [vocab_size] - logits do modelo
    uint32_t vocab_size,        // Tamanho do vocabul√°rio
    float temperature,          // Temperatura (0.0 = greedy, >0.0 = sampling, must be finite)
    uint32_t top_k,             // Top-k sampling (0 = desabilitado)
    float top_p,                // Nucleus sampling (0.0 = desabilitado)
    uint32_t* token_id_out      // [out] Token ID selecionado
);
// Nota: Usa partial sort O(V + k log k) para top-k/top-p, n√£o full sort O(V log V)
```

**Teste de Especifica√ß√£o:**
- **Teste 1:** `temperature = 1.0, top_k = 0, top_p = 0.0` ‚Üí Distribui√ß√£o uniforme sobre top-1
- **Teste 2:** `temperature = 0.5` ‚Üí Distribui√ß√£o mais concentrada (entropia menor)
- **Teste 3:** `top_k = 10` ‚Üí Apenas top-10 tokens considerados
- **Teste 4:** `top_p = 0.9` ‚Üí Apenas tokens que somam 90% de probabilidade considerados
- **Valida√ß√£o:** `sum(probs) = 1.0 ¬± 1e-5` (distribui√ß√£o v√°lida)

**Melhorias BPE - UTF-8 Decoding:**

**Assinatura:**
```c
q_error_code q_utf8_decode_char(
    const uint8_t* bytes,        // [in] Sequ√™ncia de bytes UTF-8
    size_t num_bytes,            // [in] N√∫mero de bytes dispon√≠veis
    uint32_t* code_point_out,    // [out] C√≥digo ponto Unicode
    size_t* bytes_consumed_out   // [out] Bytes consumidos (1-4)
);
```

**Teste de Especifica√ß√£o:**
- **Teste 1:** ASCII (`'A'` = 0x41) ‚Üí `code_point = 65, bytes_consumed = 1`
- **Teste 2:** 2-byte UTF-8 (`'√©'` = 0xC3 0xA9) ‚Üí `code_point = 233, bytes_consumed = 2`
- **Teste 3:** 3-byte UTF-8 (`'‰∏≠'` = 0xE4 0xB8 0xAD) ‚Üí `code_point = 20013, bytes_consumed = 3`
- **Teste 4:** Sequ√™ncia inv√°lida ‚Üí Retorna `Q_ERR_INVALID_ARG`

**Training - Backward Pass:**

**Assinatura:**
```c
q_error_code q_model_backward(
    q_model* model,              // [in/out] Modelo
    q_context* ctx,              // [in/out] Contexto de mem√≥ria
    const float* loss_grad,      // [in] Gradiente da loss (shape: [batch_size, vocab_size])
    uint32_t batch_size,         // [in] Tamanho do batch
    uint32_t seq_len             // [in] Comprimento da sequ√™ncia
);
```

**Teste de Especifica√ß√£o:**
- **Teste 1:** Gradiente unit√°rio ‚Üí Gradientes computados para todos os par√¢metros
- **Teste 2:** Gradient Checking ‚Üí `|grad_numerical - grad_analytical| < 1e-5`
- **Teste 3:** Zero Gradients ‚Üí Se `loss_grad = 0`, todos os gradientes devem ser 0
- **Valida√ß√£o:** Gradientes t√™m mesma shape que par√¢metros correspondentes

---

## FASE 4: Chain-of-Thought e Execu√ß√£o

### 4.1 Ordem de Execu√ß√£o Recomendada

**FASE 1: FASE 4.2 (Main Application)** - Prioridade ALTA
- **Dura√ß√£o Estimada:** 2-3 dias
- **Depend√™ncias:** ‚úÖ Todas satisfeitas
- **Valor:** Alto (sistema funcional end-to-end)

**FASE 2: Melhorias BPE Tokenizer** - Prioridade M√âDIA
- **Dura√ß√£o Estimada:** 3-5 dias
- **Depend√™ncias:** ‚úÖ BPE base existe
- **Valor:** M√©dio (melhora qualidade, n√£o bloqueia nada)

**FASE 3: Training (FASE 2.6, 3.4, 3.5)** - Prioridade ALTA (mas ap√≥s FASE 1 e 2)
- **Dura√ß√£o Estimada:** 3-4 semanas
- **Depend√™ncias:** ‚úÖ Forward Pass, ‚ùå Backward Pass, ‚ùå Optimizers
- **Valor:** Alto (mas requer mais infraestrutura)

### 4.2 Passos At√¥micos de Implementa√ß√£o

**FASE 4.2 (Main Application):**

1. **Definir Interface (Header)**
   - Criar `src/main.c` com estrutura b√°sica
   - Definir `q_generation_state` struct
   - Definir `q_sample_token()` function

2. **Implementar Teste de Unidade (TDD)**
   - Criar `tests/test_main.c` com testes de especifica√ß√£o
   - Testar sampling (distribui√ß√£o v√°lida)
   - Testar loop de gera√ß√£o (tokens v√°lidos)
   - Testar tratamento de erros

3. **Implementar Sampling Function**
   - Implementar `q_sample_token()` com softmax + temperatura
   - Implementar greedy sampling (temperature = 0.0) - O(V)
   - Implementar top-k sampling usando partial sort (`nth_element()` + `sort()` apenas top-k) - O(V + k log k)
   - Implementar nucleus (top-p) sampling usando partial sort - O(V + k log k)
   - **CR√çTICO:** N√£o usar full sort O(V log V), usar partial sort O(V + k log k)
   - Validar distribui√ß√£o (soma = 1.0 ¬± 1e-5)

4. **Implementar Main Loop**
   - Carregar modelo e tokenizer
   - Tokenizar prompt inicial
   - Loop: Forward ‚Üí Sample ‚Üí Print ‚Üí Update KV Cache
   - Tratamento de erros robusto

5. **Otimiza√ß√£o e Valida√ß√£o**
   - Verificar zero-malloc no hot path
   - Validar performance (lat√™ncia por token)
   - Testes end-to-end

**Melhorias BPE Tokenizer:**

1. **Definir Interface (Header)**
   - Adicionar `q_utf8_decode_char()` em `include/qorus.h`
   - Adicionar `bpe_regex_pattern` struct
   - Adicionar configura√ß√£o de regex patterns

2. **Implementar Teste de Unidade (TDD)**
   - Criar `tests/test_bpe_utf8.c` com testes UTF-8
   - Criar `tests/test_bpe_regex.c` com testes regex
   - Validar especifica√ß√£o matem√°tica

3. **Implementar UTF-8 Decoding**
   - Implementar `q_utf8_decode_char()` seguindo RFC 3629
   - Integrar com `q_tokenizer_encode()`
   - Tratamento de sequ√™ncias inv√°lidas

4. **Implementar Regex Splitting**
   - **CR√çTICO:** Usar RE2 (regex sem backtracking) ou FSM customizado para garantir O(n)
   - Compilar padr√µes regex (GPT-2 style) usando RE2 ou FSM
   - Aplicar em ordem de prioridade
   - Integrar com BPE merges
   - **Valida√ß√£o:** Testes adversarial com padr√µes que causam backtracking catastr√≥fico

5. **Otimiza√ß√£o e Valida√ß√£o**
   - Validar performance (O(n) mantido com RE2/FSM)
   - Testes adversarial (`@gereteste.md`) com padr√µes que causam backtracking
   - Valida√ß√£o com tokenizers de refer√™ncia (sentencepiece, tiktoken)
   - Benchmark de performance: confirmar O(n) mesmo com textos longos (1M+ bytes)

**Training (FASE 2.6, 3.4, 3.5):**

**FASE 2.6: Training Kernels**

1. **Implementar Loss Functions**
   - `q_cross_entropy_loss()` - CrossEntropy com softmax
   - `q_mse_loss()` - Mean Squared Error
   - Valida√ß√£o contra PyTorch

2. **Implementar Optimizers**
   - `q_adam_optimizer()` - Adam/AdamW optimizer
   - `q_sgd_optimizer()` - SGD com momentum (opcional)
   - Valida√ß√£o contra PyTorch

3. **Implementar Gradient Clipping**
   - `q_clip_gradients()` - Clipping por norma ou valor
   - Integra√ß√£o com optimizers

**FASE 3.4: Backward Pass**

1. **Implementar Backward Infrastructure**
   - Estrutura para armazenar valores intermedi√°rios
   - Chain rule aplicado a cada opera√ß√£o
   - Gradientes propagados de sa√≠da para entrada

2. **Implementar Layer Backward**
   - `q_linear_backward()` - Backward para Linear layer
   - `q_attention_backward()` - Backward para Attention
   - `q_ffn_backward()` - Backward para FFN
   - Valida√ß√£o via gradient checking

**FASE 3.5: Training Loop**

1. **Implementar Training Loop**
   - Loop: Forward ‚Üí Backward ‚Üí Optimizer Update
   - Batch processing
   - Epoch management

2. **Implementar Training Utilities**
   - Learning rate scheduling
   - Checkpointing (salvar/carregar modelo)
   - Metrics logging

---

## FASE 5: Checkpoints e Fatora√ß√£o

### 5.1 Checkpoints por Fase

**FASE 4.2:**

- **Checkpoint 1:** Compila√ß√£o limpa sem warnings (`-Wall -Wextra -Werror`)
- **Checkpoint 2:** Teste b√°sico passa (sampling produz distribui√ß√£o v√°lida)
- **Checkpoint 3:** An√°lise Est√°tica limpa (cppcheck/clang-tidy)
- **Checkpoint 4:** M√©tricas Quantitativas:
  - Complexidade: O(T √ó (F + V)) ‚â§ O(T √ó (F + V)) √ó 1.1 ‚úì (greedy)
  - Complexidade: O(T √ó (F + V + k log k)) ‚â§ O(T √ó (F + V + k log k)) √ó 1.1 ‚úì (top-k/top-p)
  - Cobertura: ‚â• 90% branches
  - Zero race conditions (single-threaded)
  - Sampling usa partial sort, n√£o full sort

**Melhorias BPE:**

- **Checkpoint 1:** Compila√ß√£o limpa sem warnings
- **Checkpoint 2:** Teste b√°sico passa (UTF-8 decodificado corretamente)
- **Checkpoint 3:** An√°lise Est√°tica limpa
- **Checkpoint 4:** M√©tricas Quantitativas:
  - Complexidade: O(n + t) ‚â§ O(n + t) √ó 1.1 ‚úì (com RE2/FSM garantindo O(n) para regex)
  - Cobertura: ‚â• 90% branches
  - Valida√ß√£o com tokenizers de refer√™ncia
  - Regex usa RE2 ou FSM (sem backtracking catastr√≥fico)

**Training:**

- **Checkpoint 1:** Compila√ß√£o limpa sem warnings
- **Checkpoint 2:** Teste b√°sico passa (gradientes computados corretamente)
- **Checkpoint 3:** An√°lise Est√°tica limpa
- **Checkpoint 4:** M√©tricas Quantitativas:
  - Complexidade: O(F + P + V) ‚â§ O(F + P + V) √ó 1.1 ‚úì
  - Cobertura: ‚â• 90% branches
  - Gradient checking passa (erro < 1e-5)

### 5.2 Fatora√ß√£o (Complexidade Ciclom√°tica)

**Crit√©rio:** Se V(G) > 10 OU (linhas > 50 E n√≠veis_indenta√ß√£o > 3), refatorar imediatamente.

**FASE 4.2:**
- **Main Loop:** V(G) ‚âà 5 (if/while simples) ‚úì
- **Sampling:** V(G) ‚âà 8 (top-k/top-p logic) ‚úì

**Melhorias BPE:**
- **UTF-8 Decoding:** V(G) ‚âà 6 (switch case) ‚úì
- **Regex Splitting:** V(G) ‚âà 7 (pattern matching) ‚úì

**Training:**
- **Backward Pass:** V(G) ‚âà 12 (chain rule aplicado) ‚ö†Ô∏è - Pode precisar refatora√ß√£o
- **Optimizer:** V(G) ‚âà 9 (Adam logic) ‚úì

---

## FASE 6: O Artefato de Execu√ß√£o

### Contexto Ancorado

**Arquivos a Criar:**
- `src/main.c` - Main application com loop de gera√ß√£o
- `tests/test_main.c` - Testes para main application
- `src/tokenizer/bpe_utf8.c` - UTF-8 decoding utilities (ou integrar em `bpe.c`)
- `src/tokenizer/bpe_regex.c` - Regex splitting utilities (ou integrar em `bpe.c`)
- `tests/test_bpe_utf8.c` - Testes UTF-8
- `tests/test_bpe_regex.c` - Testes regex
- `src/ops/avx2/loss.c` - Loss functions (CrossEntropy, MSE)
- `src/optim/adam.c` - Adam/AdamW optimizer
- `src/optim/sgd.c` - SGD optimizer (opcional)
- `src/core/backward.c` - Backward pass infrastructure
- `src/core/training.c` - Training loop
- `tests/test_training.c` - Testes de training

**Arquivos a Modificar:**
- `include/qorus.h` - Adicionar declara√ß√µes de novas fun√ß√µes
- `include/qorus_types.h` - Adicionar structs (`q_generation_state`, `q_gradient`, `q_adam_state`)
- `src/tokenizer/bpe.c` - Integrar UTF-8 e regex
- `Makefile` - Adicionar novos targets de teste

### Valida√ß√£o de Thresholds

**FASE 4.2:**
- ‚úÖ Complexidade (greedy): O(T √ó (F + V)) ‚â§ O(T √ó (F + V)) √ó 1.1 ‚úì
- ‚úÖ Complexidade (top-k/top-p): O(T √ó (F + V + k log k)) ‚â§ O(T √ó (F + V + k log k)) √ó 1.1 ‚úì
- ‚úÖ Fatores constantes: Sampling greedy ~10 ciclos/token ‚â§ 2x te√≥rico ‚úì
- ‚úÖ Fatores constantes: Sampling top-k ~(10 + k log k) ciclos/token ‚â§ 2x te√≥rico ‚úì
- ‚úÖ KV Cache update inclu√≠do em F (n√£o overhead adicional)

**Melhorias BPE:**
- ‚úÖ Complexidade: O(n + t) ‚â§ O(n + t) √ó 1.1 ‚úì (com RE2/FSM garantindo O(n) para regex)
- ‚úÖ Fatores constantes: UTF-8 decoding ~5 ciclos/byte ‚â§ 2x te√≥rico ‚úì
- ‚úÖ Fatores constantes: Regex splitting O(n) garantido (RE2/FSM sem backtracking)
- ‚úÖ BPE merges O(t) com hash table (n√£o O(m √ó t))

**Training:**
- ‚úÖ Complexidade: O(F + P + V) ‚â§ O(F + P + V) √ó 1.1 ‚úì
- ‚úÖ Fatores constantes: Backward pass ~1.5x forward pass ‚â§ 2x te√≥rico ‚úì

### Checklist de Implementa√ß√£o

#### FASE 4.2: Main Application (Prioridade ALTA)

- [ ] **1. Definir Interface**
  - [ ] Criar `src/main.c` com estrutura b√°sica
  - [ ] Definir `q_generation_state` struct em `include/qorus_types.h`
  - [ ] Definir `q_sample_token()` function em `include/qorus.h`
  - [ ] Documentar pr√©/p√≥s-condi√ß√µes

- [ ] **2. Implementar Testes (TDD)**
  - [ ] Criar `tests/test_main.c` com testes de especifica√ß√£o
  - [ ] Teste: Sampling produz distribui√ß√£o v√°lida (soma = 1.0)
  - [ ] Teste: Top-k sampling funciona corretamente
  - [ ] Teste: Nucleus (top-p) sampling funciona corretamente
  - [ ] Teste: Loop de gera√ß√£o produz tokens v√°lidos
  - [ ] Teste: KV Cache atualizado corretamente
  - [ ] Teste: Tratamento de erros robusto

- [ ] **3. Implementar Sampling Function**
  - [ ] Implementar `q_sample_token()` com softmax + temperatura
  - [ ] Implementar greedy sampling (temperature = 0.0) - O(V)
  - [ ] Implementar top-k sampling usando partial sort (`nth_element()` + `sort()` apenas top-k) - O(V + k log k)
  - [ ] Implementar nucleus (top-p) sampling usando partial sort - O(V + k log k)
  - [ ] **CR√çTICO:** N√£o usar full sort O(V log V), usar partial sort O(V + k log k)
  - [ ] Validar distribui√ß√£o (soma = 1.0 ¬± 1e-5)
  - [ ] Otimiza√ß√£o: Evitar aloca√ß√£o din√¢mica no hot path

- [ ] **4. Implementar Main Loop**
  - [ ] Carregar modelo e tokenizer
  - [ ] Tokenizar prompt inicial
  - [ ] Loop: Forward ‚Üí Sample ‚Üí Print ‚Üí Update KV Cache
  - [ ] Tratamento de erros robusto (verificar `q_error_code`)
  - [ ] Suporte a prompts interativos (CLI)

- [ ] **5. Valida√ß√£o e Otimiza√ß√£o**
  - [ ] Verificar zero-malloc no hot path
  - [ ] Validar performance (lat√™ncia por token medida)
  - [ ] Testes end-to-end (prompt ‚Üí tokens gerados)
  - [ ] An√°lise est√°tica (cppcheck/clang-tidy)
  - [ ] Cobertura de testes ‚â• 90%

#### Melhorias BPE Tokenizer (Prioridade M√âDIA)

- [ ] **1. Definir Interface**
  - [ ] Adicionar `q_utf8_decode_char()` em `include/qorus.h`
  - [ ] Adicionar `bpe_regex_pattern` struct em `include/qorus_types.h`
  - [ ] Adicionar configura√ß√£o de regex patterns

- [ ] **2. Implementar Testes (TDD)**
  - [ ] Criar `tests/test_bpe_utf8.c` com testes UTF-8
  - [ ] Teste: ASCII decodificado corretamente
  - [ ] Teste: 2-byte UTF-8 decodificado corretamente
  - [ ] Teste: 3-byte UTF-8 decodificado corretamente
  - [ ] Teste: 4-byte UTF-8 decodificado corretamente
  - [ ] Teste: Sequ√™ncias inv√°lidas tratadas graciosamente
  - [ ] Criar `tests/test_bpe_regex.c` com testes regex
  - [ ] Teste: Padr√µes GPT-2 aplicados corretamente
  - [ ] Teste: Prioridade de padr√µes respeitada

- [ ] **3. Implementar UTF-8 Decoding**
  - [ ] Implementar `q_utf8_decode_char()` seguindo RFC 3629
  - [ ] Integrar com `q_tokenizer_encode()` em `src/tokenizer/bpe.c`
  - [ ] Tratamento de sequ√™ncias inv√°lidas (fallback para byte literal)
  - [ ] Otimiza√ß√£o: Evitar aloca√ß√£o din√¢mica no hot path

- [ ] **4. Implementar Regex Splitting**
  - [ ] **CR√çTICO:** Usar RE2 (regex sem backtracking) ou FSM customizado para garantir O(n)
  - [ ] Compilar padr√µes regex (GPT-2 style) usando RE2 ou FSM
  - [ ] Aplicar em ordem de prioridade
  - [ ] Integrar com BPE merges em `src/tokenizer/bpe.c`
  - [ ] Valida√ß√£o: Testes adversarial com padr√µes que causam backtracking catastr√≥fico

- [ ] **5. Valida√ß√£o e Otimiza√ß√£o**
  - [ ] Validar performance (O(n) mantido com RE2/FSM)
  - [ ] Testes adversarial (`@gereteste.md`) com padr√µes que causam backtracking
  - [ ] Benchmark de performance: confirmar O(n) mesmo com textos longos (1M+ bytes)
  - [ ] Valida√ß√£o com tokenizers de refer√™ncia (sentencepiece, tiktoken)
  - [ ] An√°lise est√°tica (cppcheck/clang-tidy)
  - [ ] Cobertura de testes ‚â• 90%

#### Training (FASE 2.6, 3.4, 3.5) (Prioridade ALTA - ap√≥s FASE 4.2)

**FASE 2.6: Training Kernels**

- [ ] **1. Implementar Loss Functions**
  - [ ] Criar `src/ops/avx2/loss.c`
  - [ ] Implementar `q_cross_entropy_loss()` - CrossEntropy com softmax
  - [ ] Implementar `q_mse_loss()` - Mean Squared Error
  - [ ] Valida√ß√£o contra PyTorch (erro < 1e-5)
  - [ ] Testes de especifica√ß√£o (TDD)

- [ ] **2. Implementar Optimizers**
  - [ ] Criar `src/optim/adam.c`
  - [ ] Implementar `q_adam_optimizer()` - Adam/AdamW optimizer
  - [ ] Criar `src/optim/sgd.c` (opcional)
  - [ ] Implementar `q_sgd_optimizer()` - SGD com momentum
  - [ ] Valida√ß√£o contra PyTorch (converg√™ncia em dataset pequeno)
  - [ ] Testes de especifica√ß√£o (TDD)

- [ ] **3. Implementar Gradient Clipping**
  - [ ] Implementar `q_clip_gradients()` em `src/ops/avx2/loss.c`
  - [ ] Clipping por norma (L2 norm)
  - [ ] Clipping por valor (min/max)
  - [ ] Integra√ß√£o com optimizers

**FASE 3.4: Backward Pass**

- [ ] **1. Implementar Backward Infrastructure**
  - [ ] Criar `src/core/backward.c`
  - [ ] Estrutura para armazenar valores intermedi√°rios
  - [ ] Chain rule aplicado a cada opera√ß√£o
  - [ ] Gradientes propagados de sa√≠da para entrada

- [ ] **2. Implementar Layer Backward**
  - [ ] `q_linear_backward()` - Backward para Linear layer
  - [ ] `q_attention_backward()` - Backward para Attention
  - [ ] `q_ffn_backward()` - Backward para FFN
  - [ ] `q_rmsnorm_backward()` - Backward para RMSNorm
  - [ ] Valida√ß√£o via gradient checking (erro < 1e-5)

**FASE 3.5: Training Loop**

- [ ] **1. Implementar Training Loop**
  - [ ] Criar `src/core/training.c`
  - [ ] Loop: Forward ‚Üí Backward ‚Üí Optimizer Update
  - [ ] Batch processing
  - [ ] Epoch management

- [ ] **2. Implementar Training Utilities**
  - [ ] Learning rate scheduling
  - [ ] Checkpointing (salvar/carregar modelo)
  - [ ] Metrics logging

- [ ] **3. Valida√ß√£o End-to-End**
  - [ ] Teste: Training converge em dataset pequeno
  - [ ] Teste: Loss diminui ao longo do treinamento
  - [ ] Teste: Gradientes computados corretamente (gradient checking)
  - [ ] An√°lise est√°tica (cppcheck/clang-tidy)
  - [ ] Cobertura de testes ‚â• 90%

---

## Resumo Executivo

### Ordem de Execu√ß√£o Recomendada

1. **FASE 4.2 (Main Application)** - 2-3 dias
   - ‚úÖ Depend√™ncias satisfeitas
   - ‚úÖ Alto valor (sistema funcional end-to-end)
   - ‚úÖ Baixa complexidade

2. **Melhorias BPE Tokenizer** - 3-5 dias (pode ser feito em paralelo ou ap√≥s FASE 4.2)
   - ‚úÖ Depend√™ncias satisfeitas
   - ‚úÖ M√©dio valor (melhora qualidade)
   - ‚úÖ M√©dia complexidade

3. **Training (FASE 2.6, 3.4, 3.5)** - 3-4 semanas (ap√≥s FASE 4.2)
   - ‚úÖ Forward Pass existe
   - ‚ùå Requer Backward Pass, Optimizers, Loss Functions
   - ‚úÖ Alto valor (mas requer mais infraestrutura)

### Valida√ß√£o de Thresholds (Compara√ß√£o com Lower Bound Real)

- ‚úÖ **FASE 4.2 (greedy):** O(T √ó (F + V)) ‚â§ O(T √ó (F + V)) √ó 1.1 ‚úì
- ‚úÖ **FASE 4.2 (top-k/top-p):** O(T √ó (F + V + k log k)) ‚â§ O(T √ó (F + V + k log k)) √ó 1.1 ‚úì
  - **Nota:** Partial sort mant√©m threshold (k << V, ent√£o k log k << V log V)
- ‚úÖ **Melhorias BPE:** O(n + t) ‚â§ O(n + t) √ó 1.1 ‚úì (com RE2/FSM garantindo O(n) para regex)
- ‚úÖ **Training:** O(F + P + V) ‚â§ O(F + P + V) √ó 1.1 ‚úì

### Pr√≥ximos Passos Imediatos

1. **Come√ßar FASE 4.2** - Implementar `src/main.c` com loop de gera√ß√£o
2. **Em paralelo (opcional):** Come√ßar melhorias BPE Tokenizer
3. **Ap√≥s FASE 4.2:** Come√ßar Training (FASE 2.6 ‚Üí 3.4 ‚Üí 3.5)

---

## FASE 7: Riscos e Mitiga√ß√µes

### 7.1 Riscos de Performance

**Risco 1: Sampling com Full Sort O(V log V)**
- **Severidade:** ALTA (viola threshold para vocabul√°rios grandes)
- **Probabilidade:** M√âDIA (implementa√ß√£o ing√™nua pode usar full sort)
- **Mitiga√ß√£o:** Usar partial sort (`nth_element()` + `sort()` apenas top-k)
- **Valida√ß√£o:** Benchmark confirmando O(V + k log k) em vez de O(V log V)

**Risco 2: Regex Backtracking Catastr√≥fico O(n¬≤)**
- **Severidade:** ALTA (viola threshold para textos longos)
- **Probabilidade:** BAIXA (padr√µes GPT-2 s√£o relativamente seguros)
- **Mitiga√ß√£o:** Usar RE2 (regex sem backtracking) ou FSM customizado
- **Valida√ß√£o:** Testes adversarial com padr√µes que causam backtracking

**Risco 3: KV Cache Update Overhead N√£o Considerado**
- **Severidade:** BAIXA (j√° inclu√≠do em F)
- **Probabilidade:** BAIXA (j√° documentado como parte de F)
- **Mitiga√ß√£o:** Documentar que O(L √ó D) √© parte de F (forward pass)
- **Valida√ß√£o:** Confirmar que F inclui KV cache update

### 7.2 Riscos de Implementa√ß√£o

**Risco 4: Thread Safety N√£o Especificado**
- **Severidade:** M√âDIA (pode causar bugs se usado em contexto multi-threaded)
- **Probabilidade:** BAIXA (implementa√ß√£o single-threaded)
- **Mitiga√ß√£o:** Documentar explicitamente que implementa√ß√£o √© single-threaded
- **Valida√ß√£o:** An√°lise est√°tica confirmando aus√™ncia de data races

**Risco 5: Temperature = 0.0 N√£o Tratado**
- **Severidade:** BAIXA (greedy sampling deve ser permitido)
- **Probabilidade:** BAIXA (pr√©-condi√ß√µes corrigidas)
- **Mitiga√ß√£o:** Permitir `temperature = 0.0` para greedy sampling
- **Valida√ß√£o:** Testes com `temperature = 0.0` funcionando corretamente

### 7.3 Riscos de Depend√™ncias

**Risco 6: RE2 N√£o Dispon√≠vel**
- **Severidade:** M√âDIA (fallback para FSM customizado)
- **Probabilidade:** BAIXA (RE2 √© biblioteca comum)
- **Mitiga√ß√£o:** Implementar FSM customizado como fallback
- **Valida√ß√£o:** Build system detecta RE2, usa FSM se n√£o dispon√≠vel

---

## FASE 8: Thread Safety e Concorr√™ncia

### 8.1 Modelo de Threading

**Implementa√ß√£o:** Single-threaded (sem locks necess√°rios)

**Justificativa:**
- Loop de gera√ß√£o √© sequencial (token por token)
- KV Cache √© append-only (sem race conditions em single-threaded)
- Sampling √© stateless (sem estado compartilhado)

**Se Multi-threading Necess√°rio no Futuro:**
- Adicionar locks em `q_context` para acesso concorrente
- Usar atomic operations para contadores compartilhados
- Documentar thread safety em API p√∫blica

### 8.2 An√°lise de Race Conditions

**Vari√°veis Compartilhadas:**
- `ctx->scratch_head` - Apenas single-threaded ‚úì
- `ctx->kv_buffer` - Append-only, single-threaded ‚úì
- `model->layers` - Read-only ap√≥s inicializa√ß√£o ‚úì

**Conclus√£o:** Sem race conditions em implementa√ß√£o single-threaded.

---

**Status:** ‚úÖ **PLANEJAMENTO COMPLETO E CORRIGIDO - PRONTO PARA EXECU√á√ÉO**

**√öltima Atualiza√ß√£o:** 2025-01-02 (ap√≥s auditoria e corre√ß√µes)

